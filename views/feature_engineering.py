"""
Trang X·ª≠ L√Ω & Ch·ªçn Bi·∫øn - Feature Engineering & Selection
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from utils.session_state import init_session_state


# ============ FRAGMENT FUNCTIONS ============
# S·ª≠ d·ª•ng @st.fragment ƒë·ªÉ ngƒÉn rerun to√†n b·ªô trang khi t∆∞∆°ng t√°c

@st.fragment
def remove_columns_fragment(data):
    """Fragment ƒë·ªÉ x·ª≠ l√Ω lo·∫°i b·ªè c·ªôt - kh√¥ng g√¢y rerun to√†n trang"""
    st.markdown("##### üîç X√≥a/Lo·∫°i Bi·∫øn ƒê·ªãnh Danh")
    
    st.markdown("""
    <div style="background-color: #262730; padding: 1rem; border-radius: 8px; margin-bottom: 1rem;">
        <p style="margin: 0; font-size: 0.9rem;">üí° <strong>Bi·∫øn ƒë·ªãnh danh</strong> kh√¥ng mang th√¥ng tin d·ª± ƒëo√°n, 
        n√™n lo·∫°i b·ªè kh·ªèi m√¥ h√¨nh:</p>
        <ul style="font-size: 0.85rem; margin: 0.5rem 0 0 1rem;">
            <li>ID kh√°ch h√†ng (customer_id, user_id)</li>
            <li>S·ªë h·ª£p ƒë·ªìng (contract_id, loan_id)</li>
            <li>S·ªë CMND/CCCD, s·ªë t√†i kho·∫£n</li>
            <li>C√°c m√£ ƒë·ªãnh danh kh√°c</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)
    
    # L·∫•y data m·ªõi nh·∫•t t·ª´ session_state
    current_data = st.session_state.data
    all_cols = current_data.columns.tolist()
    
    if all_cols:
        # Hi·ªÉn th·ªã th√¥ng b√°o n·∫øu v·ª´a x√≥a c·ªôt th√†nh c√¥ng
        if st.session_state.get('_removed_cols_success'):
            removed_info = st.session_state._removed_cols_success
            st.success(f"‚úÖ ƒê√£ lo·∫°i b·ªè {removed_info['count']} c·ªôt: {', '.join(removed_info['cols'])}")
            # Clear th√¥ng b√°o sau khi hi·ªÉn th·ªã
            del st.session_state._removed_cols_success
        
        st.info(f"üìã Dataset hi·ªán c√≥ {len(all_cols)} c·ªôt")
        
        # Show columns info
        cols_info = []
        for col in all_cols:
            unique_count = current_data[col].nunique()
            unique_pct = round(unique_count / len(current_data) * 100, 2)
            cols_info.append({
                'C·ªôt': col,
                'S·ªë gi√° tr·ªã duy nh·∫•t': unique_count,
                'T·ª∑ l·ªá unique (%)': unique_pct
            })
        
        cols_df = pd.DataFrame(cols_info)
        st.dataframe(cols_df, width='stretch', hide_index=True, height=300)
        
        # Check view-only mode
        is_view_only = st.session_state.get('fe_view_only', False)
        
        # Select columns to remove
        cols_to_remove = st.multiselect(
            "Ch·ªçn c·ªôt ƒë·ªÉ lo·∫°i b·ªè:",
            all_cols,
            key="id_cols_to_remove_frag",
            help="Ch·ªçn c√°c c·ªôt ƒë·ªãnh danh c·∫ßn lo·∫°i b·ªè kh·ªèi dataset",
            disabled=is_view_only
        )
        
        if is_view_only:
            st.warning("üîí B·∫°n kh√¥ng c√≥ quy·ªÅn thay ƒë·ªïi d·ªØ li·ªáu.")
        
        if st.button("üóëÔ∏è Lo·∫°i B·ªè C√°c C·ªôt ƒê√£ Ch·ªçn", key="remove_id_cols_frag", width='stretch', type="primary", disabled=is_view_only):
            if cols_to_remove:
                # Initialize removed_columns_config if not exists
                if 'removed_columns_config' not in st.session_state:
                    st.session_state.removed_columns_config = {}
                
                # Backup before removing
                if 'removed_columns_backup' not in st.session_state:
                    st.session_state.removed_columns_backup = {}
                
                for col in cols_to_remove:
                    # Backup data
                    st.session_state.removed_columns_backup[col] = st.session_state.data[col].copy()
                    
                    # Save to config for dashboard tracking
                    st.session_state.removed_columns_config[col] = {
                        'reason': 'Bi·∫øn ƒë·ªãnh danh',
                        'unique_count': st.session_state.data[col].nunique(),
                        'applied': True
                    }
                    
                    # Remove from data
                    st.session_state.data = st.session_state.data.drop(columns=[col])
                    
                    # Also remove from train/valid/test if they exist
                    for dataset_name in ['train_data', 'valid_data', 'test_data']:
                        if dataset_name in st.session_state and st.session_state[dataset_name] is not None:
                            if col in st.session_state[dataset_name].columns:
                                st.session_state[dataset_name] = st.session_state[dataset_name].drop(columns=[col])
                
                # L∆∞u th√¥ng tin ƒë·ªÉ hi·ªÉn th·ªã sau rerun
                st.session_state._removed_cols_success = {
                    'count': len(cols_to_remove),
                    'cols': cols_to_remove
                }
                # Rerun fragment ƒë·ªÉ c·∫≠p nh·∫≠t dropdown
                st.rerun(scope="fragment")
            else:
                st.warning("Vui l√≤ng ch·ªçn √≠t nh·∫•t 1 c·ªôt")


@st.fragment
def validation_fragment(data):
    """Fragment ƒë·ªÉ x·ª≠ l√Ω validation gi√° tr·ªã - kh√¥ng g√¢y rerun to√†n trang"""
    st.markdown("##### ‚ö†Ô∏è X·ª≠ L√Ω Gi√° Tr·ªã Kh√¥ng H·ª£p L·ªá")
    
    st.markdown("""
    <div style="background-color: #262730; padding: 1rem; border-radius: 8px; margin-bottom: 1rem;">
        <p style="margin: 0; font-size: 0.9rem;">üí° <strong>V√≠ d·ª• gi√° tr·ªã v√¥ l√Ω c·∫ßn x·ª≠ l√Ω:</strong></p>
        <ul style="font-size: 0.85rem; margin: 0.5rem 0 0 1rem;">
            <li>Thu nh·∫≠p √¢m ‚Üí 0 ho·∫∑c NA</li>
            <li>Tu·ªïi < 18 ho·∫∑c > 90 ‚Üí ng∆∞·ª°ng</li>
            <li>D∆∞ n·ª£ √¢m ‚Üí 0</li>
            <li>K·ª≥ h·∫°n ‚â§ 0 ‚Üí NA ho·∫∑c min</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)
    
    # Select column to validate
    numeric_cols_validate = data.select_dtypes(include=[np.number]).columns.tolist()
    
    if numeric_cols_validate:
        selected_validate_cols = st.multiselect(
            "Ch·ªçn c√°c c·ªôt c·∫ßn x·ª≠ l√Ω (c√≥ th·ªÉ ch·ªçn nhi·ªÅu):",
            numeric_cols_validate,
            key="validate_cols_frag",
            help="Ch·ªçn m·ªôt ho·∫∑c nhi·ªÅu c·ªôt s·ªë ƒë·ªÉ √°p d·ª•ng c√πng quy t·∫Øc x·ª≠ l√Ω"
        )
        
        if len(selected_validate_cols) > 0:
            # Show summary statistics for selected columns
            st.info(f"üìä ƒê√£ ch·ªçn **{len(selected_validate_cols)}** c·ªôt: {', '.join([f'`{c}`' for c in selected_validate_cols[:3]])}{'...' if len(selected_validate_cols) > 3 else ''}")
            
            st.markdown("---")
            
            # Configure validation rule
            validation_type = st.selectbox(
                "Lo·∫°i quy t·∫Øc:",
                ["Gi√° tr·ªã √¢m", "Ng∆∞·ª°ng t·ªëi thi·ªÉu", "Ng∆∞·ª°ng t·ªëi ƒëa", "Kho·∫£ng gi√° tr·ªã"],
                key="validation_type_frag"
            )
            
            if validation_type == "Gi√° tr·ªã √¢m":
                _handle_negative_validation(data, selected_validate_cols, validation_type)
            elif validation_type == "Ng∆∞·ª°ng t·ªëi thi·ªÉu":
                _handle_min_threshold_validation(data, selected_validate_cols, validation_type)
            elif validation_type == "Ng∆∞·ª°ng t·ªëi ƒëa":
                _handle_max_threshold_validation(data, selected_validate_cols, validation_type)
            elif validation_type == "Kho·∫£ng gi√° tr·ªã":
                _handle_range_validation(data, selected_validate_cols, validation_type)
    else:
        st.info("Kh√¥ng c√≥ c·ªôt s·ªë ƒë·ªÉ x·ª≠ l√Ω")


def _handle_negative_validation(data, selected_validate_cols, validation_type):
    """X·ª≠ l√Ω gi√° tr·ªã √¢m"""
    total_invalid = sum([len(data[data[col] < 0]) for col in selected_validate_cols])
    st.info(f"üìä T·ªïng **{total_invalid}** gi√° tr·ªã √¢m trong {len(selected_validate_cols)} c·ªôt")
    
    action = st.radio(
        "H√†nh ƒë·ªông:",
        ["Chuy·ªÉn v·ªÅ 0", "Chuy·ªÉn v·ªÅ NA"],
        key="negative_action_frag"
    )
    
    if 'validation_config' not in st.session_state:
        st.session_state.validation_config = {}
    
    if st.button("‚úÖ √Åp D·ª•ng Cho T·∫•t C·∫£ C·ªôt", key="apply_negative_frag", width='stretch', type="primary"):
        # Check if train_data exists
        train_data = st.session_state.get('train_data')
        if train_data is None:
            st.error("‚ö†Ô∏è Ch∆∞a chia t·∫≠p Train/Test. Vui l√≤ng chia t·∫≠p d·ªØ li·ªáu tr∆∞·ªõc.")
            st.stop()
        
        if total_invalid > 0:
            if 'column_backups' not in st.session_state:
                st.session_state.column_backups = {}
            
            processed_cols = []
            for col in selected_validate_cols:
                invalid_count = len(data[data[col] < 0])
                if invalid_count > 0:
                    backup_key = f"validation_{col}"
                    st.session_state.column_backups[backup_key] = {
                        'data': st.session_state.data[col].copy(),
                        'train_data': train_data[col].copy() if col in train_data.columns else None,
                        'valid_data': st.session_state.valid_data[col].copy() if st.session_state.get('valid_data') is not None and col in st.session_state.valid_data.columns else None,
                        'test_data': st.session_state.test_data[col].copy() if st.session_state.get('test_data') is not None and col in st.session_state.test_data.columns else None
                    }
                    
                    # Apply to main data
                    if action == "Chuy·ªÉn v·ªÅ 0":
                        st.session_state.data.loc[st.session_state.data[col] < 0, col] = 0
                        st.session_state.train_data.loc[st.session_state.train_data[col] < 0, col] = 0
                        if st.session_state.get('valid_data') is not None:
                            st.session_state.valid_data.loc[st.session_state.valid_data[col] < 0, col] = 0
                        if st.session_state.get('test_data') is not None:
                            st.session_state.test_data.loc[st.session_state.test_data[col] < 0, col] = 0
                    else:
                        st.session_state.data.loc[st.session_state.data[col] < 0, col] = np.nan
                        st.session_state.train_data.loc[st.session_state.train_data[col] < 0, col] = np.nan
                        if st.session_state.get('valid_data') is not None:
                            st.session_state.valid_data.loc[st.session_state.valid_data[col] < 0, col] = np.nan
                        if st.session_state.get('test_data') is not None:
                            st.session_state.test_data.loc[st.session_state.test_data[col] < 0, col] = np.nan
                    
                    # Build datasets info
                    datasets_info = "Train"
                    if st.session_state.get('valid_data') is not None:
                        datasets_info += "/Valid"
                    if st.session_state.get('test_data') is not None:
                        datasets_info += "/Test"
                    
                    st.session_state.validation_config[col] = {
                        'type': validation_type,
                        'action': action,
                        'affected_count': invalid_count,
                        'applied': True,
                        'applied_to_all': True
                    }
                    processed_cols.append(col)
            
            st.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω {total_invalid} gi√° tr·ªã √¢m tr√™n {datasets_info}!")
        else:
            st.info("Kh√¥ng c√≥ gi√° tr·ªã √¢m ƒë·ªÉ x·ª≠ l√Ω trong c√°c c·ªôt ƒë√£ ch·ªçn")


def _handle_min_threshold_validation(data, selected_validate_cols, validation_type):
    """X·ª≠ l√Ω ng∆∞·ª°ng t·ªëi thi·ªÉu"""
    min_threshold = st.number_input(
        "Ng∆∞·ª°ng min (gi√° tr·ªã < ng∆∞·ª°ng s·∫Ω b·ªã x·ª≠ l√Ω):",
        value=0.0,
        key="min_threshold_frag"
    )
    
    total_invalid = sum([len(data[data[col] < min_threshold]) for col in selected_validate_cols])
    st.info(f"üìä T·ªïng **{total_invalid}** gi√° tr·ªã < {min_threshold} trong {len(selected_validate_cols)} c·ªôt")
    
    action = st.radio(
        "H√†nh ƒë·ªông:",
        [f"Chuy·ªÉn v·ªÅ {min_threshold}", "Chuy·ªÉn v·ªÅ NA"],
        key="min_action_frag"
    )
    
    if st.button("‚úÖ √Åp D·ª•ng Cho T·∫•t C·∫£ C·ªôt", key="apply_min_frag", width='stretch', type="primary"):
        if total_invalid > 0:
            if 'column_backups' not in st.session_state:
                st.session_state.column_backups = {}
            if 'validation_config' not in st.session_state:
                st.session_state.validation_config = {}
            
            processed_cols = []
            for col in selected_validate_cols:
                invalid_count = len(data[data[col] < min_threshold])
                if invalid_count > 0:
                    backup_key = f"validation_{col}"
                    st.session_state.column_backups[backup_key] = st.session_state.data[col].copy()
                    
                    if "NA" in action:
                        st.session_state.data.loc[st.session_state.data[col] < min_threshold, col] = np.nan
                    else:
                        st.session_state.data.loc[st.session_state.data[col] < min_threshold, col] = min_threshold
                    
                    st.session_state.validation_config[col] = {
                        'type': validation_type,
                        'threshold': min_threshold,
                        'action': action,
                        'affected_count': invalid_count,
                        'applied': True
                    }
                    processed_cols.append(col)
            
            st.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω {total_invalid} gi√° tr·ªã trong {len(processed_cols)} c·ªôt!")


def _handle_max_threshold_validation(data, selected_validate_cols, validation_type):
    """X·ª≠ l√Ω ng∆∞·ª°ng t·ªëi ƒëa"""
    max_threshold = st.number_input(
        "Ng∆∞·ª°ng max (gi√° tr·ªã > ng∆∞·ª°ng s·∫Ω b·ªã x·ª≠ l√Ω):",
        value=100.0,
        key="max_threshold_frag"
    )
    
    total_invalid = sum([len(data[data[col] > max_threshold]) for col in selected_validate_cols])
    st.info(f"üìä T·ªïng **{total_invalid}** gi√° tr·ªã > {max_threshold} trong {len(selected_validate_cols)} c·ªôt")
    
    action = st.radio(
        "H√†nh ƒë·ªông:",
        [f"Chuy·ªÉn v·ªÅ {max_threshold}", "Chuy·ªÉn v·ªÅ NA"],
        key="max_action_frag"
    )
    
    if st.button("‚úÖ √Åp D·ª•ng Cho T·∫•t C·∫£ C·ªôt", key="apply_max_frag", width='stretch', type="primary"):
        if total_invalid > 0:
            if 'column_backups' not in st.session_state:
                st.session_state.column_backups = {}
            if 'validation_config' not in st.session_state:
                st.session_state.validation_config = {}
            
            processed_cols = []
            for col in selected_validate_cols:
                invalid_count = len(data[data[col] > max_threshold])
                if invalid_count > 0:
                    backup_key = f"validation_{col}"
                    st.session_state.column_backups[backup_key] = st.session_state.data[col].copy()
                    
                    if "NA" in action:
                        st.session_state.data.loc[st.session_state.data[col] > max_threshold, col] = np.nan
                    else:
                        st.session_state.data.loc[st.session_state.data[col] > max_threshold, col] = max_threshold
                    
                    st.session_state.validation_config[col] = {
                        'type': validation_type,
                        'threshold': max_threshold,
                        'action': action,
                        'affected_count': invalid_count,
                        'applied': True
                    }
                    processed_cols.append(col)
            
            st.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω {total_invalid} gi√° tr·ªã trong {len(processed_cols)} c·ªôt!")


@st.fragment
def outliers_transform_fragment(data):
    """Fragment ƒë·ªÉ x·ª≠ l√Ω outliers v√† bi·∫øn ƒë·ªïi ph√¢n ph·ªëi - kh√¥ng g√¢y rerun to√†n trang"""
    
    # Hi·ªÉn th·ªã th√¥ng b√°o th√†nh c√¥ng n·∫øu c√≥
    if st.session_state.get('_outlier_success'):
        st.success(st.session_state._outlier_success)
        del st.session_state._outlier_success
    
    if st.session_state.get('_transform_success'):
        st.success(st.session_state._transform_success)
        del st.session_state._transform_success
    
    current_data = st.session_state.data
    
    # Sub-section 5.1: X·ª≠ L√Ω Outliers
    st.markdown("#### 5.1 X·ª≠ L√Ω Outliers")
    
    col_outlier1, col_outlier2 = st.columns([1, 1])
    
    with col_outlier1:
        st.markdown("##### ‚öôÔ∏è C·∫•u H√¨nh X·ª≠ L√Ω Outliers")
        
        outlier_method = st.selectbox(
            "Ph∆∞∆°ng ph√°p:",
            ["Winsorization", "IQR Method", "Z-Score", "Keep All"],
            key="outlier_method_frag",
            help="Winsorization: Thay outliers b·∫±ng ph√¢n v·ªã\nIQR: S·ª≠ d·ª•ng Interquartile Range\nZ-Score: D·ª±a tr√™n ƒë·ªô l·ªách chu·∫©n\nKeep All: Gi·ªØ nguy√™n"
        )
        
        # Show method-specific parameters
        if outlier_method == "Winsorization":
            st.markdown("**C·∫•u h√¨nh ph√¢n v·ªã:**")
            col_w1, col_w2 = st.columns(2)
            with col_w1:
                lower_percentile = st.number_input(
                    "Ph√¢n v·ªã d∆∞·ªõi:",
                    min_value=0.0,
                    max_value=0.5,
                    value=0.05,
                    step=0.01,
                    key="winsor_lower_frag"
                )
            with col_w2:
                upper_percentile = st.number_input(
                    "Ph√¢n v·ªã tr√™n:",
                    min_value=0.5,
                    max_value=1.0,
                    value=0.95,
                    step=0.01,
                    key="winsor_upper_frag"
                )
        
        elif outlier_method == "IQR Method":
            st.markdown("**C·∫•u h√¨nh IQR:**")
            col_iqr1, col_iqr2 = st.columns(2)
            with col_iqr1:
                iqr_multiplier = st.slider(
                    "H·ªá s·ªë IQR:",
                    min_value=1.0,
                    max_value=3.0,
                    value=1.5,
                    step=0.1,
                    key="iqr_multiplier_frag"
                )
            with col_iqr2:
                iqr_action = st.selectbox(
                    "H√†nh ƒë·ªông:",
                    ["clip", "remove", "nan"],
                    key="iqr_action_frag"
                )
        
        elif outlier_method == "Z-Score":
            st.markdown("**C·∫•u h√¨nh Z-Score:**")
            col_z1, col_z2 = st.columns(2)
            with col_z1:
                z_threshold = st.slider(
                    "Ng∆∞·ª°ng Z-score:",
                    min_value=2.0,
                    max_value=4.0,
                    value=3.0,
                    step=0.1,
                    key="z_threshold_frag"
                )
            with col_z2:
                z_action = st.selectbox(
                    "H√†nh ƒë·ªông:",
                    ["clip", "remove", "nan"],
                    key="z_action_frag"
                )
        
        # Select columns
        numeric_cols = current_data.select_dtypes(include=[np.number]).columns.tolist()
        if numeric_cols:
            selected_outlier_cols = st.multiselect(
                "Ch·ªçn c·ªôt ƒë·ªÉ x·ª≠ l√Ω:",
                numeric_cols,
                key="outlier_cols_frag"
            )
            
            if selected_outlier_cols and outlier_method != "Keep All":
                if st.button("‚úÖ √Åp D·ª•ng X·ª≠ L√Ω Outliers", key="apply_outlier_frag", width='stretch', type="primary"):
                    # Initialize preprocessing pipeline if not exists
                    if 'preprocessing_pipeline' not in st.session_state or st.session_state.preprocessing_pipeline is None:
                        from backend.data_processing import PreprocessingPipeline
                        st.session_state.preprocessing_pipeline = PreprocessingPipeline()
                    
                    pipeline = st.session_state.preprocessing_pipeline
                    
                    # Get train_data for fitting
                    train_data = st.session_state.get('train_data')
                    if train_data is None:
                        st.error("‚ö†Ô∏è Ch∆∞a chia t·∫≠p Train/Test. Vui l√≤ng chia t·∫≠p d·ªØ li·ªáu tr∆∞·ªõc.")
                        st.stop()
                    
                    processed = 0
                    for col in selected_outlier_cols:
                        # Backup
                        if 'outlier_backup' not in st.session_state:
                            st.session_state.outlier_backup = {}
                        st.session_state.outlier_backup[col] = {
                            'data': st.session_state.data[col].copy(),
                            'train_data': train_data[col].copy() if col in train_data.columns else None,
                            'valid_data': st.session_state.valid_data[col].copy() if st.session_state.get('valid_data') is not None and col in st.session_state.valid_data.columns else None,
                            'test_data': st.session_state.test_data[col].copy() if st.session_state.get('test_data') is not None and col in st.session_state.test_data.columns else None
                        }
                        
                        # FIT outlier bounds on train_data only
                        params = {}
                        action = 'clip'  # default
                        if outlier_method == "Winsorization":
                            params = {'lower_percentile': lower_percentile, 'upper_percentile': upper_percentile}
                        elif outlier_method == "IQR Method":
                            params = {'iqr_multiplier': iqr_multiplier}
                            action = iqr_action
                        elif outlier_method == "Z-Score":
                            params = {'z_threshold': z_threshold}
                            action = z_action
                        
                        pipeline.fit_outlier_bounds(train_data, col, outlier_method, **params)
                        
                        # TRANSFORM all datasets with the same bounds
                        # Transform main data
                        st.session_state.data = pipeline.transform_outliers(st.session_state.data, col, action)
                        
                        # Transform train_data
                        st.session_state.train_data = pipeline.transform_outliers(st.session_state.train_data, col, action)
                        
                        # Transform valid_data if exists
                        if st.session_state.get('valid_data') is not None:
                            st.session_state.valid_data = pipeline.transform_outliers(st.session_state.valid_data, col, action)
                        
                        # Transform test_data if exists
                        if st.session_state.get('test_data') is not None:
                            st.session_state.test_data = pipeline.transform_outliers(st.session_state.test_data, col, action)
                        
                        processed += 1
                    
                    # Save outlier config for dashboard
                    if 'outlier_config' not in st.session_state or 'columns' not in st.session_state.get('outlier_config', {}):
                        st.session_state.outlier_config = {'columns': [], 'details': {}}
                    
                    for col in selected_outlier_cols:
                        if col not in st.session_state.outlier_config['columns']:
                            st.session_state.outlier_config['columns'].append(col)
                        st.session_state.outlier_config['details'][col] = {
                            'method': outlier_method,
                            'action': action,
                            'applied': True,
                            'applied_to_all': True
                        }
                    
                    # Build success message
                    datasets_info = "Train"
                    if st.session_state.get('valid_data') is not None:
                        datasets_info += "/Valid"
                    if st.session_state.get('test_data') is not None:
                        datasets_info += "/Test"
                    
                    st.session_state._outlier_success = f"‚úÖ ƒê√£ x·ª≠ l√Ω outliers cho {processed} c·ªôt tr√™n {datasets_info}"
                    st.rerun(scope="fragment")
    
    with col_outlier2:
        st.markdown("##### üìä Preview Outliers")
        
        if numeric_cols:
            preview_col = st.selectbox(
                "Ch·ªçn c·ªôt ƒë·ªÉ xem:",
                numeric_cols,
                key="preview_outlier_col_frag"
            )
            
            col_data = current_data[preview_col].dropna()
            if len(col_data) > 0:
                Q1, Q3 = col_data.quantile([0.25, 0.75])
                IQR = Q3 - Q1
                lower = Q1 - 1.5 * IQR
                upper = Q3 + 1.5 * IQR
                outliers = col_data[(col_data < lower) | (col_data > upper)]
                
                col_m1, col_m2 = st.columns(2)
                with col_m1:
                    st.metric("S·ªë outliers", len(outliers))
                with col_m2:
                    st.metric("T·ª∑ l·ªá", f"{len(outliers)/len(col_data)*100:.2f}%")
                
                # Box plot
                fig = go.Figure()
                fig.add_trace(go.Box(y=col_data, name=preview_col, marker_color='#667eea'))
                fig.update_layout(
                    title=f"Box Plot - {preview_col}",
                    template="plotly_dark",
                    height=250,
                    showlegend=False
                )
                st.plotly_chart(fig, width='stretch')
    
    # Sub-section 5.2: Bi·∫øn ƒê·ªïi Ph√¢n Ph·ªëi
    st.markdown("---")
    st.markdown("#### 5.2 Bi·∫øn ƒê·ªïi Ph√¢n Ph·ªëi")
    
    st.markdown("""
    <div style="background-color: #262730; padding: 1rem; border-radius: 8px; margin-bottom: 1rem;">
        <p style="margin: 0; font-size: 0.9rem;">üí° <strong>Bi·∫øn ƒë·ªïi ph√¢n ph·ªëi</strong> gi√∫p:</p>
        <ul style="font-size: 0.85rem; margin: 0.5rem 0 0 1rem;">
            <li>Gi·∫£m ƒë·ªô l·ªách (skewness) c·ªßa d·ªØ li·ªáu</li>
            <li>L√†m cho ph√¢n ph·ªëi g·∫ßn chu·∫©n h∆°n</li>
            <li>C·∫£i thi·ªán hi·ªáu su·∫•t m√¥ h√¨nh</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)
    
    col_transform1, col_transform2 = st.columns([1, 1])
    
    with col_transform1:
        st.markdown("##### ‚öôÔ∏è C·∫•u H√¨nh Bi·∫øn ƒê·ªïi")
        
        # Show success message if transform was applied
        if st.session_state.get('_transform_success'):
            st.success(st.session_state._transform_success)
            st.session_state._transform_success = None
        
        numeric_cols_transform = current_data.select_dtypes(include=[np.number]).columns.tolist()
        
        if numeric_cols_transform:
            selected_transform_col = st.selectbox(
                "Ch·ªçn c·ªôt c·∫ßn bi·∫øn ƒë·ªïi:",
                numeric_cols_transform,
                key="transform_col_frag"
            )
            
            col_data_transform = current_data[selected_transform_col].dropna()
            if len(col_data_transform) > 0:
                skewness = col_data_transform.skew()
                
                stat_t1, stat_t2 = st.columns(2)
                with stat_t1:
                    st.metric("Skewness", f"{skewness:.3f}")
                with stat_t2:
                    if abs(skewness) < 0.5:
                        st.success("‚úÖ G·∫ßn chu·∫©n")
                    elif abs(skewness) < 1.0:
                        st.warning("‚ö†Ô∏è L·ªách v·ª´a")
                    else:
                        st.error("‚ùå L·ªách m·∫°nh")
                
                st.markdown("---")
                
                transform_method = st.selectbox(
                    "Ph∆∞∆°ng ph√°p bi·∫øn ƒë·ªïi:",
                    ["Log (logarithm)", "Log1p (log(1+x))", "Sqrt (square root)", 
                     "Cbrt (cube root)", "Box-Cox", "Yeo-Johnson", "Reciprocal (1/x)", "Square (x¬≤)"],
                    key="transform_method_frag"
                )
                
                method_desc = {
                    "Log (logarithm)": "Gi·∫£m skew d∆∞∆°ng, y√™u c·∫ßu gi√° tr·ªã > 0",
                    "Log1p (log(1+x))": "Nh∆∞ Log nh∆∞ng x·ª≠ l√Ω ƒë∆∞·ª£c gi√° tr·ªã 0",
                    "Sqrt (square root)": "Gi·∫£m skew d∆∞∆°ng nh·∫π h∆°n Log",
                    "Cbrt (cube root)": "Gi·∫£m skew d∆∞∆°ng, x·ª≠ l√Ω ƒë∆∞·ª£c gi√° tr·ªã √¢m",
                    "Box-Cox": "T·ª± ƒë·ªông t√¨m Œª t·ªëi ∆∞u, y√™u c·∫ßu gi√° tr·ªã > 0",
                    "Yeo-Johnson": "Nh∆∞ Box-Cox nh∆∞ng x·ª≠ l√Ω ƒë∆∞·ª£c gi√° tr·ªã √¢m",
                    "Reciprocal (1/x)": "Cho ph√¢n ph·ªëi l·ªách ph·∫£i m·∫°nh",
                    "Square (x¬≤)": "TƒÉng skew (√≠t d√πng)"
                }
                st.info(f"üìù {method_desc.get(transform_method, '')}")
                
                # Check applicability
                can_apply = True
                if transform_method == "Log (logarithm)" and (col_data_transform <= 0).any():
                    can_apply = False
                    st.warning("‚ö†Ô∏è Log y√™u c·∫ßu t·∫•t c·∫£ gi√° tr·ªã > 0")
                elif transform_method == "Box-Cox" and (col_data_transform <= 0).any():
                    can_apply = False
                    st.warning("‚ö†Ô∏è Box-Cox y√™u c·∫ßu t·∫•t c·∫£ gi√° tr·ªã > 0")
                elif transform_method == "Reciprocal (1/x)" and (col_data_transform == 0).any():
                    can_apply = False
                    st.warning("‚ö†Ô∏è Reciprocal kh√¥ng x·ª≠ l√Ω ƒë∆∞·ª£c gi√° tr·ªã 0")
                
                if st.button("‚úÖ √Åp D·ª•ng Bi·∫øn ƒê·ªïi", key="apply_transform_frag", width='stretch', type="primary", disabled=not can_apply):
                    # Check if train_data exists
                    train_data = st.session_state.get('train_data')
                    if train_data is None:
                        st.error("‚ö†Ô∏è Ch∆∞a chia t·∫≠p Train/Test. Vui l√≤ng chia t·∫≠p d·ªØ li·ªáu tr∆∞·ªõc.")
                        st.stop()
                    
                    # Backup
                    if 'transform_backup' not in st.session_state:
                        st.session_state.transform_backup = {}
                    st.session_state.transform_backup[selected_transform_col] = {
                        'data': st.session_state.data[selected_transform_col].copy(),
                        'train_data': train_data[selected_transform_col].copy() if selected_transform_col in train_data.columns else None,
                        'valid_data': st.session_state.valid_data[selected_transform_col].copy() if st.session_state.get('valid_data') is not None and selected_transform_col in st.session_state.valid_data.columns else None,
                        'test_data': st.session_state.test_data[selected_transform_col].copy() if st.session_state.get('test_data') is not None and selected_transform_col in st.session_state.test_data.columns else None
                    }
                    
                    # Helper function to apply transformation
                    def apply_transform(series, method):
                        if method == "Log (logarithm)":
                            return np.log(series)
                        elif method == "Log1p (log(1+x))":
                            return np.log1p(series)
                        elif method == "Sqrt (square root)":
                            return np.sqrt(np.abs(series))
                        elif method == "Cbrt (cube root)":
                            return np.cbrt(series)
                        elif method == "Reciprocal (1/x)":
                            return 1 / series
                        elif method == "Square (x¬≤)":
                            return np.square(series)
                        return series
                    
                    # Apply transformation to all datasets
                    if transform_method in ["Box-Cox", "Yeo-Johnson"]:
                        from scipy import stats
                        if transform_method == "Box-Cox":
                            transformed, _ = stats.boxcox(st.session_state.data[selected_transform_col].dropna())
                            st.session_state.data.loc[st.session_state.data[selected_transform_col].notna(), selected_transform_col] = transformed
                            transformed_train, _ = stats.boxcox(train_data[selected_transform_col].dropna())
                            st.session_state.train_data.loc[st.session_state.train_data[selected_transform_col].notna(), selected_transform_col] = transformed_train
                            if st.session_state.get('valid_data') is not None:
                                transformed_valid, _ = stats.boxcox(st.session_state.valid_data[selected_transform_col].dropna())
                                st.session_state.valid_data.loc[st.session_state.valid_data[selected_transform_col].notna(), selected_transform_col] = transformed_valid
                            if st.session_state.get('test_data') is not None:
                                transformed_test, _ = stats.boxcox(st.session_state.test_data[selected_transform_col].dropna())
                                st.session_state.test_data.loc[st.session_state.test_data[selected_transform_col].notna(), selected_transform_col] = transformed_test
                        else:  # Yeo-Johnson
                            transformed, _ = stats.yeojohnson(st.session_state.data[selected_transform_col].dropna())
                            st.session_state.data.loc[st.session_state.data[selected_transform_col].notna(), selected_transform_col] = transformed
                            transformed_train, _ = stats.yeojohnson(train_data[selected_transform_col].dropna())
                            st.session_state.train_data.loc[st.session_state.train_data[selected_transform_col].notna(), selected_transform_col] = transformed_train
                            if st.session_state.get('valid_data') is not None:
                                transformed_valid, _ = stats.yeojohnson(st.session_state.valid_data[selected_transform_col].dropna())
                                st.session_state.valid_data.loc[st.session_state.valid_data[selected_transform_col].notna(), selected_transform_col] = transformed_valid
                            if st.session_state.get('test_data') is not None:
                                transformed_test, _ = stats.yeojohnson(st.session_state.test_data[selected_transform_col].dropna())
                                st.session_state.test_data.loc[st.session_state.test_data[selected_transform_col].notna(), selected_transform_col] = transformed_test
                    else:
                        st.session_state.data[selected_transform_col] = apply_transform(st.session_state.data[selected_transform_col], transform_method)
                        st.session_state.train_data[selected_transform_col] = apply_transform(st.session_state.train_data[selected_transform_col], transform_method)
                        if st.session_state.get('valid_data') is not None:
                            st.session_state.valid_data[selected_transform_col] = apply_transform(st.session_state.valid_data[selected_transform_col], transform_method)
                        if st.session_state.get('test_data') is not None:
                            st.session_state.test_data[selected_transform_col] = apply_transform(st.session_state.test_data[selected_transform_col], transform_method)
                    
                    # Save transform config for dashboard
                    if 'transform_config' not in st.session_state or not isinstance(st.session_state.transform_config, dict):
                        st.session_state.transform_config = {}
                    
                    st.session_state.transform_config[selected_transform_col] = {
                        'method': transform_method,
                        'applied': True,
                        'applied_to_all': True
                    }
                    
                    # Build success message
                    datasets_info = "Train"
                    if st.session_state.get('valid_data') is not None:
                        datasets_info += "/Valid"
                    if st.session_state.get('test_data') is not None:
                        datasets_info += "/Test"
                    
                    success_msg = f"ƒê√£ √°p d·ª•ng {transform_method} cho '{selected_transform_col}' tr√™n {datasets_info}"
                    
                    # Show inline success message
                    st.success(f"‚úÖ {success_msg}")
                    
                    # Calculate new skewness for display
                    new_skewness = st.session_state.data[selected_transform_col].skew()
                    st.info(f"üìä Skewness m·ªõi: **{new_skewness:.3f}**")
    
    with col_transform2:
        st.markdown("##### üìä Tr·ª±c Quan H√≥a Ph√¢n Ph·ªëi")
        
        if numeric_cols_transform:
            viz_col = st.selectbox(
                "Ch·ªçn c·ªôt ƒë·ªÉ xem ph√¢n ph·ªëi:",
                numeric_cols_transform,
                key="viz_transform_col_frag"
            )
            
            col_data_viz = current_data[viz_col].dropna()
            
            if len(col_data_viz) > 0:
                fig = go.Figure()
                fig.add_trace(go.Histogram(
                    x=col_data_viz,
                    name='Distribution',
                    marker_color='#667eea',
                    opacity=0.7,
                    nbinsx=30
                ))
                fig.update_layout(
                    title=f"Ph√¢n ph·ªëi - {viz_col}",
                    xaxis_title="Gi√° tr·ªã",
                    yaxis_title="T·∫ßn su·∫•t",
                    template="plotly_dark",
                    height=300,
                    showlegend=False
                )
                st.plotly_chart(fig, width='stretch')
                
                # Statistics
                st.markdown("##### üìà Th·ªëng K√™")
                stats_df = pd.DataFrame({
                    'Th·ªëng k√™': ['Mean', 'Median', 'Std', 'Min', 'Max', 'Skewness'],
                    'Gi√° tr·ªã': [
                        f"{col_data_viz.mean():.2f}",
                        f"{col_data_viz.median():.2f}",
                        f"{col_data_viz.std():.2f}",
                        f"{col_data_viz.min():.2f}",
                        f"{col_data_viz.max():.2f}",
                        f"{col_data_viz.skew():.3f}"
                    ]
                })
                st.dataframe(stats_df, width='stretch', hide_index=True)


@st.fragment
def missing_values_fragment(data, missing_data):
    """Fragment ƒë·ªÉ x·ª≠ l√Ω gi√° tr·ªã thi·∫øu - kh√¥ng g√¢y rerun to√†n trang"""
    
    # Hi·ªÉn th·ªã th√¥ng b√°o th√†nh c√¥ng n·∫øu c√≥
    if st.session_state.get('_missing_success'):
        st.success(st.session_state._missing_success)
        del st.session_state._missing_success
    
    # Show rows with missing data section
    if len(missing_data) > 0:
        st.markdown("##### üìã Xem B·∫£n Ghi C√≥ D·ªØ Li·ªáu Thi·∫øu")
        
        current_data = st.session_state.data
        # Get rows with any missing values
        rows_with_missing = current_data[current_data.isnull().any(axis=1)]
        
        col_preview1, col_preview2 = st.columns([3, 2])
        with col_preview1:
            st.metric("S·ªë d√≤ng c√≥ missing", len(rows_with_missing), 
                     f"{len(rows_with_missing)/len(current_data)*100:.1f}% t·ªïng s·ªë")
        with col_preview2:
            show_missing_rows = st.checkbox("Hi·ªÉn th·ªã c√°c d√≤ng", value=True, key="show_missing_rows_frag")
        
        if show_missing_rows:
            # Filter options - select column to prioritize
            missing_cols_list = [col for col in current_data.columns if current_data[col].isnull().sum() > 0]
            selected_col_filter = st.selectbox(
                "∆Øu ti√™n hi·ªÉn th·ªã c·ªôt thi·∫øu:",
                ["T·∫•t c·∫£"] + missing_cols_list,
                key="missing_col_filter_frag",
                help="Ch·ªçn c·ªôt ƒë·ªÉ ∆∞u ti√™n s·∫Øp x·∫øp c√°c d√≤ng thi·∫øu d·ªØ li·ªáu ·ªü c·ªôt ƒë√≥ l√™n tr√™n."
            )
            
            # Sort data to prioritize rows with missing data in selected column
            if selected_col_filter != "T·∫•t c·∫£" and selected_col_filter in rows_with_missing.columns:
                rows_display = rows_with_missing.copy()
                rows_display['_priority'] = rows_display[selected_col_filter].isnull().astype(int)
                rows_display = rows_display.sort_values('_priority', ascending=False)
                display_data = rows_display.drop('_priority', axis=1)
                
                missing_in_selected = rows_with_missing[selected_col_filter].isnull().sum()
                st.info(f"üéØ ∆Øu ti√™n: {missing_in_selected} d√≤ng thi·∫øu d·ªØ li·ªáu ·ªü `{selected_col_filter}` ƒë∆∞·ª£c s·∫Øp x·∫øp l√™n tr√™n.")
            else:
                display_data = rows_with_missing
            
            # Highlight missing values
            def highlight_selected_col_missing(row):
                styles = [''] * len(row)
                for idx, (col_name, val) in enumerate(row.items()):
                    if pd.isnull(val):
                        if selected_col_filter != "T·∫•t c·∫£" and col_name == selected_col_filter:
                            styles[idx] = 'background-color: #ff3333; color: white; font-weight: bold;'
                        else:
                            styles[idx] = 'background-color: #ff6b6b; color: white;'
                return styles
            
            st.dataframe(
                display_data.style.apply(highlight_selected_col_missing, axis=1),
                width='stretch',
                height=400
            )
        
        st.markdown("---")
        st.markdown("##### ‚öôÔ∏è C·∫•u H√¨nh X·ª≠ L√Ω Nhi·ªÅu C·ªôt C√πng L√∫c")
        
        # Get current missing columns
        current_missing_cols = [col for col in current_data.columns if current_data[col].isnull().sum() > 0]
        
        # Select columns to configure
        selected_missing_cols = st.multiselect(
            "Ch·ªçn c√°c c·ªôt c·∫ßn x·ª≠ l√Ω (c√≥ th·ªÉ ch·ªçn nhi·ªÅu):",
            current_missing_cols,
            key="selected_missing_cols_frag",
            help="Ch·ªçn m·ªôt ho·∫∑c nhi·ªÅu c·ªôt ƒë·ªÉ √°p d·ª•ng c√πng ph∆∞∆°ng ph√°p x·ª≠ l√Ω missing"
        )
        
        if len(selected_missing_cols) > 0:
            # Show summary info
            total_missing = sum([current_data[col].isnull().sum() for col in selected_missing_cols])
            st.info(f"üìä ƒê√£ ch·ªçn **{len(selected_missing_cols)}** c·ªôt | T·ªïng missing: **{total_missing}** gi√° tr·ªã")
            
            # Method selection
            method_options = [
                "Mean Imputation",
                "Median Imputation",
                "Mode Imputation",
                "Forward Fill",
                "Backward Fill",
                "Interpolation",
                "Constant Value",
                "Drop Rows"
            ]
            
            selected_method = st.selectbox(
                "Ph∆∞∆°ng ph√°p x·ª≠ l√Ω:",
                method_options,
                key="method_all_missing_frag"
            )
            
            # Constant value input if needed
            constant_val = None
            if selected_method == "Constant Value":
                constant_val = st.text_input(
                    "Gi√° tr·ªã ƒëi·ªÅn:",
                    value="0",
                    key="const_all_missing_frag"
                )
            
            # Initialize session state
            if 'missing_config' not in st.session_state:
                st.session_state.missing_config = {}
            if 'column_backups' not in st.session_state:
                st.session_state.column_backups = {}
            
            # Process button
            if st.button("‚úÖ X·ª≠ L√Ω T·∫•t C·∫£ C·ªôt ƒê√£ Ch·ªçn", key="add_config_all_missing_frag", width='stretch', type="primary"):
                processed_count = 0
                total_filled = 0
                
                # Initialize preprocessing pipeline if not exists
                if 'preprocessing_pipeline' not in st.session_state or st.session_state.preprocessing_pipeline is None:
                    from backend.data_processing import PreprocessingPipeline
                    st.session_state.preprocessing_pipeline = PreprocessingPipeline()
                
                pipeline = st.session_state.preprocessing_pipeline
                
                # Get train_data for fitting
                train_data = st.session_state.get('train_data')
                if train_data is None:
                    st.error("‚ö†Ô∏è Ch∆∞a chia t·∫≠p Train/Test. Vui l√≤ng chia t·∫≠p d·ªØ li·ªáu tr∆∞·ªõc.")
                    st.stop()
                
                for col in selected_missing_cols:
                    missing_count = current_data[col].isnull().sum()
                    
                    # BACKUP current state
                    st.session_state.column_backups[col] = {
                        'data': st.session_state.data[col].copy(),
                        'full_data': st.session_state.data.copy(),
                        'train_data': train_data[col].copy() if col in train_data.columns else None,
                        'valid_data': st.session_state.get('valid_data', pd.DataFrame())[col].copy() if st.session_state.get('valid_data') is not None and col in st.session_state.valid_data.columns else None,
                        'test_data': st.session_state.get('test_data', pd.DataFrame())[col].copy() if st.session_state.get('test_data') is not None and col in st.session_state.test_data.columns else None
                    }
                    
                    # FIT on train_data only
                    constant_value = None
                    if selected_method == "Constant Value":
                        constant_value = constant_val
                        if pd.api.types.is_numeric_dtype(train_data[col]):
                            try:
                                constant_value = float(constant_val) if '.' in str(constant_val) else int(constant_val)
                            except:
                                pass
                    
                    pipeline.fit_imputer(train_data, col, selected_method, constant_value)
                    
                    # TRANSFORM all datasets
                    # Transform main data
                    st.session_state.data = pipeline.transform_imputation(st.session_state.data, col)
                    
                    # Transform train_data
                    st.session_state.train_data = pipeline.transform_imputation(st.session_state.train_data, col)
                    
                    # Transform valid_data if exists
                    if st.session_state.get('valid_data') is not None:
                        st.session_state.valid_data = pipeline.transform_imputation(st.session_state.valid_data, col)
                    
                    # Transform test_data if exists
                    if st.session_state.get('test_data') is not None:
                        st.session_state.test_data = pipeline.transform_imputation(st.session_state.test_data, col)
                    
                    total_filled += missing_count
                    processed_count += 1
                    
                    # Save config with fill_value info
                    imputer_info = pipeline.imputers.get(col, {})
                    st.session_state.missing_config[col] = {
                        'method': selected_method,
                        'original_missing': missing_count,
                        'fill_value': imputer_info.get('fill_value'),
                        'processed': True,
                        'can_undo': True,
                        'applied_to_all': True  # Mark that it was applied to all datasets
                    }
                    if selected_method == "Constant Value":
                        st.session_state.missing_config[col]['constant'] = constant_val
                
                # Show success message with info about all datasets
                datasets_info = "Train"
                if st.session_state.get('valid_data') is not None:
                    datasets_info += "/Valid"
                if st.session_state.get('test_data') is not None:
                    datasets_info += "/Test"
                
                st.session_state._missing_success = f"‚úÖ ƒê√£ x·ª≠ l√Ω {processed_count} c·ªôt ({total_filled} gi√° tr·ªã) tr√™n {datasets_info}"
                st.rerun(scope="fragment")
        else:
            st.info("üí° Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt c·ªôt ƒë·ªÉ x·ª≠ l√Ω missing values")
        
        # Show processing history
        if st.session_state.get('missing_config'):
            st.markdown("---")
            st.markdown("##### üìã L·ªãch S·ª≠ X·ª≠ L√Ω")
            
            config_df = pd.DataFrame([
                {
                    'C·ªôt': col,
                    'Ph∆∞∆°ng ph√°p': cfg['method'],
                    'Missing ban ƒë·∫ßu': f"{cfg['original_missing']}",
                    'Gi√° tr·ªã ƒëi·ªÅn': cfg.get('constant', '-'),
                    'Tr·∫°ng th√°i': '‚úÖ ƒê√£ x·ª≠ l√Ω'
                }
                for col, cfg in st.session_state.missing_config.items()
            ])
            
            st.dataframe(config_df, width='stretch', hide_index=True)
            
            # Undo specific column
            st.markdown("**Ho√†n t√°c t·ª´ng c·ªôt:**")
            col_undo1, col_undo2 = st.columns([3, 1])
            with col_undo1:
                col_to_undo = st.selectbox("Ch·ªçn c·ªôt ƒë·ªÉ ho√†n t√°c:", list(st.session_state.missing_config.keys()), key="col_undo_select_frag")
            with col_undo2:
                if st.button("üîÑ Ho√†n T√°c", key="undo_missing_btn_frag"):
                    if col_to_undo in st.session_state.column_backups:
                        backup = st.session_state.column_backups[col_to_undo]
                        config = st.session_state.missing_config[col_to_undo]
                        
                        if config['method'] == "Drop Rows":
                            st.session_state.data = backup['full_data'].copy()
                        else:
                            st.session_state.data[col_to_undo] = backup['data'].copy()
                        
                        del st.session_state.missing_config[col_to_undo]
                        del st.session_state.column_backups[col_to_undo]
                        
                        st.session_state._missing_success = f"‚úÖ ƒê√£ ho√†n t√°c c·ªôt `{col_to_undo}`"
                        st.rerun(scope="fragment")
                    else:
                        st.error("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y backup")
    else:
        st.success("‚úÖ Kh√¥ng c√≥ gi√° tr·ªã thi·∫øu trong dataset!")


@st.fragment
def split_data_fragment(data):
    """Fragment ƒë·ªÉ chia t·∫≠p Train/Valid/Test - kh√¥ng g√¢y rerun to√†n trang"""
    
    col_split1, col_split2 = st.columns([1, 1])
    
    with col_split1:
        st.markdown("##### üìä C·∫•u H√¨nh Chia T·∫≠p")
        
        # Check if target column exists
        target_col = st.session_state.get('target_column')
        current_data = st.session_state.data
        
        if target_col:
            # Show target with undo button
            target_col1, target_col2 = st.columns([3, 1])
            with target_col1:
                st.success(f"üéØ C·ªôt target: `{target_col}`")
            with target_col2:
                if st.button("‚Ü©Ô∏è B·ªè ch·ªçn", key="undo_target_selection_frag", help="B·ªè ch·ªçn c·ªôt target", width='stretch'):
                    st.session_state.target_column = None
                    st.session_state._split_success = "‚úÖ ƒê√£ b·ªè ch·ªçn target"
                    st.rerun(scope="fragment")
        else:
            target_col = st.selectbox(
                "Ch·ªçn c·ªôt target:",
                options=current_data.columns.tolist(),
                key="temp_target_select_frag"
            )
            if st.button("üíæ L∆∞u Target", key="save_temp_target_frag", width='stretch'):
                st.session_state.target_column = target_col
                st.session_state._split_success = f"‚úÖ ƒê√£ l∆∞u target: `{target_col}`"
                st.rerun(scope="fragment")
        
        # Get current target
        target_col = st.session_state.get('target_column')
        
        # Split configuration
        split_col1, split_col2 = st.columns(2)
        
        with split_col1:
            train_ratio = st.slider(
                "T·ª∑ l·ªá Train (%):",
                min_value=50,
                max_value=90,
                value=70,
                step=5,
                key="train_ratio_frag",
                help="Ph·∫ßn trƒÉm d·ªØ li·ªáu d√πng ƒë·ªÉ training"
            )
        
        with split_col2:
            valid_ratio = st.slider(
                "T·ª∑ l·ªá Valid (%):",
                min_value=5,
                max_value=30,
                value=15,
                step=5,
                key="valid_ratio_frag",
                help="Ph·∫ßn trƒÉm d·ªØ li·ªáu d√πng ƒë·ªÉ validation"
            )
        
        test_ratio = 100 - train_ratio - valid_ratio
        
        if test_ratio < 0:
            st.error("‚ùå T·ªïng t·ª∑ l·ªá Train + Valid ph·∫£i ‚â§ 100%")
        else:
            st.info(f"üìà T·ª∑ l·ªá chia: **Train {train_ratio}%** | **Valid {valid_ratio}%** | **Test {test_ratio}%**")
        
        # Stratify option for classification
        stratify = False
        if target_col and target_col in current_data.columns:
            if current_data[target_col].nunique() <= 20:  # Likely classification
                stratify = st.checkbox(
                    "üéØ Stratify (gi·ªØ t·ª∑ l·ªá target)",
                    value=True,
                    help="Gi·ªØ t·ª∑ l·ªá c√°c class trong target gi·ªëng nhau ·ªü train/valid/test",
                    key="stratify_split_frag"
                )
            else:
                st.info("üìä Regression task - kh√¥ng c·∫ßn stratify")
        
        # Random seed
        random_seed = st.number_input(
            "Random Seed:",
            min_value=0,
            max_value=9999,
            value=42,
            key="split_seed_frag",
            help="Seed ƒë·ªÉ t√°i t·∫°o k·∫øt qu·∫£"
        )
        
        # Split button
        if st.button("‚úÇÔ∏è Chia T·∫≠p D·ªØ Li·ªáu", type="primary", width='stretch', key="split_data_btn_frag"):
            if test_ratio >= 0 and target_col and target_col in current_data.columns:
                try:
                    from sklearn.model_selection import train_test_split
                    
                    # Separate features and target
                    X = current_data.drop(columns=[target_col])
                    y = current_data[target_col]
                    
                    # First split: train vs (valid + test)
                    if stratify and (y.dtype in ['object', 'category'] or (y.dtype in ['int64', 'int32'] and y.nunique() <= 20)):
                        X_train, X_temp, y_train, y_temp = train_test_split(
                            X, y, 
                            test_size=(100 - train_ratio) / 100,
                            random_state=random_seed,
                            stratify=y
                        )
                    else:
                        X_train, X_temp, y_train, y_temp = train_test_split(
                            X, y,
                            test_size=(100 - train_ratio) / 100,
                            random_state=random_seed
                        )
                    
                    # Second split: valid vs test
                    if valid_ratio > 0:
                        valid_size_relative = valid_ratio / (100 - train_ratio)
                        
                        if stratify and (y_temp.dtype in ['object', 'category'] or (y_temp.dtype in ['int64', 'int32'] and y_temp.nunique() <= 20)):
                            X_valid, X_test, y_valid, y_test = train_test_split(
                                X_temp, y_temp,
                                test_size=1 - valid_size_relative,
                                random_state=random_seed,
                                stratify=y_temp
                            )
                        else:
                            X_valid, X_test, y_valid, y_test = train_test_split(
                                X_temp, y_temp,
                                test_size=1 - valid_size_relative,
                                random_state=random_seed
                            )
                    else:
                        X_valid, y_valid = None, None
                        X_test, y_test = X_temp, y_temp
                    
                    # Combine back
                    train_data = pd.concat([X_train, y_train], axis=1)
                    valid_data = pd.concat([X_valid, y_valid], axis=1) if X_valid is not None else None
                    test_data = pd.concat([X_test, y_test], axis=1)
                    
                    # Save to session state
                    st.session_state.train_data = train_data
                    st.session_state.valid_data = valid_data
                    st.session_state.test_data = test_data
                    st.session_state.split_config = {
                        'train_ratio': train_ratio,
                        'valid_ratio': valid_ratio,
                        'test_ratio': test_ratio,
                        'stratify': stratify,
                        'random_seed': random_seed,
                        'target_column': target_col
                    }
                    
                    # Update main data to train data for processing
                    st.session_state.data = train_data.copy()
                    
                    st.session_state._split_success = f"‚úÖ ƒê√£ chia t·∫≠p: Train {len(train_data):,} | Valid {len(valid_data) if valid_data is not None else 0:,} | Test {len(test_data):,}"
                    st.rerun(scope="fragment")
                
                except Exception as e:
                    st.error(f"‚ùå L·ªói khi chia d·ªØ li·ªáu: {str(e)}")
            else:
                st.warning("‚ö†Ô∏è Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh v√† target column")
    
    with col_split2:
        st.markdown("##### üìà Tr·∫°ng Th√°i Chia T·∫≠p")
        
        # Hi·ªÉn th·ªã th√¥ng b√°o reset n·∫øu c√≥
        if st.session_state.get('_reset_split_success'):
            st.success(st.session_state._reset_split_success)
            del st.session_state._reset_split_success
        
        if 'train_data' in st.session_state and st.session_state.train_data is not None:
            train_size = len(st.session_state.train_data)
            valid_size = len(st.session_state.valid_data) if st.session_state.get('valid_data') is not None else 0
            test_size = len(st.session_state.test_data) if st.session_state.get('test_data') is not None else 0
            total_size = train_size + valid_size + test_size
            
            st.markdown(f"""
            <div style="background-color: #1a472a; padding: 1rem; border-radius: 8px; border-left: 4px solid #10b981; margin-bottom: 1rem;">
                <p style="margin: 0; font-weight: bold; color: #10b981;">‚úÖ ƒê√£ Chia T·∫≠p</p>
                <p style="margin: 0.5rem 0 0 0; font-size: 0.9rem;">
                    <strong>T·ªïng:</strong> {total_size:,} d√≤ng<br>
                    <strong>Train:</strong> {train_size:,} d√≤ng ({train_size/total_size*100:.1f}%)<br>
                    <strong>Valid:</strong> {valid_size:,} d√≤ng ({valid_size/total_size*100:.1f}%)<br>
                    <strong>Test:</strong> {test_size:,} d√≤ng ({test_size/total_size*100:.1f}%)
                </p>
            </div>
            """, unsafe_allow_html=True)
            
            # Show split config
            if 'split_config' in st.session_state:
                cfg = st.session_state.split_config
                st.markdown("**C·∫•u h√¨nh:**")
                st.json({
                    'Target': cfg['target_column'],
                    'Stratify': cfg['stratify'],
                    'Random Seed': cfg['random_seed']
                })
            
            # Current working dataset
            st.markdown("---")
            st.info(f"üìä **Dataset hi·ªán t·∫°i:** Train ({train_size:,} d√≤ng)")
            st.caption("üí° C√°c b∆∞·ªõc x·ª≠ l√Ω s·∫Ω ƒë∆∞·ª£c √°p d·ª•ng tr√™n Train, sau ƒë√≥ transform cho Valid/Test")
        
        else:
            current_data = st.session_state.data
            st.markdown(f"""
            <div style="background-color: #3a3a1a; padding: 1rem; border-radius: 8px; border-left: 4px solid #fbbf24; margin-bottom: 1rem;">
                <p style="margin: 0; font-weight: bold; color: #fbbf24;">‚è≥ Ch∆∞a Chia T·∫≠p</p>
                <p style="margin: 0.5rem 0 0 0; font-size: 0.9rem;">
                    D·ªØ li·ªáu hi·ªán t·∫°i: <strong>{len(current_data):,}</strong> d√≤ng<br>
                    H√£y c·∫•u h√¨nh v√† chia t·∫≠p ·ªü b√™n tr√°i
                </p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div style="background-color: #262730; padding: 1rem; border-radius: 8px; margin-top: 1rem;">
                <p style="margin: 0; font-size: 0.9rem;"><strong>üìö L·ª£i √≠ch c·ªßa vi·ªác chia t·∫≠p:</strong></p>
                <ul style="font-size: 0.85rem; margin: 0.5rem 0 0 1rem;">
                    <li><strong>Train:</strong> D√πng ƒë·ªÉ fit model v√† t√≠nh statistics</li>
                    <li><strong>Valid:</strong> ƒê√°nh gi√° model trong qu√° tr√¨nh training</li>
                    <li><strong>Test:</strong> ƒê√°nh gi√° cu·ªëi c√πng, d·ªØ li·ªáu ch∆∞a th·∫•y</li>
                    <li><strong>Tr√°nh overfitting:</strong> Model kh√¥ng th·∫•y valid/test trong training</li>
                    <li><strong>Tr√°nh data leakage:</strong> Statistics t·ª´ train, kh√¥ng t·ª´ to√†n b·ªô data</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)


def _handle_range_validation(data, selected_validate_cols, validation_type):
    """X·ª≠ l√Ω kho·∫£ng gi√° tr·ªã"""
    col_range1, col_range2 = st.columns(2)
    with col_range1:
        range_min = st.number_input("Gi√° tr·ªã min:", value=0.0, key="range_min_frag")
    with col_range2:
        range_max = st.number_input("Gi√° tr·ªã max:", value=100.0, key="range_max_frag")
    
    total_invalid = sum([
        len(data[(data[col] < range_min) | (data[col] > range_max)]) 
        for col in selected_validate_cols
    ])
    st.info(f"üìä T·ªïng **{total_invalid}** gi√° tr·ªã ngo√†i kho·∫£ng [{range_min}, {range_max}]")
    
    action = st.radio(
        "H√†nh ƒë·ªông:",
        ["Clip v·ªÅ bi√™n", "Chuy·ªÉn v·ªÅ NA"],
        key="range_action_frag"
    )
    
    if st.button("‚úÖ √Åp D·ª•ng Cho T·∫•t C·∫£ C·ªôt", key="apply_range_frag", width='stretch', type="primary"):
        if total_invalid > 0:
            if 'column_backups' not in st.session_state:
                st.session_state.column_backups = {}
            if 'validation_config' not in st.session_state:
                st.session_state.validation_config = {}
            
            processed_cols = []
            for col in selected_validate_cols:
                invalid_count = len(data[(data[col] < range_min) | (data[col] > range_max)])
                if invalid_count > 0:
                    backup_key = f"validation_{col}"
                    st.session_state.column_backups[backup_key] = st.session_state.data[col].copy()
                    
                    if action == "Clip v·ªÅ bi√™n":
                        st.session_state.data[col] = st.session_state.data[col].clip(range_min, range_max)
                    else:
                        mask = (st.session_state.data[col] < range_min) | (st.session_state.data[col] > range_max)
                        st.session_state.data.loc[mask, col] = np.nan
                    
                    st.session_state.validation_config[col] = {
                        'type': validation_type,
                        'range_min': range_min,
                        'range_max': range_max,
                        'action': action,
                        'affected_count': invalid_count,
                        'applied': True
                    }
                    processed_cols.append(col)
            
            st.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω {total_invalid} gi√° tr·ªã trong {len(processed_cols)} c·ªôt!")


@st.fragment
def encoding_fragment(data):
    """Fragment ƒë·ªÉ m√£ h√≥a bi·∫øn ph√¢n lo·∫°i - kh√¥ng g√¢y rerun to√†n trang"""
    
    # Hi·ªÉn th·ªã th√¥ng b√°o th√†nh c√¥ng n·∫øu c√≥
    if st.session_state.get('_encoding_success'):
        info = st.session_state._encoding_success
        st.success(f"‚úÖ ƒê√£ m√£ h√≥a `{info['col']}` b·∫±ng {info['method']}!")
        if info.get('new_cols'):
            st.info(f"üìä ƒê√£ t·∫°o {info['new_cols']} c·ªôt m·ªõi")
        del st.session_state._encoding_success
    
    if st.session_state.get('_encoding_undo_success'):
        st.success(st.session_state._encoding_undo_success)
        del st.session_state._encoding_undo_success
    
    current_data = st.session_state.data
    categorical_cols = current_data.select_dtypes(include=['object', 'category']).columns.tolist()
    
    if categorical_cols:
        st.warning(f"‚ö†Ô∏è C√≥ {len(categorical_cols)} bi·∫øn ph√¢n lo·∫°i c·∫ßn m√£ h√≥a")
        
        # Show categorical columns summary
        col_enc1, col_enc2 = st.columns([1, 1])
        
        with col_enc1:
            st.markdown("##### üìã Danh S√°ch Bi·∫øn Ph√¢n Lo·∫°i")
            
            cat_summary = []
            for col in categorical_cols:
                unique_vals = current_data[col].nunique()
                cat_summary.append({
                    'C·ªôt': col,
                    'S·ªë gi√° tr·ªã kh√°c nhau': unique_vals,
                    'Gi√° tr·ªã ph·ªï bi·∫øn': current_data[col].mode()[0] if not current_data[col].mode().empty else 'N/A'
                })
            
            cat_df = pd.DataFrame(cat_summary)
            st.dataframe(cat_df, width='stretch', hide_index=True)
        
        with col_enc2:
            st.markdown("##### ‚öôÔ∏è C·∫•u H√¨nh M√£ H√≥a T·ª´ng C·ªôt")
            
            # Filter out already encoded (applied) columns
            encoded_cols = [col for col, cfg in st.session_state.get('encoding_config', {}).items() 
                           if cfg.get('applied', False)]
            remaining_categorical_cols = [col for col in categorical_cols if col not in encoded_cols]
            
            if not remaining_categorical_cols:
                st.success("‚úÖ ƒê√£ m√£ h√≥a t·∫•t c·∫£ c√°c bi·∫øn ph√¢n lo·∫°i!")
                st.info(f"üí° ƒê√£ m√£ h√≥a: {', '.join(encoded_cols)}")
            else:
                # Select column to encode (only show remaining)
                selected_enc_col = st.selectbox(
                    "Ch·ªçn c·ªôt ƒë·ªÉ m√£ h√≥a:",
                    remaining_categorical_cols,
                    key="selected_enc_col_frag"
                )
                
                # Show column info
                unique_count = current_data[selected_enc_col].nunique()
                st.metric("S·ªë gi√° tr·ªã kh√°c nhau", unique_count)
                
                # Show recommendation
                from backend.data_processing import recommend_encoding
                recommendation = recommend_encoding(current_data, selected_enc_col)
                
                st.markdown(f"""
                <div style="background-color: #1e3a5f; padding: 0.8rem; border-radius: 6px; border-left: 3px solid #3b82f6; margin: 0.5rem 0;">
                    <p style="margin: 0; font-size: 0.85rem;">
                        <strong>üí° G·ª£i √Ω:</strong> {recommendation['recommendation']}<br>
                        <span style="font-size: 0.8rem; opacity: 0.9;">{recommendation['reason']}</span>
                    </p>
                </div>
                """, unsafe_allow_html=True)
                
                # Encoding method selection
                encoding_method = st.selectbox(
                    "Ph∆∞∆°ng ph√°p m√£ h√≥a:",
                    ["One-Hot Encoding", "Label Encoding", "Target Encoding", "Ordinal Encoding"],
                    key="encoding_method_frag"
                )
                
                # Method-specific parameters
                encoding_params = {}
                
                if encoding_method == "One-Hot Encoding":
                    drop_first = st.checkbox(
                        "Drop first dummy (tr√°nh multicollinearity)",
                        value=False,
                        key="onehot_drop_first_frag",
                        help="B·ªè c·ªôt dummy ƒë·∫ßu ti√™n ƒë·ªÉ tr√°nh hi·ªán t∆∞·ª£ng ƒëa c·ªông tuy·∫øn"
                    )
                    encoding_params['drop_first'] = drop_first
                
                elif encoding_method == "Target Encoding":
                    st.markdown("**C·∫•u h√¨nh Target Encoding:**")
                    
                    # Find target column
                    potential_targets = [col for col in current_data.columns 
                                       if 'target' in col.lower() or 'default' in col.lower() 
                                       or 'label' in col.lower() or 'churn' in col.lower()]
                    
                    numeric_cols_for_target = current_data.select_dtypes(include=[np.number]).columns.tolist()
                    
                    if potential_targets:
                        default_target = potential_targets[0]
                    elif numeric_cols_for_target:
                        default_target = numeric_cols_for_target[-1]
                    else:
                        default_target = None
                    
                    if default_target and numeric_cols_for_target:
                        target_col = st.selectbox(
                            "Ch·ªçn c·ªôt target:",
                            numeric_cols_for_target,
                            index=numeric_cols_for_target.index(default_target) if default_target in numeric_cols_for_target else 0,
                            key="target_encoding_target_frag",
                            help="C·ªôt target ƒë·ªÉ t√≠nh mean encoding"
                        )
                        
                        smoothing = st.slider(
                            "Smoothing (tr√°nh overfitting):",
                            min_value=0.0,
                            max_value=10.0,
                            value=1.0,
                            step=0.5,
                            key="target_encoding_smoothing_frag",
                            help="Gi√° tr·ªã cao h∆°n = √≠t overfitting h∆°n"
                        )
                        
                        encoding_params['target_column'] = target_col
                        encoding_params['smoothing'] = smoothing
                    else:
                        st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c·ªôt target. Vui l√≤ng ch·ªçn ph∆∞∆°ng ph√°p kh√°c.")
                
                elif encoding_method == "Ordinal Encoding":
                    st.markdown("**Th·ª© t·ª± c√°c categories:**")
                    st.info("üí° S·∫Øp x·∫øp theo th·ª© t·ª± c√≥ √Ω nghƒ©a (th·∫•p ‚Üí cao)")
            
            # Initialize encoding config
            if 'encoding_config' not in st.session_state:
                st.session_state.encoding_config = {}
            
            # Add and apply immediately
            if remaining_categorical_cols:
                if st.button("‚ûï Th√™m C·∫•u H√¨nh", key="add_enc_config_frag", width='stretch', type="primary"):
                    try:
                        # Initialize preprocessing pipeline if not exists
                        if 'preprocessing_pipeline' not in st.session_state or st.session_state.preprocessing_pipeline is None:
                            from backend.data_processing import PreprocessingPipeline
                            st.session_state.preprocessing_pipeline = PreprocessingPipeline()
                        
                        pipeline = st.session_state.preprocessing_pipeline
                        
                        # Get train_data for fitting
                        train_data = st.session_state.get('train_data')
                        if train_data is None:
                            st.error("‚ö†Ô∏è Ch∆∞a chia t·∫≠p Train/Test. Vui l√≤ng chia t·∫≠p d·ªØ li·ªáu tr∆∞·ªõc.")
                            st.stop()
                        
                        from backend.data_processing import encode_categorical
                        
                        # Backup
                        if 'column_backups' not in st.session_state:
                            st.session_state.column_backups = {}
                        backup_key = f"encoding_{selected_enc_col}"
                        st.session_state.column_backups[backup_key] = {
                            'data': st.session_state.data[selected_enc_col].copy(),
                            'train_data': train_data[selected_enc_col].copy() if selected_enc_col in train_data.columns else None,
                            'valid_data': st.session_state.valid_data[selected_enc_col].copy() if st.session_state.get('valid_data') is not None and selected_enc_col in st.session_state.valid_data.columns else None,
                            'test_data': st.session_state.test_data[selected_enc_col].copy() if st.session_state.get('test_data') is not None and selected_enc_col in st.session_state.test_data.columns else None
                        }
                        
                        # FIT encoder on train_data only
                        pipeline.fit_encoder(train_data, selected_enc_col, encoding_method, **encoding_params)
                        
                        # TRANSFORM all datasets using the same encode_categorical function
                        # Transform main data
                        encoded_data, encoding_info = encode_categorical(
                            data=st.session_state.data,
                            method=encoding_method,
                            columns=[selected_enc_col],
                            **encoding_params
                        )
                        st.session_state.data = encoded_data
                        
                        # Transform train_data
                        encoded_train, _ = encode_categorical(
                            data=st.session_state.train_data,
                            method=encoding_method,
                            columns=[selected_enc_col],
                            **encoding_params
                        )
                        st.session_state.train_data = encoded_train
                        
                        # Transform valid_data if exists
                        if st.session_state.get('valid_data') is not None:
                            encoded_valid, _ = encode_categorical(
                                data=st.session_state.valid_data,
                                method=encoding_method,
                                columns=[selected_enc_col],
                                **encoding_params
                            )
                            st.session_state.valid_data = encoded_valid
                        
                        # Transform test_data if exists
                        if st.session_state.get('test_data') is not None:
                            encoded_test, _ = encode_categorical(
                                data=st.session_state.test_data,
                                method=encoding_method,
                                columns=[selected_enc_col],
                                **encoding_params
                            )
                            st.session_state.test_data = encoded_test
                        
                        # Save config
                        st.session_state.encoding_config[selected_enc_col] = {
                            'method': encoding_method,
                            'unique_count': unique_count,
                            'params': encoding_params,
                            'applied': True,
                            'applied_to_all': True
                        }
                        
                        if 'encoding_applied_info' not in st.session_state:
                            st.session_state.encoding_applied_info = {}
                        st.session_state.encoding_applied_info.update(encoding_info)
                        
                        # Build success message
                        datasets_info = "Train"
                        if st.session_state.get('valid_data') is not None:
                            datasets_info += "/Valid"
                        if st.session_state.get('test_data') is not None:
                            datasets_info += "/Test"
                        
                        # Store success message
                        new_cols_count = None
                        if encoding_method == "One-Hot Encoding" and selected_enc_col in encoding_info:
                            new_cols_count = encoding_info[selected_enc_col]['n_new_columns']
                        
                        st.session_state._encoding_success = {
                            'col': selected_enc_col,
                            'method': encoding_method,
                            'new_cols': new_cols_count,
                            'datasets': datasets_info
                        }
                        
                        st.rerun(scope="fragment")
                    except Exception as e:
                        st.error(f"‚ùå L·ªói: {str(e)}")
                        import traceback
                        with st.expander("Chi ti·∫øt"):
                            st.code(traceback.format_exc())
        
        # Show current encoding configurations
        if st.session_state.get('encoding_config'):
            st.markdown("---")
            st.markdown("##### üìù C·∫•u H√¨nh M√£ H√≥a Hi·ªán T·∫°i")
            
            # Display each configuration with undo button
            for col, cfg in list(st.session_state.encoding_config.items()):
                col1, col2, col3 = st.columns([2, 2, 1])
                
                with col1:
                    st.text(f"üìå {col}")
                with col2:
                    st.text(f"{cfg['method']} (S·ªë gi√° tr·ªã: {cfg['unique_count']})")
                with col3:
                    if cfg.get('applied', False):
                        # Undo button for applied encoding
                        if st.button("‚Ü©Ô∏è Undo", key=f"undo_enc_{col}_frag", width='stretch'):
                            # Restore from backup
                            backup_key = f"encoding_{col}"
                            if backup_key in st.session_state.get('column_backups', {}):
                                st.session_state.data[col] = st.session_state.column_backups[backup_key]
                                del st.session_state.column_backups[backup_key]
                                
                                # Remove encoded columns if One-Hot
                                if col in st.session_state.get('encoding_applied_info', {}):
                                    enc_info = st.session_state.encoding_applied_info[col]
                                    if 'new_columns' in enc_info:
                                        for new_col in enc_info['new_columns']:
                                            if new_col in st.session_state.data.columns:
                                                st.session_state.data.drop(columns=[new_col], inplace=True)
                                    del st.session_state.encoding_applied_info[col]
                                
                                del st.session_state.encoding_config[col]
                                st.session_state._encoding_undo_success = f"‚úÖ ƒê√£ ho√†n t√°c m√£ h√≥a `{col}`"
                                st.rerun(scope="fragment")
                    else:
                        # Delete button for pending config
                        if st.button("üóëÔ∏è", key=f"del_enc_{col}_frag", width='stretch'):
                            del st.session_state.encoding_config[col]
                            st.rerun(scope="fragment")
            
            st.markdown("---")
            
            # Show applied encoding info if exists
            if st.session_state.get('encoding_applied_info'):
                with st.expander("üìã Xem Chi Ti·∫øt M√£ H√≥a ƒê√£ √Åp D·ª•ng"):
                    for col, info in st.session_state.encoding_applied_info.items():
                        st.markdown(f"**{col}** - {info['method']}")
                        
                        if 'new_columns' in info:
                            st.write(f"T·∫°o {info['n_new_columns']} c·ªôt m·ªõi:", info['new_columns'][:10])
                        elif 'mapping' in info and len(str(info['mapping'])) < 500:
                            st.write("Mapping:", info['mapping'])
                        
                        st.markdown("---")
        
        else:
            st.info("üí° Ch∆∞a c√≥ c·∫•u h√¨nh m√£ h√≥a n√†o. H√£y ch·ªçn c·ªôt v√† ph∆∞∆°ng ph√°p ·ªü tr√™n.")
    
    else:
        st.success("‚úÖ Kh√¥ng c√≥ bi·∫øn ph√¢n lo·∫°i c·∫ßn m√£ h√≥a")


@st.fragment
def binning_fragment(data):
    """Fragment ƒë·ªÉ ph√¢n nh√≥m (binning) bi·∫øn li√™n t·ª•c - kh√¥ng g√¢y rerun to√†n trang"""
    
    # Hi·ªÉn th·ªã th√¥ng b√°o th√†nh c√¥ng n·∫øu c√≥
    if st.session_state.get('_binning_success'):
        info = st.session_state._binning_success
        st.success(f"‚úÖ ƒê√£ t·∫°o c·ªôt m·ªõi: `{info['new_col']}`")
        del st.session_state._binning_success
    
    current_data = st.session_state.data
    numeric_cols_binning = current_data.select_dtypes(include=[np.number]).columns.tolist()
    
    if numeric_cols_binning:
        col_bin1, col_bin2 = st.columns([1, 1])
        
        with col_bin1:
            st.markdown("##### ‚öôÔ∏è C·∫•u H√¨nh Binning")
            
            selected_bin_col = st.selectbox(
                "Ch·ªçn bi·∫øn li√™n t·ª•c:",
                numeric_cols_binning,
                key="binning_col_select_frag",
                help="Ch·ªçn bi·∫øn s·ªë ƒë·ªÉ ph√¢n nh√≥m"
            )
            
            binning_method = st.selectbox(
                "Ph∆∞∆°ng ph√°p binning:",
                ["Optimal Binning (WoE/IV)", "Equal Width (Kho·∫£ng ƒë·ªÅu)", "Equal Frequency (T·∫ßn su·∫•t ƒë·ªÅu)", "Quantile", "Custom Bins"],
                key="binning_method_select_frag",
                help="Equal Width: chia theo kho·∫£ng gi√° tr·ªã b·∫±ng nhau\nEqual Frequency: m·ªói nh√≥m c√≥ s·ªë l∆∞·ª£ng m·∫´u t∆∞∆°ng ƒë∆∞∆°ng\nQuantile: chia theo ph√¢n v·ªã\nCustom: t·ª± ƒë·ªãnh nghƒ©a c√°c ng∆∞·ª°ng"
            )
            
            # Optimal Binning requires target column
            target_col_for_binning = None
            if binning_method == "Optimal Binning (WoE/IV)":
                st.info("üí° **Optimal Binning** t·ªëi ∆∞u h√≥a Information Value (IV) ƒë·ªÉ ph√¢n bi·ªát Good/Bad. Y√™u c·∫ßu ch·ªçn c·ªôt target.")
                
                # Get potential target columns (binary)
                target_col_for_binning = st.session_state.get('target_column', None)
                if target_col_for_binning:
                    st.success(f"üìå Target column: **{target_col_for_binning}**")
                else:
                    st.warning("‚ö†Ô∏è Ch∆∞a ch·ªçn target column. Vui l√≤ng ch·ªçn ·ªü ph·∫ßn Feature Engineering.")
                
                num_bins = st.slider(
                    "S·ªë bins t·ªëi ƒëa:",
                    min_value=2,
                    max_value=15,
                    value=5,
                    key="num_bins_slider_frag",
                    help="Optimal Binning s·∫Ω t√¨m s·ªë bins t·ªëi ∆∞u trong kho·∫£ng n√†y"
                )
                
                # Monotonic constraint option
                monotonic = st.checkbox(
                    "üìà √âp Monotonic (Bad rate tƒÉng/gi·∫£m ƒë·ªÅu)",
                    value=True,
                    key="monotonic_binning_frag",
                    help="ƒê·∫£m b·∫£o bad rate tƒÉng ho·∫∑c gi·∫£m ƒë·ªÅu theo th·ª© t·ª± bins - quan tr·ªçng cho Credit Scoring"
                )
                
                custom_bins = ""
            elif binning_method == "Custom Bins":
                st.info("üí° Nh·∫≠p c√°c ng∆∞·ª°ng ph√¢n c√°ch, VD: 0,18,30,60,100")
                custom_bins = st.text_input(
                    "Ng∆∞·ª°ng (ph√¢n c√°ch b·∫±ng d·∫•u ph·∫©y):",
                    value="",
                    key="custom_bins_input_frag",
                    help="VD: 0,25,50,75,100"
                )
                num_bins = 5  # default
            else:
                custom_bins = ""
                num_bins = st.slider(
                    "S·ªë nh√≥m:",
                    min_value=2,
                    max_value=10,
                    value=5,
                    key="num_bins_slider_frag",
                    help="S·ªë l∆∞·ª£ng nh√≥m mu·ªën chia"
                )
            
            # Label options - hide for Optimal Binning (always outputs WoE codes)
            if binning_method != "Optimal Binning (WoE/IV)":
                include_labels = st.checkbox(
                    "T·∫°o nh√£n cho c√°c nh√≥m",
                    value=True,
                    key="include_bin_labels_frag",
                    help="T·ª± ƒë·ªông t·∫°o nh√£n cho t·ª´ng nh√≥m (VD: Low, Medium, High)"
                )
                
                if include_labels:
                    label_type = st.radio(
                        "Ki·ªÉu nh√£n:",
                        ["T·ª± ƒë·ªông (Low/Medium/High)", "S·ªë th·ª© t·ª± (1,2,3...)", "Kho·∫£ng gi√° tr·ªã"],
                        key="label_type_select_frag"
                    )
                else:
                    label_type = "Kho·∫£ng gi√° tr·ªã"
            else:
                include_labels = False
                label_type = "WoE"
            
            # New column name - use _woe suffix for Optimal Binning
            if binning_method == "Optimal Binning (WoE/IV)":
                default_col_name = f"{selected_bin_col}_woe"
            else:
                default_col_name = f"{selected_bin_col}_binned"
            
            # Use dynamic key so value updates when column or method changes
            col_name_key = f"new_bin_col_{selected_bin_col}_{binning_method[:8]}"
            new_col_name = st.text_input(
                "T√™n c·ªôt m·ªõi:",
                value=default_col_name,
                key=col_name_key
            )
            
            if st.button("üîÑ Th·ª±c Hi·ªán Binning", key="apply_binning_btn_frag", type="primary", width='stretch'):
                try:
                    # Get data and remove NaN values for binning
                    bin_data = st.session_state.data[selected_bin_col].copy()
                    
                    # Check if data has enough non-null values
                    valid_data = bin_data.dropna()
                    if len(valid_data) < num_bins:
                        st.error(f"‚ùå Kh√¥ng ƒë·ªß d·ªØ li·ªáu h·ª£p l·ªá ƒë·ªÉ chia th√†nh {num_bins} nh√≥m. Ch·ªâ c√≥ {len(valid_data)} gi√° tr·ªã.")
                        binned = None
                    else:
                        # Perform binning based on method
                        if binning_method == "Optimal Binning (WoE/IV)":
                            # Optimal binning requires target column
                            if not target_col_for_binning:
                                st.error("‚ùå Vui l√≤ng ch·ªçn target column tr∆∞·ªõc khi s·ª≠ d·ª•ng Optimal Binning!")
                                binned = None
                            else:
                                try:
                                    # Try using optbinning library (better IV optimization)
                                    try:
                                        from optbinning import OptimalBinning
                                        use_optbinning = True
                                    except ImportError:
                                        use_optbinning = False
                                        st.warning("‚ö†Ô∏è Th∆∞ vi·ªán `optbinning` ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. S·ª≠ d·ª•ng Decision Tree fallback. C√†i ƒë·∫∑t b·∫±ng: `pip install optbinning`")
                                    
                                    # Prepare data
                                    X_bin = bin_data.values
                                    y_bin = st.session_state.data[target_col_for_binning].values
                                    
                                    # Remove NaN
                                    mask = ~(np.isnan(X_bin) | pd.isna(y_bin))
                                    X_clean = X_bin[mask]
                                    y_clean = y_bin[mask].astype(int)
                                    
                                    if use_optbinning:
                                        # Use optbinning library - optimizes IV directly
                                        monotonic_trend = "ascending" if monotonic else "auto"
                                        
                                        optb = OptimalBinning(
                                            name=selected_bin_col,
                                            dtype="numerical",
                                            solver="cp",  # Constraint programming solver
                                            max_n_bins=num_bins,
                                            min_bin_size=0.05,  # At least 5% per bin
                                            monotonic_trend=monotonic_trend,
                                            special_codes=None,
                                            cat_cutoff=None
                                        )
                                        optb.fit(X_clean, y_clean)
                                        
                                        # Get splits from optbinning
                                        splits = optb.splits
                                        bins = [-np.inf] + list(splits) + [np.inf]
                                        
                                        # Apply binning to full data
                                        binned = pd.cut(bin_data, bins=bins)
                                        
                                        # Get WoE/IV from binning table
                                        binning_table = optb.binning_table.build()
                                        woe_iv_info = []
                                        total_iv = 0
                                        
                                        for i, row in binning_table.iterrows():
                                            if row['Bin'] not in ['Special', 'Missing', 'Totals']:
                                                woe_val = row['WoE'] if not pd.isna(row['WoE']) else 0
                                                iv_val = row['IV'] if not pd.isna(row['IV']) else 0
                                                total_iv += iv_val
                                                woe_iv_info.append({
                                                    'bin': i, 
                                                    'range': str(row['Bin']), 
                                                    'good': int(row['Count (0)']) if 'Count (0)' in row else int(row.get('Count', 0) - row.get('Count (1)', 0)),
                                                    'bad': int(row['Count (1)']) if 'Count (1)' in row else 0,
                                                    'woe': round(woe_val, 4), 
                                                    'iv': round(iv_val, 4)
                                                })
                                        
                                        # Store IV info for display
                                        st.session_state._optimal_binning_iv = total_iv
                                        st.session_state._optimal_binning_details = woe_iv_info
                                        
                                    else:
                                        # Fallback to Decision Tree based approach
                                        from sklearn.tree import DecisionTreeClassifier
                                        from sklearn import __version__ as sklearn_version
                                        
                                        # Use Decision Tree to find optimal splits
                                        tree_params = {
                                            'max_leaf_nodes': num_bins,
                                            'min_samples_leaf': max(50, int(len(y_clean) * 0.05)),
                                            'random_state': 42
                                        }
                                        
                                        # Add monotonic constraint if enabled and sklearn supports it
                                        if monotonic:
                                            try:
                                                major, minor = map(int, sklearn_version.split('.')[:2])
                                                if (major, minor) >= (1, 4):
                                                    tree_params['monotonic_cst'] = [1]
                                            except:
                                                pass
                                        
                                        tree = DecisionTreeClassifier(**tree_params)
                                        tree.fit(X_clean.reshape(-1, 1), y_clean)
                                        
                                        # Get split points from tree
                                        thresholds = tree.tree_.threshold
                                        thresholds = thresholds[thresholds != -2]
                                        thresholds = sorted(thresholds)
                                        
                                        bins = [-np.inf] + list(thresholds) + [np.inf]
                                        binned = pd.cut(bin_data, bins=bins)
                                        
                                        # Calculate WoE and IV for display
                                        woe_iv_info = []
                                        total_good = (y_clean == 0).sum()
                                        total_bad = (y_clean == 1).sum()
                                        total_iv = 0
                                        
                                        for i, cat in enumerate(binned.cat.categories):
                                            mask_bin = binned == cat
                                            bin_good = ((st.session_state.data[target_col_for_binning] == 0) & mask_bin).sum()
                                            bin_bad = ((st.session_state.data[target_col_for_binning] == 1) & mask_bin).sum()
                                            
                                            dist_good = max(bin_good / total_good, 0.0001) if total_good > 0 else 0.0001
                                            dist_bad = max(bin_bad / total_bad, 0.0001) if total_bad > 0 else 0.0001
                                            
                                            woe = np.log(dist_good / dist_bad)
                                            iv = (dist_good - dist_bad) * woe
                                            total_iv += iv
                                            
                                            woe_iv_info.append({
                                                'bin': i, 'range': str(cat), 
                                                'good': bin_good, 'bad': bin_bad,
                                                'woe': round(woe, 4), 'iv': round(iv, 4)
                                            })
                                        
                                        st.session_state._optimal_binning_iv = total_iv
                                        st.session_state._optimal_binning_details = woe_iv_info
                                    
                                except Exception as e:
                                    st.error(f"‚ùå L·ªói Optimal Binning: {str(e)}")
                                    # Fallback to equal frequency
                                    binned, bins = pd.qcut(bin_data, q=num_bins, retbins=True, duplicates='drop')
                        
                        elif binning_method == "Equal Width (Kho·∫£ng ƒë·ªÅu)":
                            binned, bins = pd.cut(bin_data, bins=num_bins, retbins=True)
                        elif binning_method == "Equal Frequency (T·∫ßn su·∫•t ƒë·ªÅu)":
                            binned, bins = pd.qcut(bin_data, q=num_bins, retbins=True, duplicates='drop')
                        elif binning_method == "Quantile":
                            binned, bins = pd.qcut(bin_data, q=num_bins, retbins=True, duplicates='drop')
                        elif binning_method == "Custom Bins":
                            if custom_bins:
                                try:
                                    bins = [float(x.strip()) for x in custom_bins.split(',')]
                                    binned, returned_bins = pd.cut(bin_data, bins=bins, retbins=True)
                                    bins = returned_bins
                                except Exception as e:
                                    st.error(f"‚ùå ƒê·ªãnh d·∫°ng ng∆∞·ª°ng kh√¥ng h·ª£p l·ªá: {str(e)}")
                                    binned = None
                            else:
                                st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p ng∆∞·ª°ng!")
                                binned = None
                    
                    if binned is not None:
                        # Get original category codes (0-indexed)
                        original_codes = binned.cat.codes.copy()
                        num_categories = len(binned.cat.categories)
                        
                        # Determine labels for display/reference
                        if include_labels:
                            if label_type == "T·ª± ƒë·ªông (Low/Medium/High)":
                                if num_categories <= 3:
                                    labels = ['Low', 'Medium', 'High'][:num_categories]
                                elif num_categories == 4:
                                    labels = ['Very Low', 'Low', 'High', 'Very High']
                                elif num_categories == 5:
                                    labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']
                                else:
                                    labels = [f'Group_{i+1}' for i in range(num_categories)]
                            elif label_type == "S·ªë th·ª© t·ª± (1,2,3...)":
                                labels = [str(i+1) for i in range(num_categories)]
                        else:
                            labels = [str(i) for i in range(num_categories)]
                        
                        # Always output numeric codes (0, 1, 2, ...) for ML training compatibility
                        # Codes are 0-indexed, -1 for NaN
                        binned_numeric = original_codes.copy()
                        # Handle NaN: codes == -1 means NaN, keep as NaN
                        binned_numeric = binned_numeric.astype(float)
                        binned_numeric[binned_numeric == -1] = np.nan
                        
                        # Create the output series
                        binned_output = pd.Series(binned_numeric, index=bin_data.index)
                        
                        # Add to main dataframe
                        st.session_state.data.loc[:, new_col_name] = binned_output
                        
                        # Sync to train/valid/test data if they exist
                        # Apply same binning directly using the bins found
                        def apply_binning_codes(df, col_name, bins_edges):
                            """Apply binning to a column and return numeric codes"""
                            if col_name not in df.columns:
                                return None
                            binned_series = pd.cut(df[col_name], bins=bins_edges)
                            codes = binned_series.cat.codes.astype(float)
                            codes[codes == -1] = np.nan
                            return codes
                        
                        if st.session_state.get('train_data') is not None and selected_bin_col in st.session_state.train_data.columns:
                            st.session_state.train_data[new_col_name] = apply_binning_codes(
                                st.session_state.train_data, selected_bin_col, bins
                            )
                        
                        if st.session_state.get('valid_data') is not None and selected_bin_col in st.session_state.valid_data.columns:
                            st.session_state.valid_data[new_col_name] = apply_binning_codes(
                                st.session_state.valid_data, selected_bin_col, bins
                            )
                        
                        if st.session_state.get('test_data') is not None and selected_bin_col in st.session_state.test_data.columns:
                            st.session_state.test_data[new_col_name] = apply_binning_codes(
                                st.session_state.test_data, selected_bin_col, bins
                            )
                        
                        # Clear cached feature importance results to force recalculation
                        if 'feature_importance_results' in st.session_state:
                            del st.session_state.feature_importance_results
                        
                        # Save to binning config
                        if 'binning_config' not in st.session_state:
                            st.session_state.binning_config = {}
                        
                        st.session_state.binning_config[selected_bin_col] = {
                            'method': binning_method,
                            'bins': bins.tolist() if hasattr(bins, 'tolist') else bins,
                            'num_bins': len(bins) - 1 if isinstance(bins, (list, np.ndarray)) else num_bins,
                            'new_column': new_col_name,
                            'labels': include_labels,
                            'applied': True
                        }
                        
                        st.session_state._binning_success = {'new_col': new_col_name}
                        st.rerun(scope="fragment")
                
                except Exception as e:
                    st.error(f"‚ùå L·ªói khi binning: {str(e)}")
                    import traceback
                    with st.expander("Chi ti·∫øt l·ªói"):
                        st.code(traceback.format_exc())
        
        with col_bin2:
            st.markdown("##### üìä Ph√¢n T√≠ch & Tr·ª±c Quan")
            
            # Show Optimal Binning IV results if available
            if st.session_state.get('_optimal_binning_iv') is not None:
                total_iv = st.session_state._optimal_binning_iv
                iv_details = st.session_state.get('_optimal_binning_details', [])
                
                # IV interpretation
                if total_iv < 0.02:
                    iv_interpret = "‚ùå Kh√¥ng d·ª± ƒëo√°n ƒë∆∞·ª£c"
                    iv_color = "#f44336"
                elif total_iv < 0.1:
                    iv_interpret = "‚ö†Ô∏è Y·∫øu"
                    iv_color = "#ff9800"
                elif total_iv < 0.3:
                    iv_interpret = "‚úÖ Trung b√¨nh"
                    iv_color = "#4caf50"
                elif total_iv < 0.5:
                    iv_interpret = "üéØ M·∫°nh"
                    iv_color = "#2196f3"
                else:
                    iv_interpret = "üî• R·∫•t m·∫°nh (ki·ªÉm tra overfitting)"
                    iv_color = "#9c27b0"
                
                st.markdown(f"""
                <div style="background: linear-gradient(90deg, {iv_color}22, transparent); padding: 1rem; border-radius: 8px; border-left: 4px solid {iv_color}; margin-bottom: 1rem;">
                    <h4 style="margin: 0; color: {iv_color};">üìà Information Value: {total_iv:.4f}</h4>
                    <p style="margin: 0.5rem 0 0 0; font-size: 0.9rem;">{iv_interpret}</p>
                </div>
                """, unsafe_allow_html=True)
                
                # Show WoE table
                if iv_details:
                    st.markdown("**Chi ti·∫øt WoE theo bin:**")
                    iv_df = pd.DataFrame(iv_details)
                    iv_df.columns = ['Bin', 'Kho·∫£ng', 'Good', 'Bad', 'WoE', 'IV']
                    st.dataframe(iv_df.style.background_gradient(subset=['IV'], cmap='RdYlGn'), width='stretch', hide_index=True)
                
                # Clear after display
                st.session_state._optimal_binning_iv = None
                st.session_state._optimal_binning_details = None
            
            # Show statistics
            if selected_bin_col in current_data.columns:
                col_data_bin = current_data[selected_bin_col].dropna()
                
                if len(col_data_bin) > 0:
                    stats_col1, stats_col2, stats_col3 = st.columns(3)
                    with stats_col1:
                        st.metric("Min", f"{col_data_bin.min():.2f}")
                    with stats_col2:
                        st.metric("Mean", f"{col_data_bin.mean():.2f}")
                    with stats_col3:
                        st.metric("Max", f"{col_data_bin.max():.2f}")
                    
                    # Distribution plot
                    import plotly.express as px
                    fig = px.histogram(
                        col_data_bin,
                        nbins=30,
                        title=f"Ph√¢n ph·ªëi {selected_bin_col}",
                        labels={'value': selected_bin_col, 'count': 'S·ªë l∆∞·ª£ng'}
                    )
                    fig.update_layout(
                        template="plotly_dark",
                        height=300,
                        showlegend=False,
                        margin=dict(l=0, r=0, t=30, b=0)
                    )
                    st.plotly_chart(fig, width='stretch')
            
            # Show binning history
            if st.session_state.get('binning_config'):
                st.markdown("---")
                st.markdown("**üìã L·ªãch S·ª≠ Binning:**")
                
                for orig_col, cfg in st.session_state.binning_config.items():
                    st.markdown(f"""
                    <div style="background-color: #1a472a; padding: 0.5rem; border-radius: 4px; margin-bottom: 0.5rem;">
                        <small>
                        ‚úÖ <strong>{orig_col}</strong> ‚Üí {cfg['new_column']}<br>
                        &nbsp;&nbsp;&nbsp;Ph∆∞∆°ng ph√°p: {cfg['method']}<br>
                        &nbsp;&nbsp;&nbsp;S·ªë nh√≥m: {cfg['num_bins']}
                        </small>
                    </div>
                    """, unsafe_allow_html=True)
    else:
        st.info("üí° Kh√¥ng c√≥ bi·∫øn s·ªë ƒë·ªÉ th·ª±c hi·ªán binning")


@st.fragment
def scaling_fragment(data):
    """Fragment ƒë·ªÉ chu·∫©n h√≥a/scaling bi·∫øn s·ªë - kh√¥ng g√¢y rerun to√†n trang"""
    
    # Hi·ªÉn th·ªã th√¥ng b√°o th√†nh c√¥ng n·∫øu c√≥
    if st.session_state.get('_scaling_success'):
        info = st.session_state._scaling_success
        st.success(f"‚úÖ ƒê√£ scaling {info['count']} c·ªôt!")
        if info.get('new_cols'):
            st.info(f"üìä ƒê√£ t·∫°o {info['count']} c·ªôt m·ªõi v·ªõi suffix '_scaled'")
        del st.session_state._scaling_success
    
    current_data = st.session_state.data
    numeric_cols_scale = current_data.select_dtypes(include=[np.number]).columns.tolist()
    
    if numeric_cols_scale:
        col_scale1, col_scale2 = st.columns([1, 1])
        
        with col_scale1:
            st.markdown("##### ‚öôÔ∏è C·∫•u H√¨nh Scaling")
            
            scaling_method = st.selectbox(
                "Ph∆∞∆°ng ph√°p scaling:",
                [
                    "StandardScaler (Z-score normalization)",
                    "MinMaxScaler (0-1 scaling)",
                    "RobustScaler (using IQR)",
                    "MaxAbsScaler",
                    "Normalizer (L2 norm)"
                ],
                key="scaling_method_select_frag",
                help="StandardScaler: (x - mean) / std\nMinMaxScaler: (x - min) / (max - min)\nRobustScaler: s·ª≠ d·ª•ng median v√† IQR, t·ªët cho outliers"
            )
            
            st.markdown("**Ch·ªçn c√°c c·ªôt c·∫ßn scaling:**")
            
            # Exclude target if exists
            target_col = st.session_state.get('target_column')
            cols_to_scale_options = [col for col in numeric_cols_scale if col != target_col]
            
            if not cols_to_scale_options:
                cols_to_scale_options = numeric_cols_scale
            
            select_all_scale = st.checkbox(
                "Ch·ªçn t·∫•t c·∫£ bi·∫øn s·ªë",
                value=False,
                key="select_all_scale_checkbox_frag"
            )
            
            if select_all_scale:
                selected_scale_cols = cols_to_scale_options
            else:
                selected_scale_cols = st.multiselect(
                    "Ch·ªçn c·ªôt:",
                    cols_to_scale_options,
                    default=[],
                    key="scale_cols_multiselect_frag",
                    help="Ch·ªçn c√°c c·ªôt s·ªë c·∫ßn scaling"
                )
            
            st.info(f"üìä ƒê√£ ch·ªçn: **{len(selected_scale_cols)}** c·ªôt")
            
            # Additional options
            create_new_cols = st.checkbox(
                "T·∫°o c·ªôt m·ªõi (gi·ªØ nguy√™n c·ªôt g·ªëc)",
                value=False,
                key="create_new_scaled_cols_frag",
                help="N·∫øu check: t·∫°o c·ªôt m·ªõi v·ªõi suffix '_scaled'\nN·∫øu kh√¥ng: ghi ƒë√® l√™n c·ªôt g·ªëc"
            )
            
            if st.button("üîÑ Th·ª±c Hi·ªán Scaling", key="apply_scaling_btn_frag", type="primary", width='stretch'):
                if selected_scale_cols:
                    try:
                        # Initialize preprocessing pipeline if not exists
                        if 'preprocessing_pipeline' not in st.session_state or st.session_state.preprocessing_pipeline is None:
                            from backend.data_processing import PreprocessingPipeline
                            st.session_state.preprocessing_pipeline = PreprocessingPipeline()
                        
                        pipeline = st.session_state.preprocessing_pipeline
                        
                        # Get train_data for fitting
                        train_data = st.session_state.get('train_data')
                        if train_data is None:
                            st.error("‚ö†Ô∏è Ch∆∞a chia t·∫≠p Train/Test. Vui l√≤ng chia t·∫≠p d·ªØ li·ªáu tr∆∞·ªõc.")
                            st.stop()
                        
                        # Initialize configs if not exists
                        if 'scaling_config' not in st.session_state:
                            st.session_state.scaling_config = {}
                        if 'column_backups' not in st.session_state:
                            st.session_state.column_backups = {}
                        
                        # Backup columns before scaling
                        for col in selected_scale_cols:
                            backup_key = f"scaling_{col}"
                            st.session_state.column_backups[backup_key] = {
                                'data': st.session_state.data[col].copy(),
                                'train_data': train_data[col].copy() if col in train_data.columns else None,
                                'valid_data': st.session_state.valid_data[col].copy() if st.session_state.get('valid_data') is not None and col in st.session_state.valid_data.columns else None,
                                'test_data': st.session_state.test_data[col].copy() if st.session_state.get('test_data') is not None and col in st.session_state.test_data.columns else None
                            }
                        
                        # FIT scaler on train_data only
                        pipeline.fit_scaler(train_data, selected_scale_cols, scaling_method)
                        
                        # TRANSFORM all datasets
                        if create_new_cols:
                            new_col_names = [f"{col}_scaled" for col in selected_scale_cols]
                            
                            # Transform and add new columns to main data
                            scaled_main = pipeline.scalers["_".join(sorted(selected_scale_cols))]['scaler'].transform(st.session_state.data[selected_scale_cols])
                            scaled_df = pd.DataFrame(scaled_main, columns=new_col_names, index=st.session_state.data.index)
                            st.session_state.data = pd.concat([st.session_state.data, scaled_df], axis=1)
                            
                            # Transform train_data
                            scaled_train = pipeline.scalers["_".join(sorted(selected_scale_cols))]['scaler'].transform(train_data[selected_scale_cols])
                            scaled_train_df = pd.DataFrame(scaled_train, columns=new_col_names, index=train_data.index)
                            st.session_state.train_data = pd.concat([st.session_state.train_data, scaled_train_df], axis=1)
                            
                            # Transform valid_data if exists
                            if st.session_state.get('valid_data') is not None:
                                scaled_valid = pipeline.scalers["_".join(sorted(selected_scale_cols))]['scaler'].transform(st.session_state.valid_data[selected_scale_cols])
                                scaled_valid_df = pd.DataFrame(scaled_valid, columns=new_col_names, index=st.session_state.valid_data.index)
                                st.session_state.valid_data = pd.concat([st.session_state.valid_data, scaled_valid_df], axis=1)
                            
                            # Transform test_data if exists
                            if st.session_state.get('test_data') is not None:
                                scaled_test = pipeline.scalers["_".join(sorted(selected_scale_cols))]['scaler'].transform(st.session_state.test_data[selected_scale_cols])
                                scaled_test_df = pd.DataFrame(scaled_test, columns=new_col_names, index=st.session_state.test_data.index)
                                st.session_state.test_data = pd.concat([st.session_state.test_data, scaled_test_df], axis=1)
                            
                            # Save config for each new column
                            for orig_col, new_col in zip(selected_scale_cols, new_col_names):
                                st.session_state.scaling_config[new_col] = {
                                    'method': scaling_method,
                                    'original_column': orig_col,
                                    'new_column': True,
                                    'applied': True,
                                    'applied_to_all': True
                                }
                        else:
                            # Transform main data (overwrite)
                            st.session_state.data = pipeline.transform_scaling(st.session_state.data, selected_scale_cols)
                            
                            # Transform train_data
                            st.session_state.train_data = pipeline.transform_scaling(st.session_state.train_data, selected_scale_cols)
                            
                            # Transform valid_data if exists
                            if st.session_state.get('valid_data') is not None:
                                st.session_state.valid_data = pipeline.transform_scaling(st.session_state.valid_data, selected_scale_cols)
                            
                            # Transform test_data if exists
                            if st.session_state.get('test_data') is not None:
                                st.session_state.test_data = pipeline.transform_scaling(st.session_state.test_data, selected_scale_cols)
                            
                            # Save config for each scaled column
                            for col in selected_scale_cols:
                                st.session_state.scaling_config[col] = {
                                    'method': scaling_method,
                                    'new_column': False,
                                    'applied': True,
                                    'applied_to_all': True
                                }
                        
                        # Build success message
                        datasets_info = "Train"
                        if st.session_state.get('valid_data') is not None:
                            datasets_info += "/Valid"
                        if st.session_state.get('test_data') is not None:
                            datasets_info += "/Test"
                        
                        st.session_state._scaling_success = {
                            'count': len(selected_scale_cols),
                            'new_cols': create_new_cols,
                            'datasets': datasets_info
                        }
                        st.rerun(scope="fragment")
                    
                    except Exception as e:
                        st.error(f"‚ùå L·ªói khi scaling: {str(e)}")
                        import traceback
                        with st.expander("Chi ti·∫øt l·ªói"):
                            st.code(traceback.format_exc())
                else:
                    st.warning("‚ö†Ô∏è Vui l√≤ng ch·ªçn √≠t nh·∫•t 1 c·ªôt ƒë·ªÉ scaling")
        
        with col_scale2:
            st.markdown("##### üìä Th√¥ng Tin Scaling")
            
            # Show scaling info
            st.markdown("""
            <div style="background-color: #262730; padding: 1rem; border-radius: 8px; margin-bottom: 1rem;">
                <p style="margin: 0; font-size: 0.9rem;"><strong>üìö Ph∆∞∆°ng ph√°p Scaling:</strong></p>
                <ul style="font-size: 0.85rem; margin: 0.5rem 0 0 1rem;">
                    <li><strong>StandardScaler:</strong> Mean=0, Std=1</li>
                    <li><strong>MinMaxScaler:</strong> Scale v·ªÅ [0, 1]</li>
                    <li><strong>RobustScaler:</strong> D√πng median & IQR</li>
                    <li><strong>MaxAbsScaler:</strong> Scale v·ªÅ [-1, 1]</li>
                    <li><strong>Normalizer:</strong> Normalize m·ªói sample</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
            
            # Show scaling history
            if st.session_state.get('scaling_config'):
                st.markdown("**üìã L·ªãch S·ª≠ Scaling:**")
                
                for col, cfg in st.session_state.scaling_config.items():
                    st.markdown(f"""
                    <div style="background-color: #1a472a; padding: 0.5rem; border-radius: 4px; margin-bottom: 0.5rem;">
                        <small>
                        ‚úÖ <strong>{col}</strong><br>
                        &nbsp;&nbsp;&nbsp;Ph∆∞∆°ng ph√°p: {cfg['method']}
                        </small>
                    </div>
                    """, unsafe_allow_html=True)
            
            # Visualize before/after if data available
            if selected_scale_cols and len(selected_scale_cols) > 0:
                st.markdown("---")
                st.markdown("**üìà Ph√¢n ph·ªëi d·ªØ li·ªáu:**")
                
                sample_col = selected_scale_cols[0]
                if sample_col in current_data.columns:
                    sample_data = current_data[sample_col].dropna().head(1000)
                    
                    import plotly.express as px
                    fig = px.histogram(
                        sample_data,
                        nbins=30,
                        title=f"Tr∆∞·ªõc scaling: {sample_col}",
                        labels={'value': sample_col}
                    )
                    fig.update_layout(
                        template="plotly_dark",
                        height=250,
                        showlegend=False,
                        margin=dict(l=0, r=0, t=30, b=0)
                    )
                    st.plotly_chart(fig, width='stretch')
    else:
        st.info("üí° Kh√¥ng c√≥ bi·∫øn s·ªë ƒë·ªÉ scaling")


@st.fragment
def balancing_fragment(data):
    """Fragment ƒë·ªÉ x·ª≠ l√Ω c√¢n b·∫±ng d·ªØ li·ªáu - kh√¥ng g√¢y rerun to√†n trang"""
    
    # Hi·ªÉn th·ªã th√¥ng b√°o th√†nh c√¥ng n·∫øu c√≥
    if st.session_state.get('_balance_success'):
        st.success(st.session_state._balance_success)
        del st.session_state._balance_success
    
    col_balance1, col_balance2 = st.columns([1, 1])
    
    with col_balance1:
        st.markdown("##### ‚öôÔ∏è C·∫•u H√¨nh Balancing")
        
        # Detect target column
        target_col_balance = st.session_state.get('target_column')
        
        if not target_col_balance:
            st.warning("‚ö†Ô∏è Ch∆∞a ch·ªçn c·ªôt target. Vui l√≤ng ch·ªçn target ·ªü ph·∫ßn Chia T·∫≠p Train/Valid/Test.")
            
            # Allow manual selection
            all_cols = st.session_state.data.columns.tolist()
            target_col_balance = st.selectbox(
                "Ch·ªçn target column:",
                all_cols,
                key="balance_target_select_frag"
            )
        else:
            st.success(f"üéØ Target column: `{target_col_balance}`")
        
        balance_method = st.selectbox(
            "Ph∆∞∆°ng ph√°p:",
            ["SMOTE", "Random Over-sampling", "Random Under-sampling", "No Balancing"],
            key="balance_method_frag",
            help="SMOTE: Synthetic Minority Over-sampling\nOver-sampling: Nh√¢n b·∫£n class thi·ªÉu s·ªë\nUnder-sampling: Gi·∫£m class ƒëa s·ªë"
        )
        
        # Sampling strategy
        sampling_strategy = st.selectbox(
            "Chi·∫øn l∆∞·ª£c sampling:",
            ["auto", "minority", "not majority", "all"],
            key="sampling_strategy_frag",
            help="auto: c√¢n b·∫±ng v·ªÅ class ƒëa s·ªë\nminority: ch·ªâ oversample class thi·ªÉu s·ªë\nnot majority: oversample t·∫•t c·∫£ tr·ª´ class ƒëa s·ªë"
        )
        
        if st.button("‚úÖ C√¢n B·∫±ng D·ªØ Li·ªáu", key="apply_balance_frag", width='stretch', type="primary"):
            if target_col_balance and target_col_balance in st.session_state.data.columns:
                try:
                    with st.spinner(f"ƒêang c√¢n b·∫±ng d·ªØ li·ªáu b·∫±ng {balance_method}..."):
                        # Import backend
                        from backend.data_processing.balancer import balance_data
                        
                        # Backup data before balancing
                        if 'column_backups' not in st.session_state:
                            st.session_state.column_backups = {}
                        st.session_state.column_backups['data_before_balance'] = st.session_state.data.copy()
                        
                        # Apply balancing to main dataset
                        balanced_data, balance_info = balance_data(
                            data=st.session_state.data,
                            target_column=target_col_balance,
                            method=balance_method,
                            random_state=42,
                            sampling_strategy=sampling_strategy
                        )
                        
                        # Update session state for main dataset
                        st.session_state.data = balanced_data
                        st.session_state.balance_info = balance_info
                        
                        # Also apply to train_data if it exists (to keep Analysis tab in sync)
                        if 'train_data' in st.session_state and st.session_state.train_data is not None:
                            try:
                                # Check if target column exists in train_data
                                if target_col_balance in st.session_state.train_data.columns:
                                    balanced_train, train_balance_info = balance_data(
                                        data=st.session_state.train_data,
                                        target_column=target_col_balance,
                                        method=balance_method,
                                        random_state=42,
                                        sampling_strategy=sampling_strategy
                                    )
                                    st.session_state.train_data = balanced_train
                            except Exception as e:
                                pass  # Silent fail for train data sync
                        
                        # Show size change
                        size_msg = ""
                        if balance_info.get('size_change', 0) != 0:
                            size_change = balance_info['size_change']
                            if size_change > 0:
                                size_msg = f" | üìà +{size_change} d√≤ng"
                            else:
                                size_msg = f" | üìâ {size_change} d√≤ng"
                        
                        st.session_state._balance_success = f"‚úÖ {balance_info['message']}{size_msg}"
                        st.rerun(scope="fragment")
                        
                except ImportError:
                    st.error("‚ùå Thi·∫øu th∆∞ vi·ªán imbalanced-learn. C√†i ƒë·∫∑t b·∫±ng: pip install imbalanced-learn")
                except Exception as e:
                    st.error(f"‚ùå L·ªói khi c√¢n b·∫±ng d·ªØ li·ªáu: {str(e)}")
                    import traceback
                    with st.expander("Chi ti·∫øt l·ªói"):
                        st.code(traceback.format_exc())
            else:
                st.warning("‚ö†Ô∏è Vui l√≤ng ch·ªçn target column h·ª£p l·ªá")
        
        # Undo button
        if st.session_state.get('balance_info'):
            st.markdown("---")
            if st.button("‚Ü©Ô∏è Ho√†n T√°c C√¢n B·∫±ng", key="undo_balance_frag", width='stretch'):
                if 'data_before_balance' in st.session_state.get('column_backups', {}):
                    st.session_state.data = st.session_state.column_backups['data_before_balance'].copy()
                    del st.session_state.column_backups['data_before_balance']
                    del st.session_state.balance_info
                    st.session_state._balance_success = "‚úÖ ƒê√£ ho√†n t√°c c√¢n b·∫±ng d·ªØ li·ªáu!"
                    st.rerun(scope="fragment")
    
    with col_balance2:
        st.markdown("##### üìä Ph√¢n B·ªï Class")
        
        # Get target column
        target_col_viz = st.session_state.get('target_column')
        
        if not target_col_viz:
            # Try to auto-detect
            potential_targets = [col for col in st.session_state.data.columns if 'target' in col.lower() or 'default' in col.lower() or 'label' in col.lower()]
            if potential_targets:
                target_col_viz = potential_targets[0]
        
        if target_col_viz and target_col_viz in st.session_state.data.columns:
            # Get class distribution
            from backend.data_processing.balancer import get_class_distribution, check_imbalance
            
            try:
                dist_info = get_class_distribution(st.session_state.data, target_col_viz)
                imbalance_check = check_imbalance(st.session_state.data, target_col_viz)
                
                # Display metrics
                st.metric("Target column", target_col_viz)
                
                col_m1, col_m2 = st.columns(2)
                with col_m1:
                    st.metric("S·ªë classes", dist_info['n_classes'])
                with col_m2:
                    st.metric("T·ª∑ l·ªá m·∫•t c√¢n b·∫±ng", f"{dist_info['imbalance_ratio']:.2f}")
                
                # Show distribution
                st.markdown("**üìã Ph√¢n b·ªï t·ª´ng class:**")
                for cls, count in dist_info['counts'].items():
                    pct = dist_info['percentages'][cls]
                    st.text(f"Class {cls}: {count:,} ({pct:.1f}%)")
                
                # Show imbalance warning
                if imbalance_check['is_imbalanced']:
                    st.warning(f"‚ö†Ô∏è Dataset m·∫•t c√¢n b·∫±ng! T·ª∑ l·ªá: {imbalance_check['imbalance_ratio']:.2f}")
                    st.info(f"üí° **G·ª£i √Ω:** {imbalance_check['recommendation']}")
                else:
                    st.success("‚úÖ Dataset t∆∞∆°ng ƒë·ªëi c√¢n b·∫±ng")
                
                # Show balance history if exists
                if st.session_state.get('balance_info'):
                    st.markdown("---")
                    st.markdown("**üìä L·ªãch S·ª≠ C√¢n B·∫±ng:**")
                    balance_info = st.session_state.balance_info
                    
                    st.markdown(f"""
                    <div style="background-color: #1a472a; padding: 0.8rem; border-radius: 6px;">
                        <small>
                        ‚úÖ Ph∆∞∆°ng ph√°p: <strong>{balance_info['method']}</strong><br>
                        üìè K√≠ch th∆∞·ªõc: {balance_info['original_size']:,} ‚Üí {balance_info['balanced_size']:,}<br>
                        üìä Ph√¢n b·ªï m·ªõi:
                        </small>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    for cls, count in balance_info['balanced_distribution'].items():
                        pct = (count / balance_info['balanced_size']) * 100
                        st.text(f"  Class {cls}: {count:,} ({pct:.1f}%)")
                    
            except Exception as e:
                st.error(f"L·ªói khi ph√¢n t√≠ch ph√¢n b·ªï: {str(e)}")
        else:
            st.info("üí° Ch∆∞a x√°c ƒë·ªãnh ƒë∆∞·ª£c target column. Vui l√≤ng ch·ªçn target ·ªü ph·∫ßn c·∫•u h√¨nh b√™n tr√°i.")


@st.fragment
def feature_selection_fragment(data):
    """Fragment ƒë·ªÉ ch·ªçn ƒë·∫∑c tr∆∞ng cho m√¥ h√¨nh - kh√¥ng g√¢y rerun to√†n trang"""
    
    # Hi·ªÉn th·ªã th√¥ng b√°o th√†nh c√¥ng n·∫øu c√≥
    if st.session_state.get('_feature_selection_success'):
        st.success(st.session_state._feature_selection_success)
        del st.session_state._feature_selection_success
    
    st.markdown("""
    <div style="background-color: #262730; padding: 1rem; border-radius: 8px; margin: 1rem 0;">
        <p style="margin: 0;">üìã <strong>Ch·ªçn c√°c ƒë·∫∑c tr∆∞ng</strong> b·∫°n mu·ªën s·ª≠ d·ª•ng ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh. 
        C√≥ th·ªÉ d·ª±a tr√™n feature importance ho·∫∑c ki·∫øn th·ª©c nghi·ªáp v·ª•.</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Get all columns except target
    all_cols = data.columns.tolist()
    
    # Assume last column is target (or let user select)
    col1, col2 = st.columns([1, 1])
    
    with col1:
        # Get current saved target from session state (set in Ti·ªÅn X·ª≠ L√Ω tab)
        current_target = st.session_state.get('target_column')
        
        if current_target and current_target in all_cols:
            st.success(f"üéØ C·ªôt target: **`{current_target}`**")
        else:
            st.warning("‚ö†Ô∏è Ch∆∞a ch·ªçn c·ªôt target. Vui l√≤ng quay l·∫°i tab **Ti·ªÅn X·ª≠ L√Ω** ƒë·ªÉ ch·ªçn target.")
            return
    
    with col2:
        st.metric("S·ªë bi·∫øn c√≥ s·∫µn", len(all_cols) - 1)
    
    # Get the saved target column from session state
    saved_target = current_target
    
    # Available features (exclude target)
    available_features = [col for col in all_cols if col != saved_target]
    
    # Feature selection
    st.markdown("#### üéØ Ch·ªçn ƒê·∫∑c Tr∆∞ng")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        selection_mode = st.radio(
            "Ch·∫ø ƒë·ªô ch·ªçn:",
            ["Ch·ªçn th·ªß c√¥ng", "Ch·ªçn t·ª± ƒë·ªông (theo threshold)"],
            key="selection_mode_frag"
        )
        
        if selection_mode == "Ch·ªçn t·ª± ƒë·ªông (theo threshold)":
            importance_threshold = st.slider(
                "Ng∆∞·ª°ng importance:",
                0.0, 1.0, 0.01, 0.01,
                key="importance_threshold_frag"
            )
            
            if st.button("üîÑ Ch·ªçn T·ª± ƒê·ªông", key="auto_select_frag"):
                # Mock auto selection
                num_selected = np.random.randint(5, min(15, len(available_features)))
                selected = np.random.choice(available_features, num_selected, replace=False).tolist()
                st.session_state.selected_features = selected
                st.session_state._feature_selection_success = f"‚úÖ ƒê√£ ch·ªçn t·ª± ƒë·ªông {len(selected)} ƒë·∫∑c tr∆∞ng!"
                st.rerun(scope="fragment")
    
    with col2:
        # Manual selection
        if selection_mode == "Ch·ªçn th·ªß c√¥ng":
            # Filter default values to only include valid options
            default_features = []
            if st.session_state.selected_features:
                default_features = [f for f in st.session_state.selected_features if f in available_features]
            if not default_features:
                default_features = available_features[:min(10, len(available_features))]
            
            selected_features = st.multiselect(
                "Ch·ªçn c√°c ƒë·∫∑c tr∆∞ng:",
                available_features,
                default=default_features,
                key="manual_features_frag"
            )
            
            if st.button("üíæ L∆∞u L·ª±a Ch·ªçn", key="save_selection_frag", type="primary"):
                st.session_state.selected_features = selected_features
                st.session_state._feature_selection_success = f"‚úÖ ƒê√£ l∆∞u {len(selected_features)} ƒë·∫∑c tr∆∞ng!"
                st.rerun(scope="fragment")
        else:
            # Display auto-selected features
            if st.session_state.selected_features:
                st.multiselect(
                    "ƒê·∫∑c tr∆∞ng ƒë√£ ch·ªçn:",
                    available_features,
                    default=[f for f in st.session_state.selected_features if f in available_features],
                    disabled=True,
                    key="auto_features_display_frag"
                )
    
    st.markdown("---")
    
    # Summary
    if st.session_state.selected_features:
        st.success(f"‚úÖ **ƒê√£ ch·ªçn {len(st.session_state.selected_features)} ƒë·∫∑c tr∆∞ng cho m√¥ h√¨nh**")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            numeric_selected = len([f for f in st.session_state.selected_features 
                                   if f in data.select_dtypes(include=[np.number]).columns])
            st.metric("Bi·∫øn s·ªë", numeric_selected)
        
        with col2:
            categorical_selected = len([f for f in st.session_state.selected_features 
                                       if f in data.select_dtypes(include=['object', 'category']).columns])
            st.metric("Bi·∫øn ph√¢n lo·∫°i", categorical_selected)
        
        with col3:
            st.metric("T·ªïng bi·∫øn", len(st.session_state.selected_features))
        
        # Display selected features
        with st.expander("üìã Xem Danh S√°ch ƒê·∫∑c Tr∆∞ng ƒê√£ Ch·ªçn"):
            for i, feat in enumerate(st.session_state.selected_features, 1):
                st.text(f"{i}. {feat}")
    else:
        st.warning("‚ö†Ô∏è Ch∆∞a ch·ªçn ƒë·∫∑c tr∆∞ng n√†o. Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt ƒë·∫∑c tr∆∞ng.")


def render():
    """Render trang x·ª≠ l√Ω v√† ch·ªçn bi·∫øn"""
    init_session_state()
    
    # Import permissions
    from utils.permissions import check_and_show_view_only
    
    st.markdown("## ‚öôÔ∏è X·ª≠ L√Ω & Ch·ªçn Bi·∫øn")
    st.markdown("Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu v√† l·ª±a ch·ªçn c√°c ƒë·∫∑c tr∆∞ng quan tr·ªçng cho m√¥ h√¨nh.")
    
    # Check view-only mode
    is_view_only = check_and_show_view_only("‚öôÔ∏è Feature Engineering")
    
    # Store in session state for fragment access
    st.session_state.fe_view_only = is_view_only
    
    # If view-only, show info and display read-only config summary
    if is_view_only:
        st.info("üìã **Ch·∫ø ƒë·ªô xem** - B·∫°n c√≥ th·ªÉ xem c·∫•u h√¨nh x·ª≠ l√Ω d·ªØ li·ªáu nh∆∞ng kh√¥ng th·ªÉ ch·ªânh s·ª≠a.")
    
    # Check if data exists
    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu. Vui l√≤ng upload d·ªØ li·ªáu t·ª´ trang 'Upload & EDA' tr∆∞·ªõc.")
        return
    
    # Initialize backup system - save original data on first visit
    if 'data_original_backup' not in st.session_state:
        st.session_state.data_original_backup = st.session_state.data.copy()
        st.session_state.column_backups = {}  # Store backup before each column processing
    
    data = st.session_state.data
    
    # Show data selector if processed data exists
    if st.session_state.get('processed_data') is not None:
        col_selector1, col_selector2 = st.columns([3, 1])
        with col_selector1:
            st.success(f"‚úÖ ƒêang l√†m vi·ªác v·ªõi dataset: {len(data)} d√≤ng, {len(data.columns)} c·ªôt")
        with col_selector2:
            data_view = st.selectbox(
                "Xem d·ªØ li·ªáu:",
                ["Original", "Processed"],
                key="data_view_selector",
                help="Ch·ªçn xem d·ªØ li·ªáu g·ªëc ho·∫∑c ƒë√£ x·ª≠ l√Ω"
            )
            if data_view == "Processed":
                data = st.session_state.processed_data
                st.info(f"üìä Processed: {len(data)} d√≤ng")
    else:
        st.success(f"‚úÖ ƒêang l√†m vi·ªác v·ªõi dataset: {len(data)} d√≤ng, {len(data.columns)} c·ªôt")
    
    # Add clear configuration button
    col_status1, col_status2, col_status3 = st.columns([2, 1, 1])
    with col_status2:
        # Show number of configurations
        total_configs = (
            len(st.session_state.get('missing_config', {})) +
            len(st.session_state.get('encoding_config', {})) +
            len(st.session_state.get('binning_config', {}))
        )
        if total_configs > 0:
            st.info(f"üìã {total_configs} c·∫•u h√¨nh ƒë√£ l∆∞u")
    
    with col_status3:
        if total_configs > 0:
            if st.button("Ho√†n V·ªÅ Ban ƒê·∫ßu", key="clear_all_configs", help="X√≥a t·∫•t c·∫£ c·∫•u h√¨nh v√† ho√†n v·ªÅ d·ªØ li·ªáu g·ªëc", type="primary"):
                # Restore original data
                st.session_state.data = st.session_state.data_original_backup.copy()
                # Clear all configs
                st.session_state.removed_columns_config = {}
                st.session_state.missing_config = {}
                st.session_state.encoding_config = {}
                st.session_state.scaling_config = {}
                st.session_state.outlier_config = {}
                st.session_state.binning_config = {}
                st.session_state.validation_config = {}
                # Clear column backups
                st.session_state.column_backups = {}
                st.session_state.removed_columns_backup = {}
                st.success("‚úÖ ƒê√£ ho√†n v·ªÅ d·ªØ li·ªáu ban ƒë·∫ßu!")
                st.rerun()
    
    st.markdown("---")
    
    # Tabs for different processing steps
    tab1, tab2, tab3 = st.tabs([
        "üîß Ti·ªÅn X·ª≠ L√Ω",
        "üìä Ph√¢n T√≠ch & ƒê√°nh Gi√°",
        "‚úÖ Ch·ªçn Bi·∫øn"
    ])
    
    # Tab 1: Preprocessing
    with tab1:
        st.markdown("### üîß C√°c B∆∞·ªõc Ti·ªÅn X·ª≠ L√Ω")
        
        # ============ DASHBOARD T·ªîNG H·ª¢P C·∫§U H√åNH ============
        dashboard_header_col1, dashboard_header_col2 = st.columns([4, 1])
        with dashboard_header_col1:
            st.markdown("#### üìä Dashboard Theo D√µi C·∫•u H√¨nh")
        with dashboard_header_col2:
            if st.button("üîÑ L√†m M·ªõi", key="refresh_dashboard_top", help="L√†m m·ªõi Dashboard ƒë·ªÉ xem c√°c thay ƒë·ªïi m·ªõi nh·∫•t", type="primary"):
                st.rerun()
        
        # Count all configurations
        total_configs = (
            (1 if st.session_state.get('split_config') else 0) +
            len(st.session_state.get('removed_columns_config', {})) +
            len(st.session_state.get('missing_config', {})) +
            len(st.session_state.get('outlier_config', {}).get('columns', [])) +
            len(st.session_state.get('encoding_config', {})) +
            len(st.session_state.get('validation_config', {})) +
            len(st.session_state.get('binning_config', {})) +
            len(st.session_state.get('scaling_config', {})) +
            (1 if st.session_state.get('balance_info') else 0)
        )
        
        if total_configs > 0:
            # Summary cards - use 2 rows for better layout
            st.markdown("##### üìà T·ªïng Quan")
            status_row0_col1, status_row0_col2, status_row0_col3, status_row0_col4 = st.columns(4)
            status_row1_col1, status_row1_col2, status_row1_col3, status_row1_col4 = st.columns(4)
            status_row2_col1, status_row2_col2, status_row2_col3, status_row2_col4 = st.columns(4)
            
            # Row 0 - Split info
            with status_row0_col1:
                split_applied = 1 if st.session_state.get('split_config') else 0
                st.metric("‚úÇÔ∏è Chia T·∫≠p", "ƒê√£ chia" if split_applied else "Ch∆∞a chia")
            
            with status_row0_col2:
                removed_cols = len(st.session_state.get('removed_columns_config', {}))
                st.metric("üóëÔ∏è Lo·∫°i B·ªè C·ªôt", removed_cols if removed_cols > 0 else "0")
            
            with status_row0_col3:
                validation_configs = len(st.session_state.get('validation_config', {}))
                st.metric("‚úÖ Validation", validation_configs if validation_configs > 0 else "0")
            
            with status_row0_col4:
                missing_configs = len(st.session_state.get('missing_config', {}))
                st.metric("üìù Missing Values", missing_configs if missing_configs > 0 else "0")
            
            # Row 1
            with status_row1_col1:
                outlier_configs = len(st.session_state.get('outlier_config', {}).get('columns', []))
                st.metric("‚ö†Ô∏è Outliers", outlier_configs if outlier_configs > 0 else "0")
            
            with status_row1_col2:
                encoding_configs = len(st.session_state.get('encoding_config', {}))
                st.metric("üî§ Encoding", encoding_configs if encoding_configs > 0 else "0")
            
            with status_row1_col3:
                binning_configs = len(st.session_state.get('binning_config', {}))
                st.metric("üìä Binning", binning_configs if binning_configs > 0 else "0")
            
            with status_row1_col4:
                scaling_configs = len(st.session_state.get('scaling_config', {}))
                st.metric("üìè Scaling", scaling_configs if scaling_configs > 0 else "0")
            
            # Row 2
            with status_row2_col1:
                balance_applied = 1 if st.session_state.get('balance_info') else 0
                st.metric("‚öñÔ∏è Balancing", "ƒê√£ √°p d·ª•ng" if balance_applied else "Ch∆∞a c√≥")
            
            # Detailed configuration table
            st.markdown("##### üìã Chi Ti·∫øt C·∫•u H√¨nh ƒê√£ L∆∞u")
            
            # Create a container for configurations with undo buttons
            config_count = 0
            
            # Split config - hi·ªÉn th·ªã ƒë·∫ßu ti√™n
            if st.session_state.get('split_config'):
                config_count += 1
                split_cfg = st.session_state.split_config
                train_size = len(st.session_state.train_data) if st.session_state.get('train_data') is not None else 0
                valid_size = len(st.session_state.valid_data) if st.session_state.get('valid_data') is not None else 0
                test_size = len(st.session_state.test_data) if st.session_state.get('test_data') is not None else 0
                
                col1, col2, col3, col4, col5, col6 = st.columns([1.5, 1.5, 2, 1.5, 1.5, 0.8])
                
                with col1:
                    st.markdown(f"**2Ô∏è‚É£ Chia T·∫≠p**")
                with col2:
                    st.markdown(f"`{split_cfg.get('target_column', 'N/A')}`")
                with col3:
                    st.markdown(f"Train {split_cfg.get('train_ratio')}% | Valid {split_cfg.get('valid_ratio')}% | Test {split_cfg.get('test_ratio')}%")
                with col4:
                    st.markdown(f"{train_size:,} | {valid_size:,} | {test_size:,}")
                with col5:
                    st.markdown("‚úÖ **ƒê√£ √°p d·ª•ng**")
                with col6:
                    if st.button("‚Ü©Ô∏è", key="undo_split", help="Ho√†n t√°c chia t·∫≠p - Merge l·∫°i th√†nh m·ªôt"):
                        # Merge all back
                        all_data = pd.concat([
                            st.session_state.train_data,
                            st.session_state.valid_data if st.session_state.get('valid_data') is not None else pd.DataFrame(),
                            st.session_state.test_data if st.session_state.get('test_data') is not None else pd.DataFrame()
                        ], ignore_index=True)
                        
                        st.session_state.data = all_data
                        st.session_state.train_data = None
                        st.session_state.valid_data = None
                        st.session_state.test_data = None
                        st.session_state.split_config = None
                        
                        st.success("‚úÖ ƒê√£ merge t·∫•t c·∫£ t·∫≠p l·∫°i th√†nh m·ªôt!")
                        st.rerun()
                
                st.markdown("---")
            
            # Removed columns
            for col, cfg in st.session_state.get('removed_columns_config', {}).items():
                config_count += 1
                col1, col2, col3, col4, col5, col6 = st.columns([1.5, 1.5, 2, 1.5, 1.5, 0.8])
                
                with col1:
                    st.markdown(f"**3Ô∏è‚É£ Lo·∫°i B·ªè C·ªôt**")
                with col2:
                    st.markdown(f"`{col}`")
                with col3:
                    st.markdown(f"{cfg.get('reason', 'Lo·∫°i b·ªè')}")
                with col4:
                    st.markdown(f"unique={cfg.get('unique_count', 'N/A')}")
                with col5:
                    st.markdown("‚úÖ **ƒê√£ √°p d·ª•ng**")
                with col6:
                    if st.button("‚Ü©Ô∏è", key=f"undo_removed_{col}", help=f"Ho√†n t√°c lo·∫°i b·ªè c·ªôt {col}"):
                        # Restore column from backup
                        if col in st.session_state.get('removed_columns_backup', {}):
                            st.session_state.data[col] = st.session_state.removed_columns_backup[col]
                            del st.session_state.removed_columns_backup[col]
                            del st.session_state.removed_columns_config[col]
                            st.success(f"‚úÖ ƒê√£ kh√¥i ph·ª•c c·ªôt `{col}`")
                            st.rerun()
                
                st.markdown("---")
            
            # Missing configs
            for col, cfg in st.session_state.get('missing_config', {}).items():
                config_count += 1
                col1, col2, col3, col4, col5, col6 = st.columns([1.5, 1.5, 2, 1.5, 1.5, 0.8])
                
                with col1:
                    st.markdown(f"**4Ô∏è‚É£ Missing Values**")
                with col2:
                    st.markdown(f"`{col}`")
                with col3:
                    st.markdown(f"{cfg.get('method', 'N/A')}")
                with col4:
                    fill_val = cfg.get('fill_value', cfg.get('constant', 'N/A'))
                    st.markdown(f"{fill_val}")
                with col5:
                    is_applied = cfg.get('processed', False)
                    if is_applied:
                        applied_to_all = cfg.get('applied_to_all', False)
                        if applied_to_all:
                            st.markdown("‚úÖ **Train/Valid/Test**")
                        else:
                            st.markdown("‚úÖ **ƒê√£ √°p d·ª•ng**")
                    else:
                        st.markdown("‚è≥ **Ch·ªù √°p d·ª•ng**")
                with col6:
                    if st.button("üóëÔ∏è", key=f"delete_missing_{col}", help=f"X√≥a c·∫•u h√¨nh {col}"):
                        del st.session_state.missing_config[col]
                        st.success(f"‚úÖ ƒê√£ x√≥a c·∫•u h√¨nh")
                        st.rerun()
                
                st.markdown("---")
            
            # Outlier configs
            if st.session_state.get('outlier_config'):
                outlier_cfg = st.session_state.outlier_config
                details = outlier_cfg.get('details', {})
                
                for col in outlier_cfg.get('columns', []):
                    config_count += 1
                    col_detail = details.get(col, {})
                    is_applied = col_detail.get('applied', False)
                    
                    col1, col2, col3, col4, col5, col6 = st.columns([1.5, 1.5, 2, 1.5, 1.5, 0.8])
                    
                    with col1:
                        st.markdown(f"**5Ô∏è‚É£ Outliers**")
                    with col2:
                        st.markdown(f"`{col}`")
                    with col3:
                        st.markdown(f"{col_detail.get('method', 'N/A')}")
                    with col4:
                        st.markdown(f"Action: {col_detail.get('action', 'N/A')}")
                    with col5:
                        if is_applied:
                            applied_to_all = col_detail.get('applied_to_all', False)
                            if applied_to_all:
                                st.markdown("‚úÖ **Train/Valid/Test**")
                            else:
                                st.markdown("‚úÖ **ƒê√£ √°p d·ª•ng**")
                        else:
                            st.markdown("‚è≥ **Ch·ªù √°p d·ª•ng**")
                    with col6:
                        backup_key = f"outlier_{col}" if f"outlier_{col}" in st.session_state.get('outlier_backup', {}) else col
                        if is_applied and backup_key in st.session_state.get('outlier_backup', {}):
                            if st.button("‚Ü©Ô∏è", key=f"undo_outlier_{col}", help=f"Ho√†n t√°c x·ª≠ l√Ω outlier {col}"):
                                # Restore column from backup
                                backup = st.session_state.outlier_backup[backup_key]
                                if isinstance(backup, dict):
                                    st.session_state.data[col] = backup.get('data')
                                    if backup.get('train_data') is not None:
                                        st.session_state.train_data[col] = backup['train_data']
                                    if backup.get('valid_data') is not None:
                                        st.session_state.valid_data[col] = backup['valid_data']
                                    if backup.get('test_data') is not None:
                                        st.session_state.test_data[col] = backup['test_data']
                                else:
                                    st.session_state.data[col] = backup
                                del st.session_state.outlier_backup[backup_key]
                                # Remove from outlier config
                                st.session_state.outlier_config['columns'].remove(col)
                                if col in st.session_state.outlier_config.get('details', {}):
                                    del st.session_state.outlier_config['details'][col]
                                if not st.session_state.outlier_config['columns']:
                                    st.session_state.outlier_config = {}
                                st.success(f"‚úÖ ƒê√£ ho√†n t√°c x·ª≠ l√Ω outlier cho `{col}`")
                                st.rerun()
                    
                    st.markdown("---")
            
            # Encoding configs
            for col, cfg in st.session_state.get('encoding_config', {}).items():
                config_count += 1
                col1, col2, col3, col4, col5, col6 = st.columns([1.5, 1.5, 2, 1.5, 1.5, 0.8])
                
                params_str = ''
                if 'params' in cfg:
                    params = cfg['params']
                    if 'drop_first' in params:
                        params_str = f"drop_first={params['drop_first']}"
                    elif 'target_column' in params:
                        params_str = f"target={params['target_column']}"
                
                is_applied = cfg.get('applied', False)
                
                with col1:
                    st.markdown(f"**6Ô∏è‚É£ Encoding**")
                with col2:
                    st.markdown(f"`{col}`")
                with col3:
                    st.markdown(f"{cfg.get('method', 'N/A')}")
                with col4:
                    st.markdown(f"{params_str or 'default'}")
                with col5:
                    if is_applied:
                        applied_to_all = cfg.get('applied_to_all', False)
                        if applied_to_all:
                            st.markdown("‚úÖ **Train/Valid/Test**")
                        else:
                            st.markdown("‚úÖ **ƒê√£ √°p d·ª•ng**")
                    else:
                        st.markdown("‚è≥ **Ch·ªù √°p d·ª•ng**")
                with col6:
                    if is_applied and f"encoding_{col}" in st.session_state.get('column_backups', {}):
                        if st.button("‚Ü©Ô∏è", key=f"undo_encoding_{col}", help=f"Ho√†n t√°c m√£ h√≥a {col}"):
                            # Restore original column
                            backup_key = f"encoding_{col}"
                            st.session_state.data[col] = st.session_state.column_backups[backup_key]
                            del st.session_state.column_backups[backup_key]
                            
                            # Remove encoded columns if One-Hot
                            if col in st.session_state.get('encoding_applied_info', {}):
                                enc_info = st.session_state.encoding_applied_info[col]
                                if 'new_columns' in enc_info:
                                    for new_col in enc_info['new_columns']:
                                        if new_col in st.session_state.data.columns:
                                            st.session_state.data.drop(columns=[new_col], inplace=True)
                                del st.session_state.encoding_applied_info[col]
                            
                            # Remove from encoding config
                            del st.session_state.encoding_config[col]
                            st.success(f"‚úÖ ƒê√£ ho√†n t√°c m√£ h√≥a cho `{col}`")
                            st.rerun()
                    elif not is_applied:
                        if st.button("üóëÔ∏è", key=f"delete_encoding_{col}", help=f"X√≥a c·∫•u h√¨nh {col}"):
                            del st.session_state.encoding_config[col]
                            st.success(f"‚úÖ ƒê√£ x√≥a c·∫•u h√¨nh")
                            st.rerun()
                
                st.markdown("---")
            
            # Validation configs
            for col, cfg in st.session_state.get('validation_config', {}).items():
                config_count += 1
                col1, col2, col3, col4, col5, col6 = st.columns([1.5, 1.5, 2, 1.5, 1.5, 0.8])
                
                is_applied = cfg.get('applied', False)
                
                with col1:
                    st.markdown(f"**3Ô∏è‚É£ Validation**")
                with col2:
                    st.markdown(f"`{col}`")
                with col3:
                    st.markdown(f"{cfg.get('type', 'N/A')}")
                with col4:
                    st.markdown(f"{cfg.get('threshold', cfg.get('value', 'N/A'))}")
                with col5:
                    if is_applied:
                        applied_to_all = cfg.get('applied_to_all', False)
                        if applied_to_all:
                            st.markdown("‚úÖ **Train/Valid/Test**")
                        else:
                            st.markdown("‚úÖ **ƒê√£ √°p d·ª•ng**")
                    else:
                        st.markdown("‚è≥ **Ch·ªù √°p d·ª•ng**")
                with col6:
                    if is_applied and f"validation_{col}" in st.session_state.get('column_backups', {}):
                        if st.button("‚Ü©Ô∏è", key=f"undo_validation_{col}", help=f"Ho√†n t√°c validation {col}"):
                            # Restore column from backup
                            backup_key = f"validation_{col}"
                            st.session_state.data[col] = st.session_state.column_backups[backup_key]
                            del st.session_state.column_backups[backup_key]
                            del st.session_state.validation_config[col]
                            st.success(f"‚úÖ ƒê√£ ho√†n t√°c validation cho `{col}`")
                            st.rerun()
                    elif not is_applied:
                        if st.button("üóëÔ∏è", key=f"delete_validation_{col}", help=f"X√≥a c·∫•u h√¨nh {col}"):
                            del st.session_state.validation_config[col]
                            st.success(f"‚úÖ ƒê√£ x√≥a c·∫•u h√¨nh")
                            st.rerun()
                
                st.markdown("---")
            
            # Binning configs
            for col, cfg in st.session_state.get('binning_config', {}).items():
                config_count += 1
                col1, col2, col3, col4, col5, col6 = st.columns([1.5, 1.5, 2, 1.5, 1.5, 0.8])
                
                is_applied = cfg.get('applied', False)
                
                with col1:
                    st.markdown(f"**7Ô∏è‚É£ Binning**")
                with col2:
                    st.markdown(f"`{col}`")
                with col3:
                    st.markdown(f"{cfg.get('method', 'N/A')}")
                with col4:
                    st.markdown(f"‚Üí `{cfg.get('new_column', 'N/A')}`")
                with col5:
                    if is_applied:
                        st.markdown("‚úÖ **ƒê√£ √°p d·ª•ng**")
                    else:
                        st.markdown("‚è≥ **Ch·ªù √°p d·ª•ng**")
                with col6:
                    if is_applied:
                        if st.button("üóëÔ∏è", key=f"delete_binning_{col}", help=f"X√≥a c·ªôt binned {cfg.get('new_column')}"):
                            # Remove binned column from data
                            new_col = cfg.get('new_column')
                            if new_col and new_col in st.session_state.data.columns:
                                st.session_state.data.drop(columns=[new_col], inplace=True)
                            del st.session_state.binning_config[col]
                            st.success(f"‚úÖ ƒê√£ x√≥a c·ªôt `{new_col}`")
                            st.rerun()
                
                st.markdown("---")
            
            # Scaling configs
            for col, cfg in st.session_state.get('scaling_config', {}).items():
                config_count += 1
                col1, col2, col3, col4, col5, col6 = st.columns([1.5, 1.5, 2, 1.5, 1.5, 0.8])
                
                is_applied = cfg.get('applied', False)
                
                with col1:
                    st.markdown(f"**8Ô∏è‚É£ Scaling**")
                with col2:
                    st.markdown(f"`{col}`")
                with col3:
                    st.markdown(f"{cfg.get('method', 'N/A')}")
                with col4:
                    range_str = f"[{cfg.get('feature_range', [0, 1])[0]}, {cfg.get('feature_range', [0, 1])[1]}]" if 'feature_range' in cfg else 'standard'
                    st.markdown(f"{range_str}")
                with col5:
                    if is_applied:
                        applied_to_all = cfg.get('applied_to_all', False)
                        if applied_to_all:
                            st.markdown("‚úÖ **Train/Valid/Test**")
                        else:
                            st.markdown("‚úÖ **ƒê√£ √°p d·ª•ng**")
                    else:
                        st.markdown("‚è≥ **Ch·ªù √°p d·ª•ng**")
                with col6:
                    if is_applied and f"scaling_{col}" in st.session_state.get('column_backups', {}):
                        if st.button("‚Ü©Ô∏è", key=f"undo_scaling_{col}", help=f"Ho√†n t√°c scaling {col}"):
                            # Restore column from backup
                            backup_key = f"scaling_{col}"
                            st.session_state.data[col] = st.session_state.column_backups[backup_key]
                            del st.session_state.column_backups[backup_key]
                            del st.session_state.scaling_config[col]
                            st.success(f"‚úÖ ƒê√£ ho√†n t√°c scaling cho `{col}`")
                            st.rerun()
                
                st.markdown("---")
            
            # Balancing config
            if st.session_state.get('balance_info'):
                config_count += 1
                balance_info = st.session_state.balance_info
                
                col1, col2, col3, col4, col5, col6 = st.columns([1.5, 1.5, 2, 1.5, 1.5, 0.8])
                
                with col1:
                    st.markdown(f"**9Ô∏è‚É£ Balancing**")
                with col2:
                    st.markdown(f"`Dataset`")
                with col3:
                    st.markdown(f"{balance_info.get('method', 'N/A')}")
                with col4:
                    size_change = balance_info.get('size_change', 0)
                    change_str = f"+{size_change}" if size_change > 0 else f"{size_change}"
                    st.markdown(f"{change_str} d√≤ng")
                with col5:
                    st.markdown("‚úÖ **ƒê√£ √°p d·ª•ng**")
                with col6:
                    if st.button("‚Ü©Ô∏è", key=f"undo_balancing", help="Ho√†n t√°c c√¢n b·∫±ng d·ªØ li·ªáu"):
                        # Restore from backup if exists
                        if 'data_before_balance' in st.session_state.get('column_backups', {}):
                            st.session_state.data = st.session_state.column_backups['data_before_balance'].copy()
                            del st.session_state.column_backups['data_before_balance']
                            del st.session_state.balance_info
                            st.success(f"‚úÖ ƒê√£ ho√†n t√°c c√¢n b·∫±ng d·ªØ li·ªáu")
                            st.rerun()
                
                st.markdown("---")
            
            if config_count == 0:
                st.info("üí° Ch∆∞a c√≥ c·∫•u h√¨nh n√†o. H√£y th√™m c·∫•u h√¨nh ·ªü c√°c b∆∞·ªõc b√™n d∆∞·ªõi.")
            
            # Action buttons
            st.markdown("---")
            action_col1, action_col2, action_col3 = st.columns(3)
            
            with action_col1:
                # Scroll to top button using JavaScript
                st.markdown("""
                <a href="#" onclick="window.parent.document.querySelector('section.main').scrollTo(0, 0); return false;" 
                   style="display: inline-block; padding: 0.5rem 1rem; background-color: #262730; color: white; 
                          text-decoration: none; border-radius: 0.5rem; text-align: center; width: 100%;
                          border: 1px solid #4a4a5a;">
                    ‚¨ÜÔ∏è L√™n ƒê·∫ßu Trang
                </a>
                """, unsafe_allow_html=True)
            
            with action_col2:
                # Export configuration as JSON
                if st.button("üì• Xu·∫•t C·∫•u H√¨nh", key="export_config", width='stretch'):
                    import json
                    config_export = {
                        'removed_columns': st.session_state.get('removed_columns_config', {}),
                        'validation': st.session_state.get('validation_config', {}),
                        'missing': st.session_state.get('missing_config', {}),
                        'outlier': st.session_state.get('outlier_config', {}),
                        'encoding': st.session_state.get('encoding_config', {})
                    }
                    config_json = json.dumps(config_export, indent=2, default=str)
                    st.download_button(
                        "üíæ T·∫£i JSON",
                        config_json,
                        "preprocessing_config.json",
                        "application/json",
                        key="download_config_json"
                    )
            
            with action_col3:
                # Clear all pending configs
                pending_missing = len([c for c in st.session_state.get('missing_config', {}).items() if not c[1].get('applied')])
                pending_encoding = len([c for c in st.session_state.get('encoding_config', {}).items() if not c[1].get('applied')])
                pending_validation = len([c for c in st.session_state.get('validation_config', {}).items() if not c[1].get('applied')])
                pending_count = pending_missing + pending_encoding + pending_validation
                
                if pending_count > 0:
                    if st.button(f"üóëÔ∏è X√≥a {pending_count} Ch·ªù √Åp D·ª•ng", key="clear_pending", width='stretch', type="secondary"):
                        # Clear only pending configs
                        # Keep applied encoding configs
                        st.session_state.encoding_config = {
                            col: cfg for col, cfg in st.session_state.get('encoding_config', {}).items()
                            if cfg.get('applied', False)
                        }
                        # Keep applied validation configs
                        st.session_state.validation_config = {
                            col: cfg for col, cfg in st.session_state.get('validation_config', {}).items()
                            if cfg.get('applied', False)
                        }
                        # Clear pending missing configs
                        st.session_state.missing_config = {}
                        st.success(f"‚úÖ ƒê√£ x√≥a {pending_count} c·∫•u h√¨nh ch·ªù √°p d·ª•ng!")
                        st.rerun()
            
            # Summary statistics
            st.markdown("---")
            summary_col1, summary_col2, summary_col3 = st.columns(3)
            
            with summary_col1:
                pending = pending_count if 'pending_count' in locals() else 0
                st.info(f"‚è≥ **{pending}** c·∫•u h√¨nh ch·ªù √°p d·ª•ng")
            
            with summary_col2:
                applied = (
                    len(st.session_state.get('removed_columns_config', {})) +
                    len([c for c in st.session_state.get('encoding_config', {}).items() if c[1].get('applied')]) +
                    len([c for c in st.session_state.get('validation_config', {}).items() if c[1].get('applied')]) +
                    (len(st.session_state.get('outlier_config', {}).get('columns', [])) if 'info' in st.session_state.get('outlier_config', {}) else 0)
                )
                st.success(f"‚úÖ **{applied}** c·∫•u h√¨nh ƒë√£ √°p d·ª•ng")
            
            with summary_col3:
                total = applied + pending
                st.metric("üìä T·ªïng c·ªông", f"{total} c·∫•u h√¨nh")
            
            st.markdown("---")
        else:
            st.info("üí° Ch∆∞a c√≥ c·∫•u h√¨nh n√†o ƒë∆∞·ª£c l∆∞u. H√£y b·∫Øt ƒë·∫ßu th√™m c·∫•u h√¨nh ·ªü c√°c b∆∞·ªõc b√™n d∆∞·ªõi!")
            st.markdown("---")
        
        # ============ END DASHBOARD ============
        
        st.markdown("### 1Ô∏è‚É£ T·ªïng Quan D·ªØ Li·ªáu Thi·∫øu")
        
        # Calculate missing data
        missing_data = data.isnull().sum()
        missing_data = missing_data[missing_data > 0].sort_values(ascending=False)
        
        col1, col2 = st.columns([1, 1]) # t·ªâ l·ªá 2 b√™n tr√°i ph·∫£i
        
        with col1:
            if len(missing_data) > 0:
                st.warning(f"‚ö†Ô∏è C√≥ {len(missing_data)} c·ªôt ch·ª©a gi√° tr·ªã thi·∫øu")
                
                # Display missing data summary
                missing_df = pd.DataFrame({
                    'C·ªôt': missing_data.index,
                    'S·ªë l∆∞·ª£ng thi·∫øu': missing_data.values,
                    'T·ª∑ l·ªá (%)': (missing_data.values / len(data) * 100).round(2)
                })
                st.dataframe(missing_df, width='stretch', hide_index=True)
            
            else:
                st.success("‚úÖ Kh√¥ng c√≥ gi√° tr·ªã thi·∫øu trong dataset")
        
        with col2:
            # Show missing patterns if data has missing
            missing_data_temp = data.isnull().sum()
            missing_data_temp = missing_data_temp[missing_data_temp > 0]
            
            if len(missing_data_temp) > 0:
                st.markdown("##### üìà Ph√¢n T√≠ch M·∫´u Thi·∫øu")
                
                # Calculate missing percentage by column
                missing_pct_chart = (missing_data_temp / len(data) * 100).sort_values(ascending=False)
                
                # Create simple bar chart
                import plotly.express as px
                fig = px.bar(
                    x=missing_pct_chart.values,
                    y=missing_pct_chart.index,
                    orientation='h',
                    labels={'x': 'T·ª∑ l·ªá (%)', 'y': 'C·ªôt'},
                    title="T·ª∑ l·ªá d·ªØ li·ªáu thi·∫øu theo c·ªôt"
                )
                fig.update_layout(
                    template="plotly_dark",
                    height=400, # chi·ªÅu cao bi·ªÉu ƒë·ªì
                    showlegend=False,
                    margin=dict(l=0, r=0, t=30, b=0)
                )
                fig.update_traces(marker_color='#ff6b6b')
                st.plotly_chart(fig, width='stretch')
            else:
                st.success("‚ú® D·ªØ li·ªáu ho√†n ch·ªânh, kh√¥ng c√≥ gi√° tr·ªã thi·∫øu!")

            # Import streamlit components
            import streamlit.components.v1 as components
            
            # Initialize modal state
            if 'show_suggestions_modal' not in st.session_state:
                st.session_state.show_suggestions_modal = False
            
            suggestions = st.session_state.get("preprocessing_suggestions")
            
            # Generate suggestions content
            if suggestions:
                suggestions_content = f"""<h4 style="margin-top: 0; color: #3b82f6; font-size: 1.1rem;">üí° G·ª£i √ù X·ª≠ L√Ω (AI)</h4>
<div style="font-size: 0.9rem;">
{suggestions}
</div>"""
            else:
                suggestions_content = """<h4 style="margin-top: 0; color: #3b82f6; font-size: 1.1rem;">üí° G·ª£i √ù X·ª≠ L√Ω</h4>
<ul style="font-size: 0.9rem; margin-bottom: 0;">
<li><strong>Mean</strong>: T·ªët cho d·ªØ li·ªáu ph√¢n ph·ªëi chu·∫©n</li>
<li><strong>Median</strong>: T·ªët khi c√≥ outliers</li>
<li><strong>Mode</strong>: Cho bi·∫øn ph√¢n lo·∫°i</li>
<li><strong>Forward/Backward Fill</strong>: Cho time series</li>
<li><strong>Interpolation</strong>: Cho d·ªØ li·ªáu li√™n t·ª•c</li>
</ul>"""
            
            # Add floating button with pure HTML/CSS
            st.markdown(f"""
<style>
.floating-btn-container {{
    position: fixed;
    bottom: 80px;
    right: 30px;
    z-index: 9999;
}}

.floating-btn {{
    background-color: #1e3a5f;
    color: white;
    border: 2px solid #3b82f6;
    border-radius: 50px;
    padding: 12px 20px;
    font-size: 14px;
    font-weight: 600;
    cursor: pointer;
    box-shadow: 0 4px 15px rgba(30, 58, 95, 0.4);
    transition: all 0.3s ease;
    display: inline-block;
}}

.floating-btn:hover {{
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(59, 130, 246, 0.6);
    background-color: #2d4a7c;
}}

.modal-overlay {{
    display: none;
    position: fixed;
    z-index: 10000;
    left: 0;
    top: 0;
    width: 100%;
    height: 100%;
    background-color: rgba(0,0,0,0.7);
    animation: fadeIn 0.3s;
}}

.modal-overlay.show {{
    display: flex !important;
    align-items: center;
    justify-content: center;
}}

.modal-content {{
    background-color: #1e1e1e;
    border-radius: 12px;
    width: 90%;
    max-width: 800px;
    box-shadow: 0 8px 32px rgba(0,0,0,0.4);
    animation: slideDown 0.3s;
    max-height: 80vh;
    overflow-y: auto;
}}

.modal-header {{
    padding: 20px 30px;
    background-color: #1e3a5f;
    border: 2px solid #3b82f6;
    color: white;
    border-radius: 12px 12px 0 0;
    display: flex;
    justify-content: space-between;
    align-items: center;
}}

.modal-body {{
    padding: 30px;
    color: #e0e0e0;
}}

            .close-btn {{
                color: white;
                font-size: 28px;
                font-weight: bold;
                cursor: pointer;
                background: none;
                border: none;
                width: 32px;
                height: 32px;
                border-radius: 50%;
                transition: background 0.3s;
                display: flex;
                align-items: center;
                justify-content: center;
                line-height: 1;
                padding-bottom: 2px;
            }}.close-btn:hover {{
    background: rgba(59, 130, 246, 0.3);
}}

@keyframes fadeIn {{
    from {{ opacity: 0; }}
    to {{ opacity: 1; }}
}}

@keyframes slideDown {{
    from {{
        transform: translateY(-50px);
        opacity: 0;
    }}
    to {{
        transform: translateY(0);
        opacity: 1;
    }}
}}
</style>

<div class="floating-btn-container">
    <button class="floating-btn" id="openSuggestionsBtn">
        üí° G·ª£i √ù & Th·ªëng K√™
    </button>
</div>

<div id="suggestionsModal" class="modal-overlay">
    <div class="modal-content" id="suggestionsModalContent">
        <div class="modal-header">
            <h3 style="margin: 0;">üìä G·ª£i √ù & Th·ªëng K√™</h3>
            <button class="close-btn" id="closeSuggestionsBtn">&times;</button>
        </div>
        <div class="modal-body">
            <div style="background-color: #262730; padding: 1.2rem; border-radius: 10px; border-left: 4px solid #3b82f6;">
{suggestions_content}
            </div>
        </div>
    </div>
</div>
""", unsafe_allow_html=True)
            
            # Inject JS via components.html to ensure execution
            components.html("""
            <script>
                (function() {
                    console.log("üöÄ Script started from iframe");
                    
                    function getDoc() {
                        try {
                            return window.parent.document;
                        } catch (e) {
                            console.error("Cannot access parent document", e);
                            return document;
                        }
                    }

                    var doc = getDoc();

                    function openModal() {
                        console.log("üîò openModal called");
                        var modal = doc.getElementById('suggestionsModal');
                        if (modal) {
                            modal.classList.add('show');
                            modal.style.display = 'flex';
                        }
                    }
                    
                    function closeModal() {
                        console.log("üîò closeModal called");
                        var modal = doc.getElementById('suggestionsModal');
                        if (modal) {
                            modal.classList.remove('show');
                            modal.style.display = 'none';
                        }
                    }

                    function attachEvents() {
                        var openBtn = doc.getElementById('openSuggestionsBtn');
                        var closeBtn = doc.getElementById('closeSuggestionsBtn');
                        var modal = doc.getElementById('suggestionsModal');
                        var modalContent = doc.getElementById('suggestionsModalContent');

                        if (openBtn) {
                            console.log("‚úÖ Found openSuggestionsBtn");
                            openBtn.onclick = openModal;
                        }
                        
                        if (closeBtn) {
                            closeBtn.onclick = closeModal;
                        }

                        if (modal) {
                            modal.onclick = function(event) {
                                if (event.target === modal) closeModal();
                            }
                        }
                        
                        if (modalContent) {
                            modalContent.onclick = function(event) {
                                event.stopPropagation();
                            }
                        }
                        
                        // Global escape key handler on parent document
                        doc.addEventListener('keydown', function(event) {
                            if (event.key === 'Escape') {
                                closeModal();
                            }
                        });
                    }

                    // Poll for elements
                    var attempts = 0;
                    var interval = setInterval(function() {
                        var openBtn = doc.getElementById('openSuggestionsBtn');
                        if (openBtn) {
                            console.log("‚úÖ Elements found, attaching events");
                            attachEvents();
                            clearInterval(interval);
                        }
                        attempts++;
                        if (attempts > 20) clearInterval(interval); // Stop after 10 seconds
                    }, 500);
                    
                })();
            </script>
            """, height=0, width=0)
        
        st.markdown("---")
        
        # Section 2: Chia T·∫≠p Train/Valid/Test
        st.markdown("### 2Ô∏è‚É£ Chia T·∫≠p Train/Valid/Test")
        
        st.markdown("""
        <div style="background-color: #1e3a5f; padding: 1rem; border-radius: 8px; border-left: 4px solid #3b82f6; margin-bottom: 1rem;">
            <p style="margin: 0; font-size: 0.9rem;">üí° <strong>Quan tr·ªçng:</strong> T·∫•t c·∫£ c√°c b∆∞·ªõc x·ª≠ l√Ω (missing values, outliers, encoding...) s·∫Ω ƒë∆∞·ª£c fit tr√™n t·∫≠p <strong>Train</strong>, sau ƒë√≥ transform cho t·∫≠p <strong>Valid</strong> v√† <strong>Test</strong> ƒë·ªÉ tr√°nh data leakage.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # S·ª≠ d·ª•ng fragment ƒë·ªÉ kh√¥ng rerun to√†n trang
        split_data_fragment(data)
        
        st.markdown("---")
        
        # Section 3: X·ª≠ L√Ω Bi·∫øn ƒê·ªãnh Danh & Gi√° Tr·ªã Kh√¥ng H·ª£p L·ªá  
        st.markdown("### 3Ô∏è‚É£ X·ª≠ L√Ω Bi·∫øn ƒê·ªãnh Danh & Gi√° Tr·ªã Kh√¥ng H·ª£p L·ªá")
        
        col_id1, col_id2 = st.columns([1, 1])
        
        with col_id1:
            # S·ª≠ d·ª•ng fragment ƒë·ªÉ kh√¥ng rerun to√†n trang
            remove_columns_fragment(data)
        
        with col_id2:
            # S·ª≠ d·ª•ng fragment ƒë·ªÉ kh√¥ng rerun to√†n trang
            validation_fragment(data)
        
        st.markdown("---")
        
        # Section 4: X·ª≠ L√Ω Gi√° Tr·ªã Thi·∫øu
        st.markdown("### 4Ô∏è‚É£ X·ª≠ L√Ω Gi√° Tr·ªã Thi·∫øu")
        
        # S·ª≠ d·ª•ng fragment ƒë·ªÉ kh√¥ng rerun to√†n trang
        missing_values_fragment(data, missing_data)
        
        # Section 5: X·ª≠ L√Ω Outliers & Bi·∫øn ƒê·ªïi Ph√¢n Ph·ªëi
        st.markdown("---")
        st.markdown("### 5Ô∏è‚É£ X·ª≠ L√Ω Outliers & Bi·∫øn ƒê·ªïi Ph√¢n Ph·ªëi")
        
        # S·ª≠ d·ª•ng fragment ƒë·ªÉ kh√¥ng rerun to√†n trang
        outliers_transform_fragment(data)
        
        # Section 6: M√£ H√≥a Bi·∫øn Ph√¢n Lo·∫°i
        st.markdown("---")
        st.markdown("### 6Ô∏è‚É£ M√£ H√≥a Bi·∫øn Ph√¢n Lo·∫°i")
        
        # S·ª≠ d·ª•ng fragment ƒë·ªÉ kh√¥ng rerun to√†n trang
        encoding_fragment(data)
        
        # Section 7: Ph√¢n nh√≥m (Binning) Bi·∫øn Li√™n T·ª•c
        st.markdown("---")
        st.markdown("### 7Ô∏è‚É£ Ph√¢n Nh√≥m (Binning) Bi·∫øn Li√™n T·ª•c")
        
        st.markdown("""
        <div style="background-color: #1e3a5f; padding: 1rem; border-radius: 8px; border-left: 4px solid #3b82f6; margin-bottom: 1rem;">
            <p style="margin: 0; font-size: 0.9rem;">üí° <strong>Binning</strong> chuy·ªÉn bi·∫øn li√™n t·ª•c th√†nh c√°c nh√≥m r·ªùi r·∫°c, gi√∫p:</p>
            <ul style="font-size: 0.85rem; margin: 0.5rem 0 0 1rem;">
                <li>Gi·∫£m ·∫£nh h∆∞·ªüng c·ªßa outliers</li>
                <li>T·∫°o quan h·ªá phi tuy·∫øn</li>
                <li>D·ªÖ gi·∫£i th√≠ch v√† ph√¢n t√≠ch</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
        
        # S·ª≠ d·ª•ng fragment ƒë·ªÉ kh√¥ng rerun to√†n trang
        binning_fragment(data)
        
        # Section 8: Chu·∫©n h√≥a / Scaling
        st.markdown("---")
        st.markdown("### 8Ô∏è‚É£ Chu·∫©n H√≥a / Scaling")
        
        st.markdown("""
        <div style="background-color: #1e3a5f; padding: 1rem; border-radius: 8px; border-left: 4px solid #3b82f6; margin-bottom: 1rem;">
            <p style="margin: 0; font-size: 0.9rem;">üí° <strong>Scaling</strong> ƒë∆∞a c√°c bi·∫øn v·ªÅ c√πng thang ƒëo, quan tr·ªçng cho:</p>
            <ul style="font-size: 0.85rem; margin: 0.5rem 0 0 1rem;">
                <li>Linear Regression, Logistic Regression</li>
                <li>Neural Networks, Deep Learning</li>
                <li>K-Nearest Neighbors (KNN)</li>
                <li>Support Vector Machines (SVM)</li>
                <li>Gradient Descent optimization</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
        
        # S·ª≠ d·ª•ng fragment ƒë·ªÉ kh√¥ng rerun to√†n trang
        scaling_fragment(data)
        
        # Section 9: C√¢n B·∫±ng D·ªØ Li·ªáu
        st.markdown("---")
        st.markdown("### 9Ô∏è‚É£ C√¢n B·∫±ng D·ªØ Li·ªáu")
        
        # S·ª≠ d·ª•ng fragment ƒë·ªÉ kh√¥ng rerun to√†n trang
        balancing_fragment(data)
    
    # Tab 2: Analysis & Evaluation
    with tab2:
        st.markdown("## üìä Ph√¢n T√≠ch & ƒê√°nh Gi√° ƒê·∫∑c Tr∆∞ng")
        
        # ============ SECTION 1: Feature Importance ============
        st.markdown("### 1Ô∏è‚É£ M·ª©c ƒê·ªô Quan Tr·ªçng C·ªßa ƒê·∫∑c Tr∆∞ng (Feature Importance)")
        
        # Check if train/valid/test split exists
        if 'train_data' not in st.session_state or st.session_state.train_data is None:
            st.warning("‚ö†Ô∏è Vui l√≤ng chia t·∫≠p Train/Valid/Test tr∆∞·ªõc khi t√≠nh Feature Importance")
            st.info("üí° Quay l·∫°i Tab 'Ti·ªÅn X·ª≠ L√Ω' > M·ª•c 2Ô∏è‚É£ ƒë·ªÉ chia d·ªØ li·ªáu")
        else:
            col1, col2 = st.columns([1, 3])
            
            with col1:
                st.markdown("#### ‚öôÔ∏è C·∫•u H√¨nh")
                
                # Select target column
                train_cols = st.session_state.train_data.columns.tolist()
                
                # Try to detect target column
                potential_targets = [col for col in train_cols 
                                   if 'target' in col.lower() or 'default' in col.lower() 
                                   or 'label' in col.lower() or 'churn' in col.lower()]
                
                if potential_targets:
                    default_target_idx = train_cols.index(potential_targets[0])
                else:
                    default_target_idx = len(train_cols) - 1
                
                target_col_importance = st.selectbox(
                    "Ch·ªçn bi·∫øn m·ª•c ti√™u (Target):",
                    train_cols,
                    index=default_target_idx,
                    key="target_col_importance"
                )
                
                importance_method = st.selectbox(
                    "Ph∆∞∆°ng ph√°p t√≠nh:",
                    ["Random Forest", "LightGBM", "XGBoost", "Logistic Regression (Coef)"],
                    key="importance_method"
                )
                
                top_n = st.slider("Top N features:", 5, 30, 15, key="top_n_features")
                
                # Task type selection
                task_type = st.radio(
                    "Lo·∫°i b√†i to√°n:",
                    ["auto", "classification", "regression"],
                    index=0,
                    key="task_type_importance",
                    help="auto: T·ª± ƒë·ªông ph√°t hi·ªán d·ª±a tr√™n s·ªë l∆∞·ª£ng gi√° tr·ªã unique c·ªßa target"
                )
                
                if st.button("üîÑ T√≠nh Feature Importance", key="calc_importance", type="primary"):
                    try:
                        with st.spinner(f"ƒêang t√≠nh feature importance b·∫±ng {importance_method}..."):
                            from backend.models.feature_importance import calculate_feature_importance
                            
                            # Prepare data
                            X_train = st.session_state.train_data.drop(columns=[target_col_importance])
                            y_train = st.session_state.train_data[target_col_importance]
                            
                            # Calculate importance
                            importance_results = calculate_feature_importance(
                                X_train=X_train,
                                y_train=y_train,
                                method=importance_method,
                                top_n=top_n,
                                task_type=task_type
                            )
                            
                            # Save to session state
                            st.session_state.feature_importance_results = importance_results
                            st.session_state.importance_target_col = target_col_importance
                            
                            st.success(f"‚úÖ ƒê√£ t√≠nh xong! Ph√°t hi·ªán: {importance_results['task_type']}")
                            st.rerun()
                    
                    except Exception as e:
                        st.error(f"‚ùå L·ªói: {str(e)}")
                        import traceback
                        with st.expander("Chi ti·∫øt l·ªói"):
                            st.code(traceback.format_exc())
                
                # Show info - use main data for accurate column count
                if st.session_state.train_data is not None:
                    st.markdown("---")
                    st.markdown("##### üìä Th√¥ng Tin D·ªØ Li·ªáu")
                    st.metric("S·ªë m·∫´u train", len(st.session_state.train_data))
                    # Use main data for feature count to reflect latest changes (binning, etc.)
                    main_data = st.session_state.data
                    target_col = st.session_state.get('target_column')
                    n_features = len(main_data.columns) - 1 if target_col else len(main_data.columns)
                    st.metric("S·ªë features", n_features)
            
            with col2:
                st.markdown("#### üìä Bi·ªÉu ƒê·ªì Feature Importance")
                
                # Display results if available
                if 'feature_importance_results' in st.session_state and st.session_state.feature_importance_results:
                    results = st.session_state.feature_importance_results
                    
                    sorted_features = results['feature_names']
                    sorted_scores = results['importance_scores']
                    
                    # Create bar chart
                    fig = go.Figure()
                    
                    fig.add_trace(go.Bar(
                        x=sorted_scores,
                        y=sorted_features,
                        orientation='h',
                        marker=dict(
                            color=sorted_scores,
                            colorscale='Viridis',
                            showscale=True,
                            colorbar=dict(title="Importance")
                        ),
                        text=[f"{score:.4f}" for score in sorted_scores],
                        textposition='outside'
                    ))
                    
                    fig.update_layout(
                        title=f"Top {len(sorted_features)} Important Features - {results['method']}",
                        xaxis_title="Importance Score",
                        yaxis_title="Features",
                        template="plotly_dark",
                        height=max(400, len(sorted_features) * 25),
                        showlegend=False
                    )
                    
                    st.plotly_chart(fig, width='stretch')
                    
                    # Show additional info
                    col_info1, col_info2, col_info3 = st.columns(3)
                    with col_info1:
                        st.metric("Ph∆∞∆°ng ph√°p", results['method'])
                    with col_info2:
                        st.metric("Lo·∫°i b√†i to√°n", results['task_type'])
                    with col_info3:
                        st.metric("T·ªïng features", results['n_features'])
                    
                    # Show detailed table
                    with st.expander("üìã Xem B·∫£ng Chi Ti·∫øt"):
                        importance_df = pd.DataFrame({
                            'Feature': sorted_features,
                            'Importance Score': sorted_scores,
                            'Percentage': [f"{score*100:.2f}%" for score in sorted_scores]
                        })
                        st.dataframe(importance_df, width='stretch', hide_index=True)
                    
                    # Feature selection recommendation
                    st.markdown("---")
                    st.markdown("##### üí° G·ª£i √ù L·ª±a Ch·ªçn Features")
                    
                    threshold = st.slider(
                        "Ng∆∞·ª°ng importance t·ªëi thi·ªÉu:",
                        0.0, 0.1, 0.01, 0.001,
                        key="importance_threshold_recommend",
                        help="Features c√≥ importance < ng∆∞·ª°ng n√†y s·∫Ω ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t lo·∫°i b·ªè"
                    )
                    
                    from backend.models.feature_importance import get_feature_importance_recommendations
                    
                    recommendations = get_feature_importance_recommendations(results, threshold)
                    
                    col_rec1, col_rec2 = st.columns(2)
                    with col_rec1:
                        st.success(f"‚úÖ Gi·ªØ l·∫°i: {recommendations['n_recommended']} features")
                        if recommendations['recommended_features']:
                            with st.expander("Xem danh s√°ch"):
                                for feat in recommendations['recommended_features'][:20]:
                                    st.text(f"‚Ä¢ {feat}")
                                if recommendations['n_recommended'] > 20:
                                    st.text(f"... v√† {recommendations['n_recommended'] - 20} features kh√°c")
                    
                    with col_rec2:
                        st.warning(f"‚ö†Ô∏è C√≥ th·ªÉ b·ªè: {recommendations['n_removed']} features")
                        if recommendations['removed_features']:
                            with st.expander("Xem danh s√°ch"):
                                for feat in recommendations['removed_features'][:20]:
                                    st.text(f"‚Ä¢ {feat}")
                                if recommendations['n_removed'] > 20:
                                    st.text(f"... v√† {recommendations['n_removed'] - 20} features kh√°c")
                
                else:
                    st.info("üí° Nh·∫•n n√∫t 'T√≠nh Feature Importance' b√™n tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch")
                    
                    # Show placeholder chart
                    st.markdown("""
                    <div style="background-color: #262730; padding: 2rem; border-radius: 8px; text-align: center; margin: 2rem 0;">
                        <h3 style="color: #667eea;">üìä Bi·ªÉu ƒê·ªì Feature Importance</h3>
                        <p style="color: #888; margin-top: 1rem;">
                            Bi·ªÉu ƒë·ªì s·∫Ω hi·ªÉn th·ªã sau khi t√≠nh to√°n xong
                        </p>
                    </div>
                    """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        # ============ SECTION 2: WOE Analysis ============
        st.markdown("### 2Ô∏è‚É£ Weight of Evidence (WOE) Analysis")
        
        st.markdown("""
        <div style="background-color: #1e3a5f; padding: 1rem; border-radius: 8px; border-left: 4px solid #3b82f6; margin-bottom: 1rem;">
            <p style="margin: 0; font-size: 0.9rem;">üí° <strong>WOE (Weight of Evidence)</strong> l√† ch·ªâ s·ªë quan tr·ªçng trong credit scoring, 
            ƒëo l∆∞·ªùng kh·∫£ nƒÉng d·ª± ƒëo√°n c·ªßa t·ª´ng bi·∫øn v√† gi√∫p x√°c ƒë·ªãnh c√°c nh√≥m r·ªßi ro.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Check if train/valid/test split exists
        if 'train_data' not in st.session_state or st.session_state.train_data is None:
            st.warning("‚ö†Ô∏è Vui l√≤ng chia t·∫≠p Train/Valid/Test tr∆∞·ªõc khi t√≠nh WOE")
            st.info("üí° Quay l·∫°i Tab 'Ti·ªÅn X·ª≠ L√Ω' > M·ª•c 2Ô∏è‚É£ ƒë·ªÉ chia d·ªØ li·ªáu")
        else:
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.markdown("#### ‚öôÔ∏è C·∫•u H√¨nh")
                
                # Select target column
                train_cols = st.session_state.train_data.columns.tolist()
                target_col = st.selectbox(
                    "Ch·ªçn bi·∫øn m·ª•c ti√™u (Target):",
                    train_cols,
                    key="woe_target_col",
                    help="Target ph·∫£i l√† bi·∫øn nh·ªã ph√¢n (0/1)"
                )
                
                # Select features to analyze
                feature_cols = [col for col in train_cols if col != target_col]
                selected_features = st.multiselect(
                    "Ch·ªçn bi·∫øn ƒë·ªÉ ph√¢n t√≠ch WOE:",
                    feature_cols,
                    default=feature_cols[:min(5, len(feature_cols))],
                    key="woe_features"
                )
                
                # Number of bins for continuous variables
                n_bins = st.slider(
                    "S·ªë bins cho bi·∫øn li√™n t·ª•c:",
                    min_value=3,
                    max_value=10,
                    value=5,
                    key="woe_n_bins"
                )
                
                if st.button("üîÑ T√≠nh WOE & IV", key="calc_woe", type="primary"):
                    if len(selected_features) == 0:
                        st.error("‚ö†Ô∏è Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt bi·∫øn")
                    else:
                        with st.spinner("ƒêang t√≠nh WOE v√† Information Value..."):
                            # Mock calculation
                            import time
                            time.sleep(1.5)
                            
                            # Create mock WOE results
                            woe_results = {}
                            for feat in selected_features:
                                iv = np.random.uniform(0.02, 0.5)
                                woe_results[feat] = {
                                    'iv': iv,
                                    'bins': n_bins,
                                    'predictive_power': 'Strong' if iv > 0.3 else 'Medium' if iv > 0.1 else 'Weak'
                                }
                            
                            st.session_state.woe_results = woe_results
                            st.success(f"‚úÖ ƒê√£ t√≠nh WOE cho {len(selected_features)} bi·∫øn!")
            
            with col2:
                st.markdown("#### üìä K·∫øt Qu·∫£ WOE & Information Value")
                
                if 'woe_results' in st.session_state and st.session_state.woe_results:
                    # Display results in a table
                    woe_df = pd.DataFrame([
                        {
                            'Feature': feat,
                            'IV': f"{results['iv']:.4f}",
                            'Predictive Power': results['predictive_power']
                        }
                        for feat, results in st.session_state.woe_results.items()
                    ]).sort_values('IV', ascending=False, key=lambda x: x.str.replace('[^0-9.]', '', regex=True).astype(float))
                    
                    st.dataframe(woe_df, width='stretch', hide_index=True)
                    
                    # IV interpretation guide
                    st.markdown("""
                    <div style="background-color: #262730; padding: 1rem; border-radius: 8px; margin-top: 1rem;">
                        <h4 style="margin-top: 0; color: #3b82f6;">üìñ Gi·∫£i Th√≠ch Information Value (IV)</h4>
                        <ul style="font-size: 0.9rem; margin-bottom: 0;">
                            <li><strong>IV < 0.02</strong>: Kh√¥ng c√≥ kh·∫£ nƒÉng d·ª± ƒëo√°n</li>
                            <li><strong>0.02 ‚â§ IV < 0.1</strong>: Kh·∫£ nƒÉng d·ª± ƒëo√°n y·∫øu</li>
                            <li><strong>0.1 ‚â§ IV < 0.3</strong>: Kh·∫£ nƒÉng d·ª± ƒëo√°n trung b√¨nh</li>
                            <li><strong>0.3 ‚â§ IV < 0.5</strong>: Kh·∫£ nƒÉng d·ª± ƒëo√°n m·∫°nh</li>
                            <li><strong>IV ‚â• 0.5</strong>: Kh·∫£ nƒÉng d·ª± ƒëo√°n r·∫•t m·∫°nh (c·∫ßn ki·ªÉm tra overfitting)</li>
                        </ul>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # Plot IV chart
                    st.markdown("#### üìä Bi·ªÉu ƒê·ªì Information Value")
                    iv_values = [float(results['iv']) for results in st.session_state.woe_results.values()]
                    features = list(st.session_state.woe_results.keys())
                    
                    fig = go.Figure(data=[
                        go.Bar(
                            x=iv_values,
                            y=features,
                            orientation='h',
                            marker=dict(
                                color=iv_values,
                                colorscale=[[0, '#ff6b6b'], [0.5, '#f9ca24'], [1, '#6c5ce7']],
                                showscale=True,
                                colorbar=dict(title="IV Value")
                            )
                        )
                    ])
                    
                    fig.update_layout(
                        template="plotly_dark",
                        title="Information Value by Feature",
                        xaxis_title="Information Value",
                        yaxis_title="Feature",
                        height=400,
                        showlegend=False
                    )
                    
                    st.plotly_chart(fig, width='stretch')
                else:
                    st.info("üí° Nh·∫•n n√∫t 'T√≠nh WOE & IV' b√™n tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch")
        
        st.markdown("---")
        
        # ============ SECTION 3: Multicollinearity ============
        st.markdown("### 3Ô∏è‚É£ Ph√°t Hi·ªán & X·ª≠ L√Ω ƒêa C·ªông Tuy·∫øn")
        
        st.markdown("""
        <div style="background-color: #1e3a5f; padding: 1rem; border-radius: 8px; border-left: 4px solid #3b82f6; margin-bottom: 1rem;">
            <p style="margin: 0; font-size: 0.9rem;">üí° <strong>ƒêa c·ªông tuy·∫øn</strong> x·∫£y ra khi c√°c bi·∫øn ƒë·ªôc l·∫≠p c√≥ t∆∞∆°ng quan cao v·ªõi nhau, 
            g√¢y kh√≥ khƒÉn trong vi·ªác x√°c ƒë·ªãnh ·∫£nh h∆∞·ªüng ri√™ng c·ªßa t·ª´ng bi·∫øn v√† l√†m gi·∫£m ƒë·ªô ·ªïn ƒë·ªãnh c·ªßa m√¥ h√¨nh.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Check if train/valid/test split exists
        if 'train_data' not in st.session_state or st.session_state.train_data is None:
            st.warning("‚ö†Ô∏è Vui l√≤ng chia t·∫≠p Train/Valid/Test tr∆∞·ªõc khi ki·ªÉm tra ƒëa c·ªông tuy·∫øn")
            st.info("üí° Quay l·∫°i Tab 'Ti·ªÅn X·ª≠ L√Ω' > M·ª•c 2Ô∏è‚É£ ƒë·ªÉ chia d·ªØ li·ªáu")
        else:
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.markdown("#### ‚öôÔ∏è C·∫•u H√¨nh")
                
                # Select method
                method = st.radio(
                    "Ph∆∞∆°ng ph√°p ph√°t hi·ªán:",
                    ["VIF (Variance Inflation Factor)", "Correlation Matrix"],
                    key="multicollinearity_method"
                )
                
                # Select features
                train_cols = st.session_state.train_data.columns.tolist()
                numeric_cols = st.session_state.train_data.select_dtypes(include=[np.number]).columns.tolist()
                
                selected_features = st.multiselect(
                    "Ch·ªçn bi·∫øn s·ªë ƒë·ªÉ ph√¢n t√≠ch:",
                    numeric_cols,
                    default=numeric_cols[:min(10, len(numeric_cols))],
                    key="vif_features"
                )
                
                if method == "VIF (Variance Inflation Factor)":
                    vif_threshold = st.slider(
                        "Ng∆∞·ª°ng VIF:",
                        min_value=1.0,
                        max_value=20.0,
                        value=5.0,
                        step=0.5,
                        key="vif_threshold",
                        help="VIF > 5: ƒêa c·ªông tuy·∫øn trung b√¨nh, VIF > 10: ƒêa c·ªông tuy·∫øn nghi√™m tr·ªçng"
                    )
                else:
                    corr_threshold = st.slider(
                        "Ng∆∞·ª°ng t∆∞∆°ng quan:",
                        min_value=0.5,
                        max_value=1.0,
                        value=0.8,
                        step=0.05,
                        key="corr_threshold",
                        help="C√°c c·∫∑p bi·∫øn c√≥ |correlation| > ng∆∞·ª°ng s·∫Ω ƒë∆∞·ª£c ƒë√°nh d·∫•u"
                    )
                
                if st.button("üîÑ Ph√¢n T√≠ch ƒêa C·ªông Tuy·∫øn", key="calc_multicollinearity", type="primary"):
                    if len(selected_features) < 2:
                        st.error("‚ö†Ô∏è Vui l√≤ng ch·ªçn √≠t nh·∫•t 2 bi·∫øn")
                    else:
                        with st.spinner(f"ƒêang t√≠nh to√°n {method}..."):
                            import time
                            time.sleep(1.5)
                            
                            if method == "VIF (Variance Inflation Factor)":
                                # Mock VIF calculation
                                vif_results = pd.DataFrame({
                                    'Feature': selected_features,
                                    'VIF': np.random.uniform(1.0, 15.0, len(selected_features))
                                }).sort_values('VIF', ascending=False)
                                
                                st.session_state.vif_results = vif_results
                                # st.session_state.vif_threshold is already updated by the slider widget
                                st.success(f"‚úÖ ƒê√£ t√≠nh VIF cho {len(selected_features)} bi·∫øn!")
                            else:
                                # Mock correlation matrix
                                corr_matrix = np.random.rand(len(selected_features), len(selected_features))
                                corr_matrix = (corr_matrix + corr_matrix.T) / 2
                                np.fill_diagonal(corr_matrix, 1.0)
                                corr_df = pd.DataFrame(corr_matrix, columns=selected_features, index=selected_features)
                                
                                st.session_state.corr_matrix = corr_df
                                # st.session_state.corr_threshold is already updated by the slider widget
                                st.success(f"‚úÖ ƒê√£ t√≠nh correlation matrix cho {len(selected_features)} bi·∫øn!")
            
            with col2:
                st.markdown("#### üìä K·∫øt Qu·∫£ Ph√¢n T√≠ch")
                
                if method == "VIF (Variance Inflation Factor)" and 'vif_results' in st.session_state:
                    vif_df = st.session_state.vif_results.copy()
                    threshold = st.session_state.get('vif_threshold', 5.0)
                    
                    # Add status column
                    vif_df['Status'] = vif_df['VIF'].apply(
                        lambda x: 'üî¥ Cao' if x > 10 else 'üü° Trung b√¨nh' if x > threshold else 'üü¢ OK'
                    )
                    
                    st.dataframe(vif_df, width='stretch', hide_index=True)
                    
                    # VIF interpretation
                    st.markdown("""
                    <div style="background-color: #262730; padding: 1rem; border-radius: 8px; margin-top: 1rem;">
                        <h4 style="margin-top: 0; color: #3b82f6;">üìñ Gi·∫£i Th√≠ch VIF</h4>
                        <ul style="font-size: 0.9rem; margin-bottom: 0;">
                            <li><strong>VIF = 1</strong>: Kh√¥ng c√≥ ƒëa c·ªông tuy·∫øn</li>
                            <li><strong>1 < VIF < 5</strong>: ƒêa c·ªông tuy·∫øn v·ª´a ph·∫£i (ch·∫•p nh·∫≠n ƒë∆∞·ª£c)</li>
                            <li><strong>5 ‚â§ VIF < 10</strong>: ƒêa c·ªông tuy·∫øn trung b√¨nh (c·∫ßn c√¢n nh·∫Øc)</li>
                            <li><strong>VIF ‚â• 10</strong>: ƒêa c·ªông tuy·∫øn nghi√™m tr·ªçng (n√™n lo·∫°i b·ªè)</li>
                        </ul>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # Plot VIF chart
                    fig = go.Figure(data=[
                        go.Bar(
                            x=vif_df['VIF'],
                            y=vif_df['Feature'],
                            orientation='h',
                            marker=dict(
                                color=vif_df['VIF'],
                                colorscale=[[0, '#00d2d3'], [0.5, '#f9ca24'], [1, '#ff6b6b']],
                                showscale=True,
                                colorbar=dict(title="VIF")
                            )
                        )
                    ])
                    
                    # Add threshold line
                    fig.add_vline(x=threshold, line_dash="dash", line_color="yellow", 
                                 annotation_text=f"Threshold: {threshold}")
                    fig.add_vline(x=10, line_dash="dash", line_color="red", 
                                 annotation_text="Critical: 10")
                    
                    fig.update_layout(
                        template="plotly_dark",
                        title="Variance Inflation Factor (VIF) by Feature",
                        xaxis_title="VIF Value",
                        yaxis_title="Feature",
                        height=400,
                        showlegend=False
                    )
                    
                    st.plotly_chart(fig, width='stretch')
                    
                    # Recommendations
                    high_vif = vif_df[vif_df['VIF'] > threshold]
                    if len(high_vif) > 0:
                        st.warning(f"‚ö†Ô∏è Ph√°t hi·ªán {len(high_vif)} bi·∫øn c√≥ VIF cao:")
                        for _, row in high_vif.iterrows():
                            st.text(f"‚Ä¢ {row['Feature']}: VIF = {row['VIF']:.2f}")
                        st.info("üí° ƒê·ªÅ xu·∫•t: Xem x√©t lo·∫°i b·ªè ho·∫∑c k·∫øt h·ª£p c√°c bi·∫øn n√†y ƒë·ªÉ gi·∫£m ƒëa c·ªông tuy·∫øn")
                
                elif method == "Correlation Matrix" and 'corr_matrix' in st.session_state:
                    corr_df = st.session_state.corr_matrix
                    threshold = st.session_state.get('corr_threshold', 0.8)
                    
                    # Display correlation matrix as heatmap
                    fig = go.Figure(data=go.Heatmap(
                        z=corr_df.values,
                        x=corr_df.columns,
                        y=corr_df.index,
                        colorscale='RdBu',
                        zmid=0,
                        text=corr_df.values.round(2),
                        texttemplate='%{text}',
                        textfont={"size": 10},
                        colorbar=dict(title="Correlation")
                    ))
                    
                    fig.update_layout(
                        template="plotly_dark",
                        title="Correlation Matrix",
                        height=600,
                        xaxis={'side': 'bottom'},
                    )
                    
                    st.plotly_chart(fig, width='stretch')
                    
                    # Find high correlations
                    high_corr_pairs = []
                    for i in range(len(corr_df.columns)):
                        for j in range(i+1, len(corr_df.columns)):
                            corr_val = corr_df.iloc[i, j]
                            if abs(corr_val) > threshold:
                                high_corr_pairs.append({
                                    'Feature 1': corr_df.columns[i],
                                    'Feature 2': corr_df.columns[j],
                                    'Correlation': f"{corr_val:.3f}"
                                })
                    
                    if len(high_corr_pairs) > 0:
                        st.warning(f"‚ö†Ô∏è Ph√°t hi·ªán {len(high_corr_pairs)} c·∫∑p bi·∫øn c√≥ t∆∞∆°ng quan cao (|r| > {threshold}):")
                        high_corr_df = pd.DataFrame(high_corr_pairs)
                        st.dataframe(high_corr_df, width='stretch', hide_index=True)
                        st.info("üí° ƒê·ªÅ xu·∫•t: Xem x√©t lo·∫°i b·ªè m·ªôt trong hai bi·∫øn c√≥ t∆∞∆°ng quan cao")
                    else:
                        st.success(f"‚úÖ Kh√¥ng ph√°t hi·ªán c·∫∑p bi·∫øn n√†o c√≥ t∆∞∆°ng quan > {threshold}")
                
                else:
                    st.info("üí° Nh·∫•n n√∫t 'Ph√¢n T√≠ch ƒêa C·ªông Tuy·∫øn' b√™n tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu")
    
    # Tab 3: Feature Selection
    with tab3:
        st.markdown("### ‚úÖ Ch·ªçn ƒê·∫∑c Tr∆∞ng Cho M√¥ H√¨nh")
        
        # S·ª≠ d·ª•ng fragment ƒë·ªÉ kh√¥ng rerun to√†n trang khi t∆∞∆°ng t√°c
        feature_selection_fragment(data)
