"""
Upload & EDA Page - Upload data and exploratory data analysis
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from scipy import stats
from utils.ui_components import show_llm_analysis
from utils.session_state import init_session_state, clear_data_related_state
from backend.llm_integration import analyze_eda_with_llm, get_eda_summary, LLMConfig



def render():
    """Render Upload & EDA page"""
    print("DEBUG: Starting upload_eda.render()")
    try:
        init_session_state()
        print("DEBUG: Session state initialized")
    except Exception as e:
        st.error(f"Error initializing session: {e}")
        print(f"ERROR: Session init failed: {e}")
        return
    
    st.markdown("## üì§ T·∫£i D·ªØ Li·ªáu & Ph√¢n T√≠ch Kh√°m Ph√° D·ªØ Li·ªáu (EDA)")
    st.markdown("T·∫£i l√™n file CSV ch·ª©a d·ªØ li·ªáu kh√°ch h√†ng v√† kh√°m ph√° c√°c th√¥ng tin quan tr·ªçng.")
    
    st.markdown("---")
    
    # File uploader
    uploaded_file = st.file_uploader(
        "Ch·ªçn file d·ªØ li·ªáu CSV",
        type=['csv'],
        help="T·∫£i l√™n file CSV ch·ª©a d·ªØ li·ªáu kh√°ch h√†ng v·ªõi c√°c ƒë·∫∑c tr∆∞ng v√† nh√£n",
        key="csv_uploader"
    )
    
    if uploaded_file is not None:
        try:
            # Check if this is a new file
            uploaded_file_id = f"{uploaded_file.name}_{uploaded_file.size}"
            is_new_file = st.session_state.get('current_file_id') != uploaded_file_id
            
            # Load data with error handling
            data = pd.read_csv(uploaded_file, on_bad_lines='skip', encoding='utf-8')
            
            # Validate data
            if data.empty:
                st.error("‚ùå File is empty or invalid format")
                return
            
            if len(data) < 5:
                st.warning(f"‚ö†Ô∏è Dataset only has {len(data)} rows. Upload more data for better analysis.")
            
            # Only clear state if this is a NEW file
            if is_new_file:
                clear_data_related_state()
                st.session_state.current_file_id = uploaded_file_id
                st.info("üîÑ ƒê√£ t·∫£i file m·ªõi - C√°c c·∫•u h√¨nh tr∆∞·ªõc ƒë√≥ ƒë√£ ƒë∆∞·ª£c x√≥a")
            
            st.session_state.data = data
            st.success(f"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu th√†nh c√¥ng! ({len(data)} d√≤ng, {len(data.columns)} c·ªôt)")
            
            # Use session state to track current tab (workaround for st.tabs not preserving state)
            if 'current_eda_tab' not in st.session_state:
                st.session_state.current_eda_tab = "üìã D·ªØ Li·ªáu M·∫´u"
            
            # Tab selector using radio (preserves state on rerun)
            # Define tabs
            tabs = ["üìã D·ªØ Li·ªáu M·∫´u", "üìä Th·ªëng K√™ M√¥ T·∫£", "üìà Ph√¢n Ph·ªëi D·ªØ Li·ªáu", "‚ú® Ph√¢n T√≠ch AI"]
            
            # Tab selector using radio (preserves state on rerun)
            # Handle migration from English to Vietnamese state or other invalid states
            current_tab_index = 0
            if st.session_state.current_eda_tab in tabs:
                current_tab_index = tabs.index(st.session_state.current_eda_tab)
            
            selected_tab = st.radio(
                "Ch·ªçn m·ª•c:",
                tabs,
                horizontal=True,
                key="eda_tab_selector",
                index=current_tab_index
            )
            st.session_state.current_eda_tab = selected_tab
            
            st.markdown("---")
            
            # Tab 1: Sample Data
            if selected_tab == "üìã D·ªØ Li·ªáu M·∫´u":
                st.markdown("### üìã D·ªØ Li·ªáu M·∫´u")
                
                # Controls
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.info(f"üìä Hi·ªÉn th·ªã to√†n b·ªô {len(data):,} d√≤ng d·ªØ li·ªáu")
                with col2:
                    show_charts = st.checkbox("Hi·ªán bi·ªÉu ƒë·ªì", value=True, key="show_charts")
                
                # Use all data
                display_data = data.copy()
                
                # Show charts header if enabled
                if show_charts:
                        # Create header row with visualizations - REDESIGNED
                    import base64
                    from io import BytesIO
                    import matplotlib
                    matplotlib.use('Agg')
                    import matplotlib.pyplot as plt
                    
                    # CSS for enhanced cards
                    st.markdown("""
                    <style>
                    .feature-cards-container {
                        display: flex;
                        overflow-x: auto;
                        gap: 1rem;
                        padding: 1rem 0;
                        scrollbar-width: thin;
                    }
                    .feature-cards-container::-webkit-scrollbar {
                        height: 8px;
                    }
                    .feature-cards-container::-webkit-scrollbar-thumb {
                        background: #667eea;
                        border-radius: 4px;
                    }
                    .feature-card {
                        min-width: 180px;
                        max-width: 200px;
                        background: linear-gradient(145deg, #1e293b 0%, #0f172a 100%);
                        border-radius: 16px;
                        padding: 1rem;
                        border: 1px solid rgba(102, 126, 234, 0.2);
                        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
                        transition: all 0.3s ease;
                        flex-shrink: 0;
                    }
                    .feature-card:hover {
                        transform: translateY(-4px);
                        border-color: rgba(102, 126, 234, 0.5);
                        box-shadow: 0 8px 30px rgba(102, 126, 234, 0.2);
                    }
                    .feature-card-header {
                        font-weight: 700;
                        font-size: 0.9rem;
                        color: #e2e8f0;
                        margin-bottom: 0.8rem;
                        text-align: center;
                        white-space: nowrap;
                        overflow: hidden;
                        text-overflow: ellipsis;
                    }
                    .feature-card-chart {
                        text-align: center;
                        margin-bottom: 0.8rem;
                        background: rgba(0,0,0,0.2);
                        border-radius: 8px;
                        padding: 0.5rem;
                    }
                    .feature-card-chart img {
                        width: 100%;
                        max-width: 160px;
                        height: 60px;
                        object-fit: contain;
                    }
                    .feature-card-stats {
                        display: grid;
                        grid-template-columns: 1fr 1fr;
                        gap: 0.4rem;
                        font-size: 0.75rem;
                        margin-bottom: 0.6rem;
                    }
                    .stat-item {
                        background: rgba(30, 41, 59, 0.8);
                        padding: 0.3rem 0.5rem;
                        border-radius: 6px;
                        text-align: center;
                    }
                    .stat-label {
                        color: #64748b;
                        font-size: 0.65rem;
                        display: block;
                    }
                    .stat-value {
                        color: #e2e8f0;
                        font-weight: 600;
                        font-size: 0.8rem;
                    }
                    .feature-card-footer {
                        text-align: center;
                        padding-top: 0.5rem;
                        border-top: 1px solid rgba(100, 116, 139, 0.2);
                    }
                    .missing-ok {
                        color: #10b981;
                        font-size: 0.75rem;
                        font-weight: 500;
                    }
                    .missing-warn {
                        color: #f59e0b;
                        font-size: 0.75rem;
                        font-weight: 500;
                    }
                    </style>
                    """, unsafe_allow_html=True)
                    
                    # Build cards HTML
                    cards_html = '<div class="feature-cards-container">'
                    
                    for col_name in data.columns:
                        col_data = data[col_name]
                        
                        cards_html += '<div class="feature-card">'
                        cards_html += f'<div class="feature-card-header" title="{col_name}">{col_name}</div>'
                        
                        # Generate chart
                        chart_html = ""
                        stats_html = ""
                        
                        if pd.api.types.is_numeric_dtype(col_data):
                            # Numeric - Classify into subtypes
                            col_clean = col_data.dropna()
                            if len(col_clean) > 0:
                                n_unique = col_clean.nunique()
                                col_min, col_max = col_clean.min(), col_clean.max()
                                
                                # Determine chart type and color based on data characteristics
                                if n_unique <= 10:
                                    # Discrete/Count variable - Bar chart
                                    chart_type = "discrete"
                                    color = '#f59e0b'  # Orange
                                    edge_color = '#fbbf24'
                                elif col_min >= 0 and col_max <= 1:
                                    # Ratio/Percentage - Area-like chart
                                    chart_type = "ratio"
                                    color = '#10b981'  # Green
                                    edge_color = '#34d399'
                                elif col_min >= 0 and col_max <= 100 and 'rate' in col_name.lower():
                                    # Percentage rate
                                    chart_type = "percentage"
                                    color = '#06b6d4'  # Cyan
                                    edge_color = '#22d3ee'
                                else:
                                    # Continuous - Histogram
                                    chart_type = "continuous"
                                    color = '#667eea'  # Purple-blue
                                    edge_color = '#818cf8'
                                
                                fig, ax = plt.subplots(figsize=(2.0, 0.9), facecolor='none')
                                
                                if chart_type == "discrete":
                                    # Bar chart for discrete values
                                    value_counts = col_clean.value_counts().sort_index()
                                    if len(value_counts) > 8:
                                        value_counts = value_counts.head(8)
                                    ax.bar(range(len(value_counts)), value_counts.values, 
                                          color=color, edgecolor=edge_color, linewidth=0.5, alpha=0.85)
                                    ax.set_xticks([])
                                elif chart_type in ["ratio", "percentage"]:
                                    # Filled area chart for ratios
                                    sorted_vals = np.sort(col_clean.values)
                                    x = np.linspace(0, 1, len(sorted_vals))
                                    ax.fill_between(x, sorted_vals, alpha=0.7, color=color)
                                    ax.plot(x, sorted_vals, color=edge_color, linewidth=1.5)
                                else:
                                    # Histogram with KDE for continuous
                                    n, bins, patches = ax.hist(col_clean, bins=min(25, max(10, len(col_clean) // 8)), 
                                           color=color, edgecolor=edge_color, linewidth=0.3, alpha=0.75)
                                    
                                    # Add KDE line if enough data
                                    if len(col_clean) > 30:
                                        try:
                                            from scipy.stats import gaussian_kde
                                            kde = gaussian_kde(col_clean)
                                            x_kde = np.linspace(col_clean.min(), col_clean.max(), 100)
                                            y_kde = kde(x_kde) * len(col_clean) * (bins[1] - bins[0])
                                            ax.plot(x_kde, y_kde, color='#f472b6', linewidth=1.5, alpha=0.9)
                                        except:
                                            pass
                                
                                ax.set_xticks([])
                                ax.set_yticks([])
                                for spine in ax.spines.values():
                                    spine.set_visible(False)
                                ax.patch.set_alpha(0)
                                
                                buffer = BytesIO()
                                plt.savefig(buffer, format='png', bbox_inches='tight', transparent=True, dpi=80)
                                buffer.seek(0)
                                img_base64 = base64.b64encode(buffer.read()).decode()
                                plt.close(fig)
                                
                                chart_html = f'<img src="data:image/png;base64,{img_base64}"/>'
                                
                                # Stats for numeric - format based on magnitude
                                def fmt_num(val):
                                    if abs(val) >= 1000000:
                                        return f"{val/1000000:.1f}M"
                                    elif abs(val) >= 1000:
                                        return f"{val/1000:.1f}K"
                                    elif abs(val) < 1:
                                        return f"{val:.3f}"
                                    else:
                                        return f"{val:.1f}"
                                
                                stats_html = f'''
                                <div class="feature-card-stats">
                                    <div class="stat-item">
                                        <span class="stat-label">Min</span>
                                        <span class="stat-value">{fmt_num(col_clean.min())}</span>
                                    </div>
                                    <div class="stat-item">
                                        <span class="stat-label">Max</span>
                                        <span class="stat-value">{fmt_num(col_clean.max())}</span>
                                    </div>
                                    <div class="stat-item">
                                        <span class="stat-label">Mean</span>
                                        <span class="stat-value">{fmt_num(col_clean.mean())}</span>
                                    </div>
                                    <div class="stat-item">
                                        <span class="stat-label">Unique</span>
                                        <span class="stat-value">{col_data.nunique()}</span>
                                    </div>
                                </div>
                                '''
                        else:
                            # Categorical - Bar chart
                            value_counts = col_data.value_counts().head(4)
                            total = len(col_data)
                            
                            if len(value_counts) > 0:
                                percentages = (value_counts / total * 100)
                                
                                fig, ax = plt.subplots(figsize=(2.0, 0.9), facecolor='none')
                                bars = ax.barh(range(len(value_counts)), percentages.values, 
                                              color='#a78bfa', edgecolor='#c4b5fd', linewidth=0.5, alpha=0.85)
                                ax.set_yticks(range(len(value_counts)))
                                ax.set_yticklabels([str(v)[:10] for v in value_counts.index], 
                                                  fontsize=7, color='#e2e8f0')
                                ax.set_xticks([])
                                for spine in ax.spines.values():
                                    spine.set_visible(False)
                                ax.patch.set_alpha(0)
                                ax.invert_yaxis()
                                
                                buffer = BytesIO()
                                plt.savefig(buffer, format='png', bbox_inches='tight', transparent=True, dpi=80)
                                buffer.seek(0)
                                img_base64 = base64.b64encode(buffer.read()).decode()
                                plt.close(fig)
                                
                                chart_html = f'<img src="data:image/png;base64,{img_base64}"/>'
                                
                                # Stats for categorical
                                top_value = str(value_counts.index[0])[:12]
                                stats_html = f'''
                                <div class="feature-card-stats">
                                    <div class="stat-item" style="grid-column: span 2;">
                                        <span class="stat-label">Mode</span>
                                        <span class="stat-value">{top_value}</span>
                                    </div>
                                    <div class="stat-item">
                                        <span class="stat-label">Unique</span>
                                        <span class="stat-value">{col_data.nunique()}</span>
                                    </div>
                                    <div class="stat-item">
                                        <span class="stat-label">Top %</span>
                                        <span class="stat-value">{percentages.iloc[0]:.0f}%</span>
                                    </div>
                                </div>
                                '''
                        
                        cards_html += f'<div class="feature-card-chart">{chart_html}</div>'
                        cards_html += stats_html
                        
                        # Missing info footer
                        missing_count = col_data.isnull().sum()
                        missing_pct = (missing_count / len(col_data) * 100) if len(col_data) > 0 else 0
                        
                        cards_html += '<div class="feature-card-footer">'
                        if missing_count > 0:
                            cards_html += f'<span class="missing-warn">‚ö†Ô∏è {missing_count} missing ({missing_pct:.1f}%)</span>'
                        else:
                            cards_html += '<span class="missing-ok">‚úÖ No missing</span>'
                        cards_html += '</div>'
                        
                        cards_html += '</div>'  # Close feature-card
                    
                    cards_html += '</div>'  # Close feature-cards-container
                    
                    # Display cards
                    st.markdown(cards_html, unsafe_allow_html=True)
                
                st.markdown("---")
                
                # Display the dataframe with pagination
                st.dataframe(display_data, width='stretch', height=500)
                
                # Data info
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("üìä Total Rows", f"{len(data):,}")
                with col2:
                    st.metric("üìã Total Columns", len(data.columns))
                with col3:
                    missing_pct = (data.isnull().sum().sum() / (len(data) * len(data.columns)) * 100)
                    st.metric("‚ùì Missing Data", f"{missing_pct:.1f}%")
                with col4:
                    numeric_cols = data.select_dtypes(include=[np.number]).columns
                    st.metric("üî¢ Numeric Columns", len(numeric_cols))
            
            # Tab 2: Descriptive Statistics
            elif selected_tab == tabs[1]:
                st.markdown("### üìä Th·ªëng K√™ M√¥ T·∫£")
                
                # Numeric columns stats
                numeric_data = data.select_dtypes(include=[np.number])
                if not numeric_data.empty:
                    st.markdown("#### üî¢ Bi·∫øn S·ªë")
                    
                    stats_df = numeric_data.describe().T
                    stats_df['missing'] = data[numeric_data.columns].isnull().sum()
                    stats_df['missing_pct'] = (stats_df['missing'] / len(data) * 100).round(2)
                    
                    # Highlight styling
                    st.dataframe(
                        stats_df.style.background_gradient(cmap='viridis', subset=['mean', 'std']),
                        width='stretch'
                    )
                    
                    # Download stats
                    csv = stats_df.to_csv(index=True).encode('utf-8')
                    st.download_button(
                        "üì• T·∫£i Xu·ªëng Th·ªëng K√™ (CSV)",
                        csv,
                        "statistics.csv",
                        "text/csv",
                        key='download-stats'
                    )
                    
                    st.markdown("---")
                    
                    # Detailed column analysis
                    st.markdown("#### üîç Ph√¢n T√≠ch Chi Ti·∫øt C·ªôt")
                    
                    numeric_cols = numeric_data.columns.tolist()
                    selected_numeric_col = st.selectbox(
                        "Ch·ªçn c·ªôt s·ªë ƒë·ªÉ ph√¢n t√≠ch chi ti·∫øt:",
                        numeric_cols,
                        key="detailed_numeric_col"
                    )
                    
                    if selected_numeric_col:
                        st.markdown(f"### üìä B·∫£ng Ph√¢n T√≠ch: `{selected_numeric_col}`")
                        
                        col_data = data[selected_numeric_col].dropna()
                        
                        # Summary metrics
                        st.markdown("#### üìà T√≥m T·∫Øt Th·ªëng K√™")
                        metric_cols = st.columns(6)
                        
                        with metric_cols[0]:
                            st.metric("S·ªë l∆∞·ª£ng", f"{len(col_data):,}")
                        with metric_cols[1]:
                            st.metric("Trung b√¨nh", f"{col_data.mean():.2f}")
                        with metric_cols[2]:
                            st.metric("Trung v·ªã", f"{col_data.median():.2f}")
                        with metric_cols[3]:
                            st.metric("ƒê·ªô l·ªách chu·∫©n", f"{col_data.std():.2f}")
                        with metric_cols[4]:
                            st.metric("Min", f"{col_data.min():.2f}")
                        with metric_cols[5]:
                            st.metric("Max", f"{col_data.max():.2f}")
                        
                        st.markdown("---")
                        
                        # Charts section
                        chart_col1, chart_col2 = st.columns(2)
                        
                        with chart_col1:
                            # Histogram with default bins
                            st.markdown("##### üìä Bi·ªÉu ƒë·ªì Histogram & Ph√¢n Ph·ªëi")
                            fig_hist = px.histogram(
                                data,
                                x=selected_numeric_col,
                                marginal="box",
                                color_discrete_sequence=['#667eea']
                            )
                            fig_hist.update_layout(
                                template="plotly_dark",
                                height=350,
                                showlegend=False,
                                xaxis_title=selected_numeric_col,
                                yaxis_title="T·∫ßn su·∫•t"
                            )
                            st.plotly_chart(fig_hist, width='stretch')
                        
                        with chart_col2:
                            # Box plot for outlier detection
                            st.markdown("##### üì¶ Bi·ªÉu ƒë·ªì H·ªôp (Ph√°t hi·ªán Outlier)")
                            fig_box = go.Figure()
                            fig_box.add_trace(go.Box(
                                y=col_data,
                                name=selected_numeric_col,
                                boxmean='sd',
                                marker_color='#764ba2',
                                boxpoints='outliers'
                            ))
                            fig_box.update_layout(
                                template="plotly_dark",
                                height=350,
                                showlegend=False,
                                yaxis_title=selected_numeric_col
                            )
                            st.plotly_chart(fig_box, width='stretch')
                        
                        # Quantile and outlier analysis
                        st.markdown("---")
                        stat_col1, stat_col2 = st.columns(2)
                        
                        with stat_col1:
                            st.markdown("##### üìä Ph√¢n V·ªã (Quantiles)")
                            quantiles = col_data.quantile([0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99])
                            quantile_df = pd.DataFrame({
                                'Quantile': ['1%', '5%', '25%', '50% (Trung v·ªã)', '75%', '95%', '99%'],
                                'Gi√° tr·ªã': quantiles.values
                            })
                            st.dataframe(
                                quantile_df.style.format({'Value': '{:.2f}'}),
                                width='stretch',
                                hide_index=True
                            )
                        
                        with stat_col2:
                            st.markdown("##### ‚ö†Ô∏è Ph√¢n T√≠ch Outlier (Ph∆∞∆°ng ph√°p IQR)")
                            Q1 = col_data.quantile(0.25)
                            Q3 = col_data.quantile(0.75)
                            IQR = Q3 - Q1
                            lower_bound = Q1 - 1.5 * IQR
                            upper_bound = Q3 + 1.5 * IQR
                            
                            outliers = col_data[(col_data < lower_bound) | (col_data > upper_bound)]
                            outlier_pct = (len(outliers) / len(col_data) * 100)
                            
                            outlier_info = pd.DataFrame({
                                'Ch·ªâ s·ªë': ['C·∫≠n d∆∞·ªõi', 'C·∫≠n tr√™n', 'S·ªë l∆∞·ª£ng Outlier', 'T·ª∑ l·ªá Outlier'],
                                'Gi√° tr·ªã': [
                                    f"{lower_bound:.2f}",
                                    f"{upper_bound:.2f}",
                                    f"{len(outliers):,}",
                                    f"{outlier_pct:.2f}%"
                                ]
                            })
                            st.dataframe(outlier_info, width='stretch', hide_index=True)
                        
                        # Distribution characteristics
                        st.markdown("---")
                        st.markdown("##### üìê ƒê·∫∑c ƒêi·ªÉm Ph√¢n Ph·ªëi")
                        
                        dist_cols = st.columns(4)
                        
                        # Skewness
                        skewness = stats.skew(col_data)
                        with dist_cols[0]:
                            st.metric("ƒê·ªô l·ªách (Skewness)", f"{skewness:.3f}")
                            if abs(skewness) < 0.5:
                                st.caption("‚úÖ G·∫ßn ƒë·ªëi x·ª©ng")
                            elif skewness > 0:
                                st.caption("‚û°Ô∏è L·ªách ph·∫£i")
                            else:
                                st.caption("‚¨ÖÔ∏è L·ªách tr√°i")
                        
                        # Kurtosis
                        kurtosis = stats.kurtosis(col_data)
                        with dist_cols[1]:
                            st.metric("ƒê·ªô nh·ªçn (Kurtosis)", f"{kurtosis:.3f}")
                            if abs(kurtosis) < 0.5:
                                st.caption("‚úÖ Ph√¢n ph·ªëi chu·∫©n")
                            elif kurtosis > 0:
                                st.caption("üìà Nh·ªçn (leptokurtic)")
                            else:
                                st.caption("üìâ B·∫πt (platykurtic)")
                        
                        # Range
                        with dist_cols[2]:
                            st.metric("Ph·∫°m vi (Range)", f"{col_data.max() - col_data.min():.2f}")
                            st.caption("Max - Min")
                        
                        # CV (Coefficient of Variation)
                        cv = (col_data.std() / col_data.mean() * 100) if col_data.mean() != 0 else 0
                        with dist_cols[3]:
                            st.metric("H·ªá s·ªë bi·∫øn thi√™n (CV)", f"{cv:.2f}%")
                            if cv < 15:
                                st.caption("‚úÖ Bi·∫øn ƒë·ªông th·∫•p")
                            elif cv < 30:
                                st.caption("‚ö†Ô∏è Bi·∫øn ƒë·ªông trung b√¨nh")
                            else:
                                st.caption("üî¥ Bi·∫øn ƒë·ªông cao")
                        
                        # Value distribution table
                        st.markdown("---")
                        st.markdown("##### üìã Ph√¢n Ph·ªëi Gi√° Tr·ªã (Binned)")
                        
                        # Bins slider for binned distribution
                        bin_slider_col1, bin_slider_col2 = st.columns([3, 1])
                        with bin_slider_col1:
                            n_bins = st.slider(
                                f"Number of bins for {selected_numeric_col}:",
                                min_value=1,
                                max_value=20,
                                value=10,
                                step=1,
                                key=f"binned_dist_{selected_numeric_col}"
                            )
                        
                        # Create bins
                        bins = pd.cut(col_data, bins=n_bins)
                        bin_counts = bins.value_counts().sort_index()
                        
                        bin_df = pd.DataFrame({
                            'Value Range': bin_counts.index.astype(str),
                            'Count': bin_counts.values,
                            'Ratio (%)': (bin_counts.values / len(col_data) * 100).round(2)
                        })
                        
                        st.dataframe(bin_df, width='stretch', hide_index=True)
                        
                        # Histogram of bins
                        fig_bin = px.bar(
                            bin_df,
                            x='Value Range',
                            y='Count',
                            color='Ratio (%)',
                            color_continuous_scale='Viridis',
                            title=f"Value distribution of {selected_numeric_col}"
                        )
                        fig_bin.update_layout(
                            template="plotly_dark",
                            height=350,
                            xaxis_tickangle=-45
                        )
                        st.plotly_chart(fig_bin, width='stretch')
                
                # Categorical columns
                categorical_data = data.select_dtypes(include=['object', 'category'])
                if not categorical_data.empty:
                    st.markdown("#### üìù Categorical Variables")
                    
                    cat_info = []
                    for col in categorical_data.columns:
                        cat_info.append({
                            'Column Name': col,
                            'Unique Values': data[col].nunique(),
                            'Most Common': data[col].mode()[0] if not data[col].mode().empty else 'N/A',
                            'Top Frequency': data[col].value_counts().iloc[0] if len(data[col].value_counts()) > 0 else 0,
                            'Missing': data[col].isnull().sum(),
                            'Missing Ratio (%)': f"{data[col].isnull().sum() / len(data) * 100:.2f}"
                        })
                    
                    cat_df = pd.DataFrame(cat_info)
                    st.dataframe(cat_df, width='stretch')
            
            # Tab 3: Data Distribution
            elif selected_tab == tabs[2]:
                st.markdown("### üìà Ph√¢n Ph·ªëi & T∆∞∆°ng Quan D·ªØ Li·ªáu")
                
                viz_type = st.radio(
                    "Ch·ªçn lo·∫°i ph√¢n t√≠ch:",
                    ["Bi·ªÉu ƒê·ªì Nhi·ªát T∆∞∆°ng Quan", "Ma Tr·∫≠n Bi·ªÉu ƒê·ªì Ph√¢n T√°n", "Bi·ªÉu ƒê·ªì Ph√¢n T√°n (2 Bi·∫øn)", "Ph√¢n T√≠ch Theo Nh√≥m"],
                    horizontal=True,
                    key="viz_type_upload"
                )
                
                if viz_type == "Bi·ªÉu ƒê·ªì Nhi·ªát T∆∞∆°ng Quan":
                    st.markdown("#### üî• Ma Tr·∫≠n T∆∞∆°ng Quan")
                    
                    numeric_data = data.select_dtypes(include=[np.number])
                    if not numeric_data.empty and len(numeric_data.columns) > 1:
                        corr_matrix = numeric_data.corr()
                        
                        # Create heatmap
                        fig = px.imshow(
                            corr_matrix,
                            text_auto='.2f',
                            aspect="auto",
                            color_continuous_scale='RdBu_r',
                            title="Correlation matrix between variables",
                            zmin=-1,
                            zmax=1
                        )
                        
                        fig.update_layout(
                            template="plotly_dark",
                            height=600
                        )
                        
                        st.plotly_chart(fig, width='stretch')
                        
                        # Find high correlations
                        st.markdown("#### üîç C√°c C·∫∑p Bi·∫øn C√≥ T∆∞∆°ng Quan Cao")
                        
                        threshold = st.slider("Ng∆∞·ª°ng t∆∞∆°ng quan:", 0.0, 1.0, 0.7, 0.05, key="upload_corr_threshold")
                        
                        high_corr = []
                        for i in range(len(corr_matrix.columns)):
                            for j in range(i+1, len(corr_matrix.columns)):
                                if abs(corr_matrix.iloc[i, j]) >= threshold:
                                    high_corr.append({
                                        'Bi·∫øn 1': corr_matrix.columns[i],
                                        'Bi·∫øn 2': corr_matrix.columns[j],
                                        'T∆∞∆°ng quan': f"{corr_matrix.iloc[i, j]:.3f}",
                                        'Lo·∫°i': 'D∆∞∆°ng' if corr_matrix.iloc[i, j] > 0 else '√Çm'
                                    })
                        
                        if high_corr:
                            st.dataframe(pd.DataFrame(high_corr), width='stretch', hide_index=True)
                        else:
                            st.info(f"Kh√¥ng t√¨m th·∫•y c·∫∑p bi·∫øn n√†o c√≥ t∆∞∆°ng quan >= {threshold}")
                    else:
                        st.warning("C·∫ßn √≠t nh·∫•t 2 bi·∫øn s·ªë ƒë·ªÉ t·∫°o ma tr·∫≠n t∆∞∆°ng quan.")
                
                elif viz_type == "Ma Tr·∫≠n Bi·ªÉu ƒê·ªì Ph√¢n T√°n":
                    st.markdown("#### üî∑ Ma Tr·∫≠n Bi·ªÉu ƒê·ªì Ph√¢n T√°n (Pair Plot)")
                    st.caption("Hi·ªÉn th·ªã m·ªëi quan h·ªá gi·ªØa t·ª´ng c·∫∑p bi·∫øn s·ªë")
                    
                    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
                    if len(numeric_cols) >= 2:
                        # Allow selection of variables
                        max_vars = min(5, len(numeric_cols))
                        selected_vars = st.multiselect(
                            "Ch·ªçn bi·∫øn ƒë·ªÉ hi·ªÉn th·ªã (t·ªëi ƒëa 5):",
                            numeric_cols,
                            default=numeric_cols[:max_vars],
                            max_selections=5,
                            key="upload_scatter_matrix_vars"
                        )
                        
                        if len(selected_vars) >= 2:
                            # Create scatter matrix
                            fig = px.scatter_matrix(
                                data,
                                dimensions=selected_vars,
                                color_discrete_sequence=['#667eea'],
                                opacity=0.6
                            )
                            
                            fig.update_layout(
                                template="plotly_dark",
                                height=800,
                                title="Scatter Plot Matrix - Pairwise relationship analysis"
                            )
                            
                            fig.update_traces(diagonal_visible=False, showupperhalf=False)
                            
                            st.plotly_chart(fig, width='stretch')
                            
                            st.info("üí° **M·∫πo**: T√¨m ki·∫øm c√°c m·∫´u tuy·∫øn t√≠nh ho·∫∑c phi tuy·∫øn t√≠nh gi·ªØa c√°c c·∫∑p bi·∫øn.")
                        else:
                            st.warning("Vui l√≤ng ch·ªçn √≠t nh·∫•t 2 bi·∫øn.")
                    else:
                        st.warning("C·∫ßn √≠t nh·∫•t 2 bi·∫øn s·ªë ƒë·ªÉ t·∫°o Ma Tr·∫≠n Bi·ªÉu ƒê·ªì Ph√¢n T√°n.")
                
                elif viz_type == "Bi·ªÉu ƒê·ªì Ph√¢n T√°n (2 Bi·∫øn)":
                    st.markdown("#### üìä Ph√¢n T√≠ch Chi Ti·∫øt 2 Bi·∫øn")
                    
                    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
                    if len(numeric_cols) >= 2:
                        col1, col2 = st.columns(2)
                        with col1:
                            x_var = st.selectbox("Ch·ªçn bi·∫øn X:", numeric_cols, key="upload_scatter_x")
                        with col2:
                            y_vars = [col for col in numeric_cols if col != x_var]
                            y_var = st.selectbox("Ch·ªçn bi·∫øn Y:", y_vars, key="upload_scatter_y")
                        
                        # Options
                        opt_col1, opt_col2, opt_col3 = st.columns(3)
                        with opt_col1:
                            show_trendline = st.checkbox("Hi·ªán ƒë∆∞·ªùng xu h∆∞·ªõng", value=True, key="upload_scatter_trend")
                        with opt_col2:
                            show_marginal = st.checkbox("Hi·ªán ph√¢n ph·ªëi bi√™n", value=True, key="upload_scatter_marginal")
                        with opt_col3:
                            color_by_cat = st.checkbox("T√¥ m√†u theo bi·∫øn ph√¢n lo·∫°i", value=False, key="upload_scatter_color")
                        
                        # Color selection
                        color_var = None
                        if color_by_cat:
                            cat_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()
                            if cat_cols:
                                color_var = st.selectbox("Ch·ªçn bi·∫øn ph√¢n lo·∫°i:", cat_cols, key="upload_scatter_color_var")
                        
                        # Create scatter plot
                        fig = px.scatter(
                            data,
                            x=x_var,
                            y=y_var,
                            color=color_var,
                            trendline="ols" if show_trendline else None,
                            marginal_x="histogram" if show_marginal else None,
                            marginal_y="histogram" if show_marginal else None,
                            opacity=0.6,
                            title=f"M·ªëi quan h·ªá gi·ªØa {x_var} v√† {y_var}"
                        )
                        
                        fig.update_layout(
                            template="plotly_dark",
                            height=600
                        )
                        
                        st.plotly_chart(fig, width='stretch')
                        
                        # Calculate correlation
                        corr = data[x_var].corr(data[y_var])
                        
                        metric_col1, metric_col2, metric_col3 = st.columns(3)
                        with metric_col1:
                            st.metric("T∆∞∆°ng Quan Pearson", f"{corr:.3f}")
                        with metric_col2:
                            if abs(corr) >= 0.7:
                                st.metric("M·ª©c ƒë·ªô", "M·∫°nh üí™", delta="T∆∞∆°ng quan cao")
                            elif abs(corr) >= 0.4:
                                st.metric("M·ª©c ƒë·ªô", "Trung b√¨nh ‚öñÔ∏è", delta="T∆∞∆°ng quan v·ª´a")
                            else:
                                st.metric("M·ª©c ƒë·ªô", "Y·∫øu üìâ", delta="T∆∞∆°ng quan th·∫•p")
                        with metric_col3:
                            st.metric("Lo·∫°i", "D∆∞∆°ng ‚ÜóÔ∏è" if corr > 0 else "√Çm ‚ÜòÔ∏è")
                    else:
                        st.warning("Need at least 2 numeric variables.")
                
                else:  # Grouped Analysis
                    st.markdown("#### üì¶ Ph√¢n T√≠ch Theo Nh√≥m")
                    st.caption("So s√°nh ph√¢n ph·ªëi bi·∫øn s·ªë qua c√°c nh√≥m ph√¢n lo·∫°i")
                    
                    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
                    cat_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()
                    
                    if numeric_cols and cat_cols:
                        col1, col2 = st.columns(2)
                        with col1:
                            num_var = st.selectbox("Ch·ªçn bi·∫øn s·ªë:", numeric_cols, key="upload_group_num")
                        with col2:
                            cat_var = st.selectbox("Ch·ªçn bi·∫øn ph√¢n lo·∫°i:", cat_cols, key="upload_group_cat")
                        
                        # Limit categories to avoid clutter
                        unique_cats = data[cat_var].nunique()
                        if unique_cats > 10:
                            st.warning(f"‚ö†Ô∏è Bi·∫øn {cat_var} c√≥ {unique_cats} nh√≥m. Ch·ªâ hi·ªÉn th·ªã 10 nh√≥m ph·ªï bi·∫øn nh·∫•t.")
                            top_cats = data[cat_var].value_counts().head(10).index
                            plot_data = data[data[cat_var].isin(top_cats)]
                        else:
                            plot_data = data
                        
                        # Choose plot type
                        plot_type = st.radio(
                            "Lo·∫°i bi·ªÉu ƒë·ªì:",
                            ["Box Plot", "Violin Plot", "Strip Plot"],
                            horizontal=True,
                            key="upload_group_plot_type"
                        )
                        
                        if plot_type == "Box Plot":
                            fig = px.box(
                                plot_data,
                                x=cat_var,
                                y=num_var,
                                color=cat_var,
                                title=f"Ph√¢n ph·ªëi c·ªßa {num_var} theo {cat_var}",
                                points="outliers"
                            )
                        elif plot_type == "Violin Plot":
                            fig = px.violin(
                                plot_data,
                                x=cat_var,
                                y=num_var,
                                color=cat_var,
                                title=f"Ph√¢n ph·ªëi c·ªßa {num_var} theo {cat_var}",
                                box=True,
                                points="outliers"
                            )
                        else:  # Strip Plot
                            fig = px.strip(
                                plot_data,
                                x=cat_var,
                                y=num_var,
                                color=cat_var,
                                title=f"Ph√¢n ph·ªëi c·ªßa {num_var} theo {cat_var}"
                            )
                        
                        fig.update_layout(
                            template="plotly_dark",
                            height=500,
                            xaxis_tickangle=-45
                        )
                        
                        st.plotly_chart(fig, width='stretch')
                        
                        # Statistics by group
                        st.markdown("#### üìä Th·ªëng K√™ Theo Nh√≥m")
                        group_stats = plot_data.groupby(cat_var)[num_var].agg([
                            ('Count', 'count'),
                            ('Mean', 'mean'),
                            ('Median', 'median'),
                            ('Std Dev', 'std'),
                            ('Min', 'min'),
                            ('Max', 'max')
                        ]).round(2)
                        
                        st.dataframe(group_stats, width='stretch')
                    else:
                        if not numeric_cols:
                            st.warning("Kh√¥ng c√≥ bi·∫øn s·ªë n√†o trong d·ªØ li·ªáu.")
                        if not cat_cols:
                            st.warning("Kh√¥ng c√≥ bi·∫øn ph√¢n lo·∫°i n√†o trong d·ªØ li·ªáu.")
            
            # Tab 4: AI Analysis
            elif selected_tab == tabs[3]:
                st.markdown("### ‚ú® Ph√¢n T√≠ch T·ª± ƒê·ªông B·∫±ng AI")
                
                # Check LLM configuration
                is_llm_configured = LLMConfig.is_configured()
                
                if not is_llm_configured:
                    st.info("""
                    ‚ÑπÔ∏è **Ch∆∞a c·∫•u h√¨nh LLM API**
                    
                    ƒê·ªÉ s·ª≠ d·ª•ng ph√¢n t√≠ch AI chi ti·∫øt, vui l√≤ng:
                    1. T·∫°o file `.env` trong th∆∞ m·ª•c g·ªëc
                    2. Th√™m Google API key: `GOOGLE_API_KEY=...`
                    3. (T√πy ch·ªçn) Ch·ªçn model: `GOOGLE_MODEL=gemini-2.5-flash`
                    4. (T√πy ch·ªçn) Ch·ªçn provider: `LLM_PROVIDER=google`
                    
                    **L·∫•y Google API key mi·ªÖn ph√≠ t·∫°i: https://aistudio.google.com/app/apikey**
                    
                    **Hi·ªán t·∫°i s·∫Ω s·ª≠ d·ª•ng ch·∫ø ƒë·ªô ph√¢n t√≠ch t·ª± ƒë·ªông c∆° b·∫£n.**
                    """)
                
                st.markdown("""
                <div style="background-color: #262730; padding: 1.5rem; border-radius: 10px; border-left: 4px solid #667eea;">
                    <h4 style="margin-top: 0; color: #667eea;">üí° Ph√¢n T√≠ch T·ª± ƒê·ªông</h4>
                    <p>AI s·∫Ω ph√¢n t√≠ch to√†n b·ªô k·∫øt qu·∫£ EDA v√† cung c·∫•p:</p>
                    <ul>
                        <li>‚ú® ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu t·ªïng th·ªÉ</li>
                        <li>üìä Nh·∫≠n x√©t v·ªÅ ph√¢n ph·ªëi c√°c bi·∫øn quan tr·ªçng</li>
                        <li>üîó Ph√°t hi·ªán t∆∞∆°ng quan v√† m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn</li>
                        <li>‚ö†Ô∏è C·∫£nh b√°o v·ªÅ outliers, missing data v√† v·∫•n ƒë·ªÅ ti·ªÅm ·∫©n</li>
                        <li>üí° ƒê·ªÅ xu·∫•t roadmap ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu chi ti·∫øt</li>
                        <li>üéØ D·ª± ƒëo√°n kh·∫£ nƒÉng x√¢y d·ª±ng m√¥ h√¨nh hi·ªáu qu·∫£</li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)
                
                st.markdown("<br>", unsafe_allow_html=True)
                
                # Options
                col1, col2 = st.columns([3, 1])
                with col1:
                    analysis_button = st.button(
                        "üîÑ T·∫°o Ph√¢n T√≠ch AI" if is_llm_configured else "üìä T·∫°o Ph√¢n T√≠ch T·ª± ƒê·ªông",
                        width='stretch',
                        type="primary",
                        key="ai_analysis_btn"
                    )
                with col2:
                    show_raw_summary = st.checkbox("Xem EDA Summary", value=False, key="show_eda_raw")
                
                # Show raw EDA summary if requested
                if show_raw_summary:
                    st.markdown("---")
                    st.markdown("#### üìã EDA Summary (Raw Data)")
                    with st.expander("Xem d·ªØ li·ªáu th·ªëng k√™ chi ti·∫øt", expanded=False):
                        summary_text = get_eda_summary(data, format="text")
                        st.text(summary_text)
                
                # Generate AI analysis
                if analysis_button:
                    with st.spinner("üìã ƒêang ph√¢n t√≠ch d·ªØ li·ªáu..." if is_llm_configured else "üìä ƒêang t·∫°o b√°o c√°o..."):
                        try:
                            # Get API key and provider from config
                            api_key = LLMConfig.get_api_key() if is_llm_configured else None
                            provider = LLMConfig.DEFAULT_PROVIDER
                            
                            # Analyze with LLM
                            analysis_result = analyze_eda_with_llm(data, api_key=api_key, provider=provider)
                            
                            # Store in session state
                            st.session_state.ai_analysis = analysis_result
                            
                            st.success("‚úÖ Ph√¢n t√≠ch ho√†n th√†nh!" if is_llm_configured else "‚úÖ B√°o c√°o ƒë√£ ƒë∆∞·ª£c t·∫°o!")
                        
                        except Exception as e:
                            st.error(f"‚ùå L·ªói khi t·∫°o ph√¢n t√≠ch: {str(e)}")
                            st.info("üí° Vui l√≤ng ki·ªÉm tra API key v√† k·∫øt n·ªëi internet.")
                            import traceback
                            st.code(traceback.format_exc())
                
                # Display analysis if available
                if 'ai_analysis' in st.session_state and st.session_state.ai_analysis:
                    st.markdown("---")
                    st.markdown("### üìù K·∫øt Qu·∫£ Ph√¢n T√≠ch")
                    
                    # Display in a nice container
                    with st.container():
                        st.markdown(st.session_state.ai_analysis)
                    
                    # Auto-generate preprocessing suggestions (but don't display here)
                    # Check if we already have suggestions
                    if 'preprocessing_suggestions' not in st.session_state:
                        # Auto-generate on first time
                        with st.spinner("ü§ñ ƒêang t·∫°o g·ª£i √Ω ti·ªÅn x·ª≠ l√Ω t·ª´ AI..."):
                            try:
                                # Call LLM to generate preprocessing suggestions
                                provider = LLMConfig.DEFAULT_PROVIDER
                                api_key = LLMConfig.get_api_key() if is_llm_configured else None
                                
                                # Create prompt for preprocessing suggestions
                                suggestions_prompt = f"""D·ª±a tr√™n k·∫øt qu·∫£ ph√¢n t√≠ch EDA sau ƒë√¢y, h√£y t·∫°o m·ªôt roadmap ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu theo ƒê√öNG 8 B∆Ø·ªöC sau:

K·∫æT QU·∫¢ PH√ÇN T√çCH EDA:
{st.session_state.ai_analysis}

Y√äU C·∫¶U:
Tr·∫£ v·ªÅ roadmap ti·ªÅn x·ª≠ l√Ω theo ƒê√öNG 8 B∆Ø·ªöC SAU (kh√¥ng ƒë∆∞·ª£c th√™m b·ªõt b∆∞·ªõc):

**B∆∞·ªõc 1: Chia T·∫≠p Train/Valid/Test**
- ƒê·ªÅ xu·∫•t t·ª∑ l·ªá chia ph√π h·ª£p (v√≠ d·ª•: 70/15/15 ho·∫∑c 80/10/10)
- X√°c ƒë·ªãnh xem c√≥ c·∫ßn stratified split kh√¥ng (d·ª±a v√†o ph√¢n ph·ªëi target)
- Gi·∫£i th√≠ch l√Ω do ch·ªçn t·ª∑ l·ªá ƒë√≥

**B∆∞·ªõc 2: X·ª≠ L√Ω Bi·∫øn ƒê·ªãnh Danh & Gi√° Tr·ªã Kh√¥ng H·ª£p L·ªá**
- X√°c ƒë·ªãnh v√† lo·∫°i b·ªè c√°c c·ªôt ƒë·ªãnh danh (ID, customer_id, ...)
- Ph√°t hi·ªán v√† x·ª≠ l√Ω c√°c gi√° tr·ªã kh√¥ng h·ª£p l·ªá (√¢m, ngo√†i ph·∫°m vi, ...)
- Li·ªát k√™ C·ª§ TH·ªÇ t√™n c·ªôt c·∫ßn x·ª≠ l√Ω

**B∆∞·ªõc 3: X·ª≠ L√Ω Gi√° Tr·ªã Thi·∫øu**
- X√°c ƒë·ªãnh c√°c c·ªôt c√≥ missing values
- ƒê·ªÅ xu·∫•t ph∆∞∆°ng ph√°p x·ª≠ l√Ω CHO T·ª™NG C·ªòT (drop, mean/median/mode imputation, forward/backward fill, ...)
- Gi·∫£i th√≠ch l√Ω do ch·ªçn ph∆∞∆°ng ph√°p ƒë√≥

**B∆∞·ªõc 4: X·ª≠ L√Ω Outliers & Bi·∫øn ƒê·ªïi Ph√¢n Ph·ªëi**
- X√°c ƒë·ªãnh c√°c c·ªôt c√≥ outliers nghi√™m tr·ªçng
- ƒê·ªÅ xu·∫•t ph∆∞∆°ng ph√°p x·ª≠ l√Ω outliers (Winsorization, IQR, Z-score, ...)
- ƒê·ªÅ xu·∫•t bi·∫øn ƒë·ªïi ph√¢n ph·ªëi n·∫øu c·∫ßn (Log, Box-Cox, Yeo-Johnson, ...)
- Gi·∫£i th√≠ch l√Ω do cho t·ª´ng ph∆∞∆°ng ph√°p

**B∆∞·ªõc 5: M√£ H√≥a Bi·∫øn Ph√¢n Lo·∫°i**
- X√°c ƒë·ªãnh c√°c bi·∫øn ph√¢n lo·∫°i c·∫ßn m√£ h√≥a
- ƒê·ªÅ xu·∫•t ph∆∞∆°ng ph√°p m√£ h√≥a CHO T·ª™NG C·ªòT (One-Hot, Label, Target, Ordinal, Frequency Encoding, ...)
- Gi·∫£i th√≠ch l√Ω do ch·ªçn ph∆∞∆°ng ph√°p ƒë√≥ (d·ª±a v√†o cardinality, m·ªëi quan h·ªá v·ªõi target, th·ª© t·ª±, ...)

**B∆∞·ªõc 6: Ph√¢n Nh√≥m (Binning) Bi·∫øn Li√™n T·ª•c**
- X√°c ƒë·ªãnh c√°c bi·∫øn li√™n t·ª•c c√≥ th·ªÉ ƒë∆∞·ª£c binning (n·∫øu c√≥)
- ƒê·ªÅ xu·∫•t ph∆∞∆°ng ph√°p binning (Equal Width, Equal Frequency, Quantile, Custom)
- ƒê·ªÅ xu·∫•t s·ªë bins ph√π h·ª£p v√† gi·∫£i th√≠ch l√Ω do

**B∆∞·ªõc 7: Chu·∫©n H√≥a / Scaling**
- X√°c ƒë·ªãnh c√°c bi·∫øn s·ªë c·∫ßn scaling
- ƒê·ªÅ xu·∫•t ph∆∞∆°ng ph√°p scaling ph√π h·ª£p (StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, ...)
- Gi·∫£i th√≠ch l√Ω do ch·ªçn ph∆∞∆°ng ph√°p ƒë√≥ (d·ª±a v√†o ph√¢n ph·ªëi, outliers, model s·∫Ω d√πng, ...)

**B∆∞·ªõc 8: C√¢n B·∫±ng D·ªØ Li·ªáu**
- Ki·ªÉm tra t·ª∑ l·ªá c√°c class trong target variable
- N·∫øu m·∫•t c√¢n b·∫±ng (imbalanced), ƒë·ªÅ xu·∫•t ph∆∞∆°ng ph√°p x·ª≠ l√Ω (SMOTE, Undersampling, Class Weights, ...)
- ƒê·ªÅ xu·∫•t t·ª∑ l·ªá c√¢n b·∫±ng ph√π h·ª£p

FORMAT:
- M·ªói b∆∞·ªõc ph·∫£i c√≥ ti√™u ƒë·ªÅ in ƒë·∫≠m v·ªõi emoji
- D∆∞·ªõi m·ªói b∆∞·ªõc l√† danh s√°ch g·∫°ch ƒë·∫ßu d√≤ng CHI TI·∫æT, C·ª§ TH·ªÇ
- ƒê·ªÅ c·∫≠p T√äN C·ªòT v√† PH∆Ø∆†NG PH√ÅP c·ª• th·ªÉ
- Ng√¥n ng·ªØ: Ti·∫øng Vi·ªát chuy√™n nghi·ªáp

QUAN TR·ªåNG: 
- PH·∫¢I tr·∫£ v·ªÅ ƒê√öNG 8 B∆Ø·ªöC theo c·∫•u tr√∫c tr√™n
- M·ªói b∆∞·ªõc ph·∫£i C·ª§ TH·ªÇ, ƒë·ªÅ c·∫≠p t√™n c·ªôt v√† ph∆∞∆°ng ph√°p
- KH√îNG th√™m b∆∞·ªõc kh√°c, KH√îNG t√≥m t·∫Øt chung chung
- CH·ªà tr·∫£ v·ªÅ 8 b∆∞·ªõc, KH√îNG gi·∫£i th√≠ch th√™m!"""

                                # Call LLM
                                if is_llm_configured and api_key:
                                    if provider == "google":
                                        import google.generativeai as genai
                                        genai.configure(api_key=api_key)
                                        model = genai.GenerativeModel(LLMConfig.get_model(provider))
                                        response = model.generate_content(suggestions_prompt)
                                        suggestions_text = response.text.strip()
                                    else:
                                        # Fallback for other providers or no API
                                        suggestions_text = """**üìã Roadmap Ti·ªÅn X·ª≠ L√Ω D·ªØ Li·ªáu:**

**B∆∞·ªõc 1: üîç X·ª≠ L√Ω Bi·∫øn ƒê·ªãnh Danh & Gi√° Tr·ªã Kh√¥ng H·ª£p L·ªá**
- X√°c ƒë·ªãnh v√† lo·∫°i b·ªè c√°c c·ªôt ƒë·ªãnh danh (customer_id, ID, ...)
- Ki·ªÉm tra v√† x·ª≠ l√Ω c√°c gi√° tr·ªã kh√¥ng h·ª£p l·ªá (√¢m, ngo√†i ph·∫°m vi h·ª£p l√Ω)

**B∆∞·ªõc 2: ‚ùì X·ª≠ L√Ω Gi√° Tr·ªã Thi·∫øu**
- X√°c ƒë·ªãnh c√°c c·ªôt c√≥ missing values
- √Åp d·ª•ng ph∆∞∆°ng ph√°p ph√π h·ª£p: Drop, Mean/Median Imputation, ho·∫∑c Forward Fill

**B∆∞·ªõc 3: ‚ö†Ô∏è X·ª≠ L√Ω Outliers & Bi·∫øn ƒê·ªïi Ph√¢n Ph·ªëi**
- Ph√°t hi·ªán outliers b·∫±ng ph∆∞∆°ng ph√°p IQR ho·∫∑c Z-score
- √Åp d·ª•ng Winsorization ho·∫∑c Log Transform cho c√°c c·ªôt c√≥ outliers
- Bi·∫øn ƒë·ªïi ph√¢n ph·ªëi l·ªách b·∫±ng Log ho·∫∑c Box-Cox n·∫øu c·∫ßn

**B∆∞·ªõc 4: üî§ M√£ H√≥a Bi·∫øn Ph√¢n Lo·∫°i**
- One-Hot Encoding cho bi·∫øn c√≥ cardinality th·∫•p (< 10 categories)
- Label Encoding cho bi·∫øn ordinal ho·∫∑c binary
- Target Encoding cho bi·∫øn c√≥ cardinality cao"""
                                else:
                                    suggestions_text = """**üìã Roadmap Ti·ªÅn X·ª≠ L√Ω D·ªØ Li·ªáu:**

**B∆∞·ªõc 1: ‚úÇÔ∏è Chia T·∫≠p Train/Valid/Test**
- ƒê·ªÅ xu·∫•t chia 70% Train, 15% Valid, 15% Test
- S·ª≠ d·ª•ng stratified split ƒë·ªÉ gi·ªØ c√¢n b·∫±ng ph√¢n ph·ªëi target
- ƒê·∫£m b·∫£o t√°ch d·ªØ li·ªáu TR∆Ø·ªöC khi th·ª±c hi·ªán b·∫•t k·ª≥ b∆∞·ªõc x·ª≠ l√Ω n√†o

**B∆∞·ªõc 2: üîç X·ª≠ L√Ω Bi·∫øn ƒê·ªãnh Danh & Gi√° Tr·ªã Kh√¥ng H·ª£p L·ªá**
- X√°c ƒë·ªãnh v√† lo·∫°i b·ªè c√°c c·ªôt ƒë·ªãnh danh (customer_id, ID, ...)
- Ki·ªÉm tra v√† x·ª≠ l√Ω c√°c gi√° tr·ªã kh√¥ng h·ª£p l·ªá (√¢m, ngo√†i ph·∫°m vi h·ª£p l√Ω)

**B∆∞·ªõc 3: ‚ùì X·ª≠ L√Ω Gi√° Tr·ªã Thi·∫øu**
- X√°c ƒë·ªãnh c√°c c·ªôt c√≥ missing values
- √Åp d·ª•ng ph∆∞∆°ng ph√°p ph√π h·ª£p: Drop, Mean/Median/Mode Imputation, ho·∫∑c Forward/Backward Fill

**B∆∞·ªõc 4: ‚ö†Ô∏è X·ª≠ L√Ω Outliers & Bi·∫øn ƒê·ªïi Ph√¢n Ph·ªëi**
- Ph√°t hi·ªán outliers b·∫±ng ph∆∞∆°ng ph√°p IQR ho·∫∑c Z-score
- √Åp d·ª•ng Winsorization ho·∫∑c Log Transform cho c√°c c·ªôt c√≥ outliers
- Bi·∫øn ƒë·ªïi ph√¢n ph·ªëi l·ªách b·∫±ng Log, Box-Cox, ho·∫∑c Yeo-Johnson n·∫øu c·∫ßn

**B∆∞·ªõc 5: üî§ M√£ H√≥a Bi·∫øn Ph√¢n Lo·∫°i**
- One-Hot Encoding cho bi·∫øn c√≥ cardinality th·∫•p (< 10 categories)
- Label Encoding cho bi·∫øn ordinal ho·∫∑c binary
- Target Encoding cho bi·∫øn c√≥ cardinality cao
- Frequency Encoding cho bi·∫øn c√≥ nhi·ªÅu categories

**B∆∞·ªõc 6: üìä Ph√¢n Nh√≥m (Binning) Bi·∫øn Li√™n T·ª•c**
- Xem x√©t binning cho c√°c bi·∫øn li√™n t·ª•c ph√π h·ª£p
- √Åp d·ª•ng Equal Width, Equal Frequency, ho·∫∑c Quantile binning
- ƒê·ªÅ xu·∫•t 3-10 bins t√πy thu·ªôc v√†o d·ªØ li·ªáu

**B∆∞·ªõc 7: ‚öñÔ∏è Chu·∫©n H√≥a / Scaling**
- StandardScaler cho Linear models, Neural Networks
- MinMaxScaler cho bounded range [0,1]
- RobustScaler n·∫øu c√≥ nhi·ªÅu outliers

**B∆∞·ªõc 8: üéØ C√¢n B·∫±ng D·ªØ Li·ªáu**
- Ki·ªÉm tra t·ª∑ l·ªá c√°c class trong target
- √Åp d·ª•ng SMOTE n·∫øu imbalanced < 40%
- S·ª≠ d·ª•ng Class Weights ho·∫∑c Undersampling n·∫øu c·∫ßn"""
                                
                                # Save to session state (silently, no notification)
                                st.session_state.preprocessing_suggestions = suggestions_text
                                st.session_state.eda_analysis_result = st.session_state.ai_analysis
                                st.session_state.llm_provider = provider
                                
                            except Exception as e:
                                # Save error message but don't show notification
                                st.session_state.preprocessing_suggestions = f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫°o g·ª£i √Ω t·ª± ƒë·ªông: {str(e)}\n\nVui l√≤ng xem ph√¢n t√≠ch EDA ·ªü tr√™n ƒë·ªÉ t·ª± ƒë∆∞a ra c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω."
                    
                    # Download option
                    st.markdown("---")
                    st.download_button(
                        label="üì• T·∫£i xu·ªëng ph√¢n t√≠ch (Markdown)",
                        data=st.session_state.ai_analysis,
                        file_name="eda_analysis.md",
                        mime="text/markdown",
                        width='stretch'
                    )
                else:
                    st.markdown("---")
                    st.info("üëÜ Nh·∫•n n√∫t ph√≠a tr√™n ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch!")
        
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªçc file: {str(e)}")
    
    else:
        # If data exists, show full EDA with option to clear
        if 'data' in st.session_state and st.session_state.data is not None:
            data = st.session_state.data
            
            # Show info bar with clear button
            col_info1, col_info2, col_info3 = st.columns([2, 1, 1])
            with col_info1:
                st.success(f"‚úÖ ƒêang xem dataset hi·ªán t·∫°i: {len(data)} d√≤ng, {len(data.columns)} c·ªôt")
            with col_info2:
                st.info("üíæ D·ªØ li·ªáu ƒë√£ l∆∞u trong session")
            with col_info3:
                if st.button("üóëÔ∏è X√≥a & Upload M·ªõi", width='stretch', key="clear_and_upload"):
                    clear_data_related_state()
                    st.success("‚úÖ ƒê√£ x√≥a! Upload file m·ªõi b√™n d∆∞·ªõi.")
                    st.rerun()
            
            st.markdown("---")
            
            # Use session state to track current tab (workaround for st.tabs not preserving state)
            tab_options = ["üìã D·ªØ Li·ªáu M·∫´u", "üìä Th·ªëng K√™ M√¥ T·∫£", "üìà Ph√¢n Ph·ªëi D·ªØ Li·ªáu", "‚ú® Ph√¢n T√≠ch AI"]
            if 'current_eda_tab_cached' not in st.session_state or st.session_state.current_eda_tab_cached not in tab_options:
                st.session_state.current_eda_tab_cached = "üìã D·ªØ Li·ªáu M·∫´u"
            
            # Tab selector using radio (preserves state on rerun)
            selected_tab = st.radio(
                "Ch·ªçn m·ª•c:",
                tab_options,
                horizontal=True,
                key="eda_tab_selector_cached",
                index=tab_options.index(st.session_state.current_eda_tab_cached)
            )
            st.session_state.current_eda_tab_cached = selected_tab
            
            st.markdown("---")
            
            # Tab 1: Sample Data
            if selected_tab == "üìã D·ªØ Li·ªáu M·∫´u":
                st.markdown("### üìã D·ªØ Li·ªáu M·∫´u")
                
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.info(f"üìä Hi·ªÉn th·ªã to√†n b·ªô {len(data):,} d√≤ng d·ªØ li·ªáu")
                with col2:
                    show_charts = st.checkbox("Hi·ªán bi·ªÉu ƒë·ªì", value=True, key="show_charts_cached")
                
                display_data = data.copy()
                
                if show_charts:
                    st.markdown("---")
                    
                    import base64
                    from io import BytesIO
                    import matplotlib
                    matplotlib.use('Agg')
                    import matplotlib.pyplot as plt
                    
                    header_html = "<div style='overflow-x: auto;'><table style='width: 100%; border-collapse: collapse; font-size: 0.85rem;'>"
                    header_html += "<tr style='background-color: #1e1e1e;'>"
                    
                    for col_name in data.columns:
                        col_data = data[col_name]
                        header_html += f"<td style='border: 1px solid #444; padding: 10px; text-align: center; vertical-align: top; min-width: 120px;'>"
                        header_html += f"<div style='font-weight: bold; margin-bottom: 5px;'>{col_name}</div>"
                        
                        if pd.api.types.is_numeric_dtype(col_data):
                            col_clean = col_data.dropna()
                            if len(col_clean) > 0:
                                fig, ax = plt.subplots(figsize=(1.5, 0.8), facecolor='none')
                                ax.hist(col_clean, bins=min(15, max(5, len(col_clean) // 10)), color='#667eea', edgecolor='none')
                                ax.set_xticks([])
                                ax.set_yticks([])
                                ax.spines['top'].set_visible(False)
                                ax.spines['right'].set_visible(False)
                                ax.spines['bottom'].set_visible(False)
                                ax.spines['left'].set_visible(False)
                                ax.patch.set_alpha(0)
                                
                                buffer = BytesIO()
                                plt.savefig(buffer, format='png', bbox_inches='tight', transparent=True, dpi=50)
                                buffer.seek(0)
                                img_base64 = base64.b64encode(buffer.read()).decode()
                                plt.close(fig)
                                
                                header_html += f"<img src='data:image/png;base64,{img_base64}' style='width: 100%; max-width: 120px;'/>"
                                header_html += f"<div style='font-size: 0.7rem; margin-top: 3px;'>Min: {col_clean.min():.1f} | Max: {col_clean.max():.1f}</div>"
                                header_html += f"<div style='font-size: 0.7rem;'>Mean: {col_clean.mean():.1f} | Unique: {col_data.nunique()}</div>"
                        else:
                            value_counts = col_data.value_counts().head(3)
                            total = len(col_data)
                            
                            if len(value_counts) > 0:
                                percentages = (value_counts / total * 100)
                                
                                fig, ax = plt.subplots(figsize=(1.5, 0.8), facecolor='none')
                                ax.barh(range(len(value_counts)), percentages.values, color='#764ba2')
                                ax.set_yticks(range(len(value_counts)))
                                ax.set_yticklabels([str(v)[:8] for v in value_counts.index], fontsize=6, color='white')
                                ax.set_xticks([])
                                ax.spines['top'].set_visible(False)
                                ax.spines['right'].set_visible(False)
                                ax.spines['bottom'].set_visible(False)
                                ax.spines['left'].set_visible(False)
                                ax.patch.set_alpha(0)
                                ax.invert_yaxis()
                                
                                for i, (idx, pct) in enumerate(zip(value_counts.index, percentages.values)):
                                    ax.text(pct + 2, i, f'{pct:.0f}%', va='center', fontsize=6, color='white')
                                
                                buffer = BytesIO()
                                plt.savefig(buffer, format='png', bbox_inches='tight', transparent=True, dpi=50)
                                buffer.seek(0)
                                img_base64 = base64.b64encode(buffer.read()).decode()
                                plt.close(fig)
                                
                                header_html += f"<img src='data:image/png;base64,{img_base64}' style='width: 100%; max-width: 120px;'/>"
                                header_html += f"<div style='font-size: 0.7rem; margin-top: 3px;'>Unique: {col_data.nunique()} | Mode: {str(value_counts.index[0])[:10]}</div>"
                        
                        missing_count = col_data.isnull().sum()
                        missing_pct = (missing_count / len(col_data) * 100) if len(col_data) > 0 else 0
                        if missing_count > 0:
                            header_html += f"<div style='font-size: 0.65rem; color: #ffaa00; margin-top: 2px;'>‚ö†Ô∏è Missing: {missing_count} ({missing_pct:.1f}%)</div>"
                        else:
                            header_html += f"<div style='font-size: 0.65rem; color: #44ff44; margin-top: 2px;'>‚úÖ No missing</div>"
                        
                        header_html += "</td>"
                    
                    header_html += "</tr></table></div>"
                    st.markdown(header_html, unsafe_allow_html=True)
                
                st.markdown("---")
                st.dataframe(display_data, width='stretch', height=500)
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("üìä T·ªïng s·ªë d√≤ng", f"{len(data):,}")
                with col2:
                    st.metric("üìã T·ªïng s·ªë c·ªôt", len(data.columns))
                with col3:
                    missing_pct = (data.isnull().sum().sum() / (len(data) * len(data.columns)) * 100)
                    st.metric("‚ùì D·ªØ li·ªáu thi·∫øu", f"{missing_pct:.1f}%")
                with col4:
                    numeric_cols = data.select_dtypes(include=[np.number]).columns
                    st.metric("üî¢ C·ªôt s·ªë", len(numeric_cols))
            
            # Tab 2, 3, 4: Copy FULL content from uploaded section
            elif selected_tab == "üìä Th·ªëng K√™ M√¥ T·∫£":
                st.markdown("### üìä Th·ªëng K√™ M√¥ T·∫£")
                
                # Numeric columns stats
                numeric_data = data.select_dtypes(include=[np.number])
                if not numeric_data.empty:
                    st.markdown("#### üî¢ Bi·∫øn S·ªë")
                    
                    stats_df = numeric_data.describe().T
                    stats_df['missing'] = data[numeric_data.columns].isnull().sum()
                    stats_df['missing_pct'] = (stats_df['missing'] / len(data) * 100).round(2)
                    
                    # Highlight styling
                    st.dataframe(
                        stats_df.style.background_gradient(cmap='viridis', subset=['mean', 'std']),
                        width='stretch'
                    )
                    
                    # Download stats
                    csv = stats_df.to_csv(index=True).encode('utf-8')
                    st.download_button(
                        "üì• T·∫£i Th·ªëng K√™ (CSV)",
                        csv,
                        "statistics.csv",
                        "text/csv",
                        key='download-stats-cached'
                    )
                
                # Categorical columns
                categorical_data = data.select_dtypes(include=['object', 'category'])
                if not categorical_data.empty:
                    st.markdown("---")
                    st.markdown("#### ÔøΩ Bi·∫øn Ph√¢n Lo·∫°i")
                    
                    cat_info = []
                    for col in categorical_data.columns:
                        cat_info.append({
                            'T√™n c·ªôt': col,
                            'S·ªë gi√° tr·ªã kh√°c nhau': data[col].nunique(),
                            'Gi√° tr·ªã ph·ªï bi·∫øn nh·∫•t': data[col].mode()[0] if not data[col].mode().empty else 'N/A',
                            'T·∫ßn su·∫•t cao nh·∫•t': data[col].value_counts().iloc[0] if len(data[col].value_counts()) > 0 else 0,
                            'Thi·∫øu': data[col].isnull().sum(),
                            'T·ª∑ l·ªá thi·∫øu (%)': f"{data[col].isnull().sum() / len(data) * 100:.2f}"
                        })
                    
                    cat_df = pd.DataFrame(cat_info)
                    st.dataframe(cat_df, width='stretch')
            
            elif selected_tab == "üìà Ph√¢n Ph·ªëi D·ªØ Li·ªáu":
                st.markdown("### üìà Ph√¢n Ph·ªëi & T∆∞∆°ng Quan D·ªØ Li·ªáu")
                
                viz_type = st.radio(
                    "Ch·ªçn lo·∫°i ph√¢n t√≠ch:",
                    ["Bi·ªÉu ƒê·ªì Nhi·ªát T∆∞∆°ng Quan", "Bi·ªÉu ƒê·ªì Ph√¢n T√°n (2 Bi·∫øn)"],
                    horizontal=True,
                    key="viz_type_cached"
                )
                
                if viz_type == "Bi·ªÉu ƒê·ªì Nhi·ªát T∆∞∆°ng Quan":
                    st.markdown("#### üî• Ma Tr·∫≠n T∆∞∆°ng Quan")
                    
                    numeric_data = data.select_dtypes(include=[np.number])
                    if not numeric_data.empty and len(numeric_data.columns) > 1:
                        corr_matrix = numeric_data.corr()
                        
                        # Create heatmap
                        fig = px.imshow(
                            corr_matrix,
                            text_auto='.2f',
                            aspect="auto",
                            color_continuous_scale='RdBu_r',
                            title="Ma tr·∫≠n t∆∞∆°ng quan gi·ªØa c√°c bi·∫øn",
                            zmin=-1,
                            zmax=1
                        )
                        
                        fig.update_layout(
                            template="plotly_dark",
                            height=600
                        )
                        
                        st.plotly_chart(fig, width='stretch')
                        
                        # Find high correlations
                        st.markdown("#### üîç C√°c C·∫∑p Bi·∫øn C√≥ T∆∞∆°ng Quan Cao")
                        
                        threshold = st.slider("Ng∆∞·ª°ng t∆∞∆°ng quan:", 0.0, 1.0, 0.7, 0.05, key="cached_corr_threshold")
                        
                        high_corr = []
                        for i in range(len(corr_matrix.columns)):
                            for j in range(i+1, len(corr_matrix.columns)):
                                if abs(corr_matrix.iloc[i, j]) >= threshold:
                                    high_corr.append({
                                        'Bi·∫øn 1': corr_matrix.columns[i],
                                        'Bi·∫øn 2': corr_matrix.columns[j],
                                        'T∆∞∆°ng quan': f"{corr_matrix.iloc[i, j]:.3f}",
                                        'Lo·∫°i': 'D∆∞∆°ng' if corr_matrix.iloc[i, j] > 0 else '√Çm'
                                    })
                        
                        if high_corr:
                            st.dataframe(pd.DataFrame(high_corr), width='stretch', hide_index=True)
                        else:
                            st.info(f"Kh√¥ng t√¨m th·∫•y c·∫∑p bi·∫øn n√†o c√≥ t∆∞∆°ng quan >= {threshold}")
                    else:
                        st.warning("C·∫ßn √≠t nh·∫•t 2 bi·∫øn s·ªë ƒë·ªÉ t·∫°o ma tr·∫≠n t∆∞∆°ng quan.")
                
                else:  # Scatter Plot (2 Bi·∫øn)
                    st.markdown("#### üìä Ph√¢n T√≠ch Chi Ti·∫øt 2 Bi·∫øn")
                    
                    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
                    if len(numeric_cols) >= 2:
                        col1, col2 = st.columns(2)
                        with col1:
                            x_var = st.selectbox("Ch·ªçn bi·∫øn X:", numeric_cols, key="cached_scatter_x")
                        with col2:
                            y_vars = [col for col in numeric_cols if col != x_var]
                            y_var = st.selectbox("Ch·ªçn bi·∫øn Y:", y_vars, key="cached_scatter_y")
                        
                        # Options
                        opt_col1, opt_col2 = st.columns(2)
                        with opt_col1:
                            show_trendline = st.checkbox("Hi·ªán ƒë∆∞·ªùng xu h∆∞·ªõng", value=True, key="cached_scatter_trend")
                        with opt_col2:
                            show_marginal = st.checkbox("Hi·ªán ph√¢n ph·ªëi bi√™n", value=True, key="cached_scatter_marginal")
                        
                        # Create scatter plot
                        fig = px.scatter(
                            data,
                            x=x_var,
                            y=y_var,
                            trendline="ols" if show_trendline else None,
                            marginal_x="histogram" if show_marginal else None,
                            marginal_y="histogram" if show_marginal else None,
                            opacity=0.6,
                            title=f"M·ªëi quan h·ªá gi·ªØa {x_var} v√† {y_var}"
                        )
                        
                        fig.update_layout(
                            template="plotly_dark",
                            height=600
                        )
                        
                        st.plotly_chart(fig, width='stretch')
                        
                        # Calculate correlation
                        corr = data[x_var].corr(data[y_var])
                        
                        metric_col1, metric_col2, metric_col3 = st.columns(3)
                        with metric_col1:
                            st.metric("T∆∞∆°ng quan Pearson", f"{corr:.3f}")
                        with metric_col2:
                            if abs(corr) >= 0.7:
                                st.metric("M·ª©c ƒë·ªô", "M·∫°nh üí™", delta="T∆∞∆°ng quan cao")
                            elif abs(corr) >= 0.4:
                                st.metric("M·ª©c ƒë·ªô", "Trung b√¨nh ‚öñÔ∏è", delta="T∆∞∆°ng quan v·ª´a")
                            else:
                                st.metric("M·ª©c ƒë·ªô", "Y·∫øu üìâ", delta="T∆∞∆°ng quan th·∫•p")
                        with metric_col3:
                            st.metric("Lo·∫°i", "D∆∞∆°ng ‚ÜóÔ∏è" if corr > 0 else "√Çm ‚ÜòÔ∏è")
                    else:
                        st.warning("C·∫ßn √≠t nh·∫•t 2 bi·∫øn s·ªë.")
            
            elif selected_tab == "‚ú® Ph√¢n T√≠ch AI":
                st.markdown("### ‚ú® Ph√¢n T√≠ch T·ª± ƒê·ªông B·∫±ng AI")
                
                # Check LLM configuration
                is_llm_configured = LLMConfig.is_configured()
                
                if not is_llm_configured:
                    st.info("""
                    ‚ÑπÔ∏è **Ch∆∞a c·∫•u h√¨nh LLM API**
                    
                    ƒê·ªÉ s·ª≠ d·ª•ng ph√¢n t√≠ch AI chi ti·∫øt, vui l√≤ng:
                    1. T·∫°o file `.env` trong th∆∞ m·ª•c g·ªëc
                    2. Th√™m Google API key: `GOOGLE_API_KEY=...`
                    3. (T√πy ch·ªçn) Ch·ªçn model: `GOOGLE_MODEL=gemini-2.5-flash`
                    4. (T√πy ch·ªçn) Ch·ªçn provider: `LLM_PROVIDER=google`
                    
                    **L·∫•y Google API key mi·ªÖn ph√≠ t·∫°i: https://aistudio.google.com/app/apikey**
                    
                    **Hi·ªán t·∫°i s·∫Ω s·ª≠ d·ª•ng ch·∫ø ƒë·ªô ph√¢n t√≠ch t·ª± ƒë·ªông c∆° b·∫£n.**
                    """)
                
                st.markdown("""
                <div style="background-color: #262730; padding: 1.5rem; border-radius: 10px; border-left: 4px solid #667eea;">
                    <h4 style="margin-top: 0; color: #667eea;">üí° Ph√¢n T√≠ch T·ª± ƒê·ªông</h4>
                    <p>AI s·∫Ω ph√¢n t√≠ch to√†n b·ªô k·∫øt qu·∫£ EDA v√† cung c·∫•p:</p>
                    <ul>
                        <li>‚ú® ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu t·ªïng th·ªÉ</li>
                        <li>üìä Nh·∫≠n x√©t v·ªÅ ph√¢n ph·ªëi c√°c bi·∫øn quan tr·ªçng</li>
                        <li>üîó Ph√°t hi·ªán t∆∞∆°ng quan v√† m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn</li>
                        <li>‚ö†Ô∏è C·∫£nh b√°o v·ªÅ outliers, missing data v√† v·∫•n ƒë·ªÅ ti·ªÅm ·∫©n</li>
                        <li>üí° ƒê·ªÅ xu·∫•t roadmap ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu chi ti·∫øt</li>
                        <li>üéØ D·ª± ƒëo√°n kh·∫£ nƒÉng x√¢y d·ª±ng m√¥ h√¨nh hi·ªáu qu·∫£</li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)
                
                st.markdown("<br>", unsafe_allow_html=True)
                
                # Options
                col1, col2 = st.columns([3, 1])
                with col1:
                    analysis_button = st.button(
                        "üîÑ T·∫°o Ph√¢n T√≠ch AI" if is_llm_configured else "üìä T·∫°o Ph√¢n T√≠ch T·ª± ƒê·ªông",
                        width='stretch',
                        type="primary",
                        key="ai_analysis_btn_cached"
                    )
                with col2:
                    show_raw_summary = st.checkbox("Xem EDA Summary", value=False, key="show_eda_raw_cached")
                
                # Show raw EDA summary if requested
                if show_raw_summary:
                    st.markdown("---")
                    st.markdown("#### üìã EDA Summary (Raw Data)")
                    with st.expander("Xem d·ªØ li·ªáu th·ªëng k√™ chi ti·∫øt", expanded=False):
                        summary_text = get_eda_summary(data, format="text")
                        st.text(summary_text)
                
                # Generate AI analysis
                if analysis_button:
                    with st.spinner("üìã ƒêang ph√¢n t√≠ch d·ªØ li·ªáu..." if is_llm_configured else "üìä ƒêang t·∫°o b√°o c√°o..."):
                        try:
                            # Get API key and provider from config
                            api_key = LLMConfig.get_api_key() if is_llm_configured else None
                            provider = LLMConfig.DEFAULT_PROVIDER
                            
                            # Analyze with LLM
                            analysis_result = analyze_eda_with_llm(data, api_key=api_key, provider=provider)
                            
                            # Store in session state
                            st.session_state.ai_analysis = analysis_result
                            
                            st.success("‚úÖ Ph√¢n t√≠ch ho√†n th√†nh!" if is_llm_configured else "‚úÖ B√°o c√°o ƒë√£ ƒë∆∞·ª£c t·∫°o!")
                        
                        except Exception as e:
                            st.error(f"‚ùå L·ªói khi t·∫°o ph√¢n t√≠ch: {str(e)}")
                            st.info("üí° Vui l√≤ng ki·ªÉm tra API key v√† k·∫øt n·ªëi internet.")
                            import traceback
                            st.code(traceback.format_exc())
                
                # Display analysis if available
                if 'ai_analysis' in st.session_state and st.session_state.ai_analysis:
                    st.markdown("---")
                    st.markdown("### üìù K·∫øt Qu·∫£ Ph√¢n T√≠ch")
                    
                    # Display in a nice container
                    with st.container():
                        st.markdown(st.session_state.ai_analysis)
                    
                    # Auto-generate preprocessing suggestions after analysis
                    st.markdown("---")
                    st.markdown("### üí° G·ª£i √ù Ti·ªÅn X·ª≠ L√Ω")
                    
                    # Check if we already have suggestions
                    if 'preprocessing_suggestions' not in st.session_state:
                        # Auto-generate on first time
                        with st.spinner("ü§ñ ƒêang t·∫°o g·ª£i √Ω ti·ªÅn x·ª≠ l√Ω t·ª´ AI..."):
                            try:
                                # Call LLM to generate preprocessing suggestions
                                provider = LLMConfig.DEFAULT_PROVIDER
                                api_key = LLMConfig.get_api_key() if is_llm_configured else None
                                
                                # Create prompt for preprocessing suggestions
                                suggestions_prompt = f"""D·ª±a tr√™n k·∫øt qu·∫£ ph√¢n t√≠ch EDA sau ƒë√¢y, h√£y t·∫°o m·ªôt roadmap ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu theo ƒê√öNG 8 B∆Ø·ªöC sau:

K·∫æT QU·∫¢ PH√ÇN T√çCH EDA:
{st.session_state.ai_analysis}

Y√äU C·∫¶U:
Tr·∫£ v·ªÅ roadmap ti·ªÅn x·ª≠ l√Ω theo ƒê√öNG 8 B∆Ø·ªöC SAU (kh√¥ng ƒë∆∞·ª£c th√™m b·ªõt b∆∞·ªõc):

**B∆∞·ªõc 1: Chia T·∫≠p Train/Valid/Test**
- ƒê·ªÅ xu·∫•t t·ª∑ l·ªá chia ph√π h·ª£p (v√≠ d·ª•: 70/15/15 ho·∫∑c 80/10/10)
- X√°c ƒë·ªãnh xem c√≥ c·∫ßn stratified split kh√¥ng (d·ª±a v√†o ph√¢n ph·ªëi target)
- Gi·∫£i th√≠ch l√Ω do ch·ªçn t·ª∑ l·ªá ƒë√≥

**B∆∞·ªõc 2: X·ª≠ L√Ω Bi·∫øn ƒê·ªãnh Danh & Gi√° Tr·ªã Kh√¥ng H·ª£p L·ªá**
- X√°c ƒë·ªãnh v√† lo·∫°i b·ªè c√°c c·ªôt ƒë·ªãnh danh (ID, customer_id, ...)
- Ph√°t hi·ªán v√† x·ª≠ l√Ω c√°c gi√° tr·ªã kh√¥ng h·ª£p l·ªá (√¢m, ngo√†i ph·∫°m vi, ...)
- Li·ªát k√™ C·ª§ TH·ªÇ t√™n c·ªôt c·∫ßn x·ª≠ l√Ω

**B∆∞·ªõc 3: X·ª≠ L√Ω Gi√° Tr·ªã Thi·∫øu**
- X√°c ƒë·ªãnh c√°c c·ªôt c√≥ missing values
- ƒê·ªÅ xu·∫•t ph∆∞∆°ng ph√°p x·ª≠ l√Ω CHO T·ª™NG C·ªòT (drop, mean/median/mode imputation, forward/backward fill, ...)
- Gi·∫£i th√≠ch l√Ω do ch·ªçn ph∆∞∆°ng ph√°p ƒë√≥

**B∆∞·ªõc 4: X·ª≠ L√Ω Outliers & Bi·∫øn ƒê·ªïi Ph√¢n Ph·ªëi**
- X√°c ƒë·ªãnh c√°c c·ªôt c√≥ outliers nghi√™m tr·ªçng
- ƒê·ªÅ xu·∫•t ph∆∞∆°ng ph√°p x·ª≠ l√Ω outliers (Winsorization, IQR, Z-score, ...)
- ƒê·ªÅ xu·∫•t bi·∫øn ƒë·ªïi ph√¢n ph·ªëi n·∫øu c·∫ßn (Log, Box-Cox, Yeo-Johnson, ...)
- Gi·∫£i th√≠ch l√Ω do cho t·ª´ng ph∆∞∆°ng ph√°p

**B∆∞·ªõc 5: M√£ H√≥a Bi·∫øn Ph√¢n Lo·∫°i**
- X√°c ƒë·ªãnh c√°c bi·∫øn ph√¢n lo·∫°i c·∫ßn m√£ h√≥a
- ƒê·ªÅ xu·∫•t ph∆∞∆°ng ph√°p m√£ h√≥a CHO T·ª™NG C·ªòT (One-Hot, Label, Target, Ordinal, Frequency Encoding, ...)
- Gi·∫£i th√≠ch l√Ω do ch·ªçn ph∆∞∆°ng ph√°p ƒë√≥ (d·ª±a v√†o cardinality, m·ªëi quan h·ªá v·ªõi target, th·ª© t·ª±, ...)

**B∆∞·ªõc 6: Ph√¢n Nh√≥m (Binning) Bi·∫øn Li√™n T·ª•c**
- X√°c ƒë·ªãnh c√°c bi·∫øn li√™n t·ª•c c√≥ th·ªÉ ƒë∆∞·ª£c binning (n·∫øu c√≥)
- ƒê·ªÅ xu·∫•t ph∆∞∆°ng ph√°p binning (Equal Width, Equal Frequency, Quantile, Custom)
- ƒê·ªÅ xu·∫•t s·ªë bins ph√π h·ª£p v√† gi·∫£i th√≠ch l√Ω do

**B∆∞·ªõc 7: Chu·∫©n H√≥a / Scaling**
- X√°c ƒë·ªãnh c√°c bi·∫øn s·ªë c·∫ßn scaling
- ƒê·ªÅ xu·∫•t ph∆∞∆°ng ph√°p scaling ph√π h·ª£p (StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, ...)
- Gi·∫£i th√≠ch l√Ω do ch·ªçn ph∆∞∆°ng ph√°p ƒë√≥ (d·ª±a v√†o ph√¢n ph·ªëi, outliers, model s·∫Ω d√πng, ...)

**B∆∞·ªõc 8: C√¢n B·∫±ng D·ªØ Li·ªáu**
- Ki·ªÉm tra t·ª∑ l·ªá c√°c class trong target variable
- N·∫øu m·∫•t c√¢n b·∫±ng (imbalanced), ƒë·ªÅ xu·∫•t ph∆∞∆°ng ph√°p x·ª≠ l√Ω (SMOTE, Undersampling, Class Weights, ...)
- ƒê·ªÅ xu·∫•t t·ª∑ l·ªá c√¢n b·∫±ng ph√π h·ª£p

FORMAT:
- M·ªói b∆∞·ªõc ph·∫£i c√≥ ti√™u ƒë·ªÅ in ƒë·∫≠m v·ªõi emoji
- D∆∞·ªõi m·ªói b∆∞·ªõc l√† danh s√°ch g·∫°ch ƒë·∫ßu d√≤ng CHI TI·∫æT, C·ª§ TH·ªÇ
- ƒê·ªÅ c·∫≠p T√äN C·ªòT v√† PH∆Ø∆†NG PH√ÅP c·ª• th·ªÉ
- Ng√¥n ng·ªØ: Ti·∫øng Vi·ªát chuy√™n nghi·ªáp

QUAN TR·ªåNG: 
- PH·∫¢I tr·∫£ v·ªÅ ƒê√öNG 8 B∆Ø·ªöC theo c·∫•u tr√∫c tr√™n
- M·ªói b∆∞·ªõc ph·∫£i C·ª§ TH·ªÇ, ƒë·ªÅ c·∫≠p t√™n c·ªôt v√† ph∆∞∆°ng ph√°p
- KH√îNG th√™m b∆∞·ªõc kh√°c, KH√îNG t√≥m t·∫Øt chung chung
- CH·ªà tr·∫£ v·ªÅ 8 b∆∞·ªõc, KH√îNG gi·∫£i th√≠ch th√™m!"""

                                # Call LLM
                                if is_llm_configured and api_key:
                                    if provider == "google":
                                        import google.generativeai as genai
                                        genai.configure(api_key=api_key)
                                        model = genai.GenerativeModel(LLMConfig.get_model(provider))
                                        response = model.generate_content(suggestions_prompt)
                                        suggestions_text = response.text.strip()
                                    else:
                                        # Fallback for other providers or no API
                                        suggestions_text = """**üìã Roadmap Ti·ªÅn X·ª≠ L√Ω D·ªØ Li·ªáu:**

**B∆∞·ªõc 1: üîç X·ª≠ L√Ω Bi·∫øn ƒê·ªãnh Danh & Gi√° Tr·ªã Kh√¥ng H·ª£p L·ªá**
- X√°c ƒë·ªãnh v√† lo·∫°i b·ªè c√°c c·ªôt ƒë·ªãnh danh (customer_id, ID, ...)
- Ki·ªÉm tra v√† x·ª≠ l√Ω c√°c gi√° tr·ªã kh√¥ng h·ª£p l·ªá (√¢m, ngo√†i ph·∫°m vi h·ª£p l√Ω)

**B∆∞·ªõc 2: ‚ùì X·ª≠ L√Ω Gi√° Tr·ªã Thi·∫øu**
- X√°c ƒë·ªãnh c√°c c·ªôt c√≥ missing values
- √Åp d·ª•ng ph∆∞∆°ng ph√°p ph√π h·ª£p: Drop, Mean/Median Imputation, ho·∫∑c Forward Fill

**B∆∞·ªõc 3: ‚ö†Ô∏è X·ª≠ L√Ω Outliers & Bi·∫øn ƒê·ªïi Ph√¢n Ph·ªëi**
- Ph√°t hi·ªán outliers b·∫±ng ph∆∞∆°ng ph√°p IQR ho·∫∑c Z-score
- √Åp d·ª•ng Winsorization ho·∫∑c Log Transform cho c√°c c·ªôt c√≥ outliers
- Bi·∫øn ƒë·ªïi ph√¢n ph·ªëi l·ªách b·∫±ng Log ho·∫∑c Box-Cox n·∫øu c·∫ßn

**B∆∞·ªõc 4: üî§ M√£ H√≥a Bi·∫øn Ph√¢n Lo·∫°i**
- One-Hot Encoding cho bi·∫øn c√≥ cardinality th·∫•p (< 10 categories)
- Label Encoding cho bi·∫øn ordinal ho·∫∑c binary
- Target Encoding cho bi·∫øn c√≥ cardinality cao"""
                                else:
                                    suggestions_text = """**üìã Roadmap Ti·ªÅn X·ª≠ L√Ω D·ªØ Li·ªáu:**

**B∆∞·ªõc 1: üîç X·ª≠ L√Ω Bi·∫øn ƒê·ªãnh Danh & Gi√° Tr·ªã Kh√¥ng H·ª£p L·ªá**
- X√°c ƒë·ªãnh v√† lo·∫°i b·ªè c√°c c·ªôt ƒë·ªãnh danh (customer_id, ID, ...)
- Ki·ªÉm tra v√† x·ª≠ l√Ω c√°c gi√° tr·ªã kh√¥ng h·ª£p l·ªá (√¢m, ngo√†i ph·∫°m vi h·ª£p l√Ω)

**B∆∞·ªõc 2: ‚ùì X·ª≠ L√Ω Gi√° Tr·ªã Thi·∫øu**
- X√°c ƒë·ªãnh c√°c c·ªôt c√≥ missing values
- √Åp d·ª•ng ph∆∞∆°ng ph√°p ph√π h·ª£p: Drop, Mean/Median Imputation, ho·∫∑c Forward Fill

**B∆∞·ªõc 3: ‚ö†Ô∏è X·ª≠ L√Ω Outliers & Bi·∫øn ƒê·ªïi Ph√¢n Ph·ªëi**
- Ph√°t hi·ªán outliers b·∫±ng ph∆∞∆°ng ph√°p IQR ho·∫∑c Z-score
- √Åp d·ª•ng Winsorization ho·∫∑c Log Transform cho c√°c c·ªôt c√≥ outliers
- Bi·∫øn ƒë·ªïi ph√¢n ph·ªëi l·ªách b·∫±ng Log ho·∫∑c Box-Cox n·∫øu c·∫ßn

**B∆∞·ªõc 4: üî§ M√£ H√≥a Bi·∫øn Ph√¢n Lo·∫°i**
- One-Hot Encoding cho bi·∫øn c√≥ cardinality th·∫•p (< 10 categories)
- Label Encoding cho bi·∫øn ordinal ho·∫∑c binary
- Target Encoding cho bi·∫øn c√≥ cardinality cao"""
                                
                                # Save to session state
                                st.session_state.preprocessing_suggestions = suggestions_text
                                st.session_state.eda_analysis_result = st.session_state.ai_analysis
                                st.session_state.llm_provider = provider
                                
                            except Exception as e:
                                st.session_state.preprocessing_suggestions = f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫°o g·ª£i √Ω t·ª± ƒë·ªông: {str(e)}\n\nVui l√≤ng xem ph√¢n t√≠ch EDA ·ªü tr√™n ƒë·ªÉ t·ª± ƒë∆∞a ra c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω."
                    
                    # Display suggestions
                    if 'preprocessing_suggestions' in st.session_state:
                        st.markdown(st.session_state.preprocessing_suggestions)
                        
                        # Button to regenerate
                        if st.button("üîÑ T·∫°o L·∫°i G·ª£i √ù", key="regenerate_preprocessing_suggestions_cached"):
                            del st.session_state.preprocessing_suggestions
                            st.rerun()
                    
                    # Download option
                    st.markdown("---")
                    st.download_button(
                        label="üì• T·∫£i xu·ªëng ph√¢n t√≠ch (Markdown)",
                        data=st.session_state.ai_analysis,
                        file_name="eda_analysis.md",
                        mime="text/markdown",
                        width='stretch',
                        key="download_analysis_cached"
                    )
                else:
                    st.markdown("---")
                    st.info("üëÜ Nh·∫•n n√∫t ph√≠a tr√™n ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch!")
            
            return
        
        # No data at all - show sample format
        print("DEBUG: No file uploaded, showing sample format")
        st.info("üìù Ch∆∞a c√≥ file t·∫£i l√™n. Vui l√≤ng ch·ªçn file CSV.")
        
        with st.expander("üìã Xem M·∫´u ƒê·ªãnh D·∫°ng"):
            st.markdown("""
            File CSV c·∫ßn theo ƒë·ªãnh d·∫°ng sau:
            
            | customer_id | age | income | credit_history | loan_amount | ... | default |
            |-------------|-----|--------|----------------|-------------|-----|---------|
            | 1001        | 35  | 50000  | good           | 10000       | ... | 0       |
            | 1002        | 42  | 75000  | excellent      | 15000       | ... | 0       |
            | 1003        | 28  | 30000  | poor           | 5000        | ... | 1       |
            
            - C·ªôt cu·ªëi c√πng l√† nh√£n (target): 0 = kh√¥ng v·ª° n·ª£, 1 = v·ª° n·ª£
            - C√°c c·ªôt kh√°c l√† ƒë·∫∑c tr∆∞ng (features)
            """)
            
            # Simple basic sample only - no complex loading
            print("DEBUG: Creating basic sample data")
            sample_data = pd.DataFrame({
                'customer_id': range(1001, 1011),
                'age': np.random.randint(25, 65, 10),
                'income': np.random.randint(30000, 100000, 10),
                'credit_history': np.random.choice(['good', 'fair', 'poor'], 10),
                'loan_amount': np.random.randint(5000, 50000, 10),
                'default': np.random.choice([0, 1], 10, p=[0.8, 0.2])
            })
            
            print(f"DEBUG: Sample data created: {len(sample_data)} rows")
            
            csv = sample_data.to_csv(index=False).encode('utf-8')
            st.download_button(
                "üì• T·∫£i V·ªÅ D·ªØ Li·ªáu M·∫´u",
                csv,
                "sample_credit_data.csv",
                "text/csv"
            )
            
            st.dataframe(sample_data, width='stretch')

