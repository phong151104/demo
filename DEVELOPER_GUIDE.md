# ğŸ”§ Developer Guide - Credit Scoring System

## ğŸ“‹ Tá»•ng Quan

Document nÃ y hÆ°á»›ng dáº«n phÃ¡t triá»ƒn backend cho há»‡ thá»‘ng Credit Scoring Ä‘Ã£ cÃ³ giao diá»‡n hoÃ n chá»‰nh.

## ğŸ¯ Má»¥c TiÃªu PhÃ¡t Triá»ƒn

### Phase 1: Core Backend (Æ¯u tiÃªn cao)
1. Data Processing Pipeline
2. Model Training & Evaluation
3. Basic SHAP Integration

### Phase 2: Advanced Features
1. Full SHAP Explainability
2. LLM Integration
3. Model Persistence & Versioning

### Phase 3: Production Ready
1. API Development
2. Database Integration
3. Monitoring & Logging
4. Security & Authentication

---

## ğŸ“¦ Module 1: Data Processing

### File: `backend/data_processing/preprocessing.py`

```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from sklearn.impute import SimpleImputer

class DataPreprocessor:
    """Class xá»­ lÃ½ tiá»n xá»­ lÃ½ dá»¯ liá»‡u"""
    
    def __init__(self):
        self.imputers = {}
        self.encoders = {}
        self.scalers = {}
    
    def handle_missing_values(self, df, strategy='mean'):
        """Xá»­ lÃ½ giÃ¡ trá»‹ thiáº¿u"""
        # TODO: Implement
        pass
    
    def encode_categorical(self, df, method='onehot'):
        """MÃ£ hÃ³a biáº¿n phÃ¢n loáº¡i"""
        # TODO: Implement
        pass
    
    def scale_features(self, df, method='standard'):
        """Scale cÃ¡c biáº¿n sá»‘"""
        # TODO: Implement
        pass
```

**Káº¿t ná»‘i vá»›i UI**: 
- `pages/feature_engineering.py` Tab 1 (Tiá»n Xá»­ LÃ½)
- Replace cÃ¡c `show_processing_placeholder()` báº±ng logic thá»±c

---

## ğŸ¤– Module 2: Model Training

### File: `backend/models/trainer.py`

```python
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, accuracy_score

class ModelTrainer:
    """Class huáº¥n luyá»‡n mÃ´ hÃ¬nh"""
    
    def __init__(self, model_type='logistic'):
        self.model_type = model_type
        self.model = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
    
    def prepare_data(self, X, y, test_size=0.2):
        """Chia train/test"""
        # TODO: Implement
        pass
    
    def train(self, params=None):
        """Huáº¥n luyá»‡n mÃ´ hÃ¬nh"""
        # TODO: Implement
        pass
    
    def evaluate(self):
        """ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh"""
        # TODO: Implement
        pass
```

**Káº¿t ná»‘i vá»›i UI**: 
- `pages/model_training.py` Tab 1 (Cáº¥u HÃ¬nh)
- Button "Huáº¥n Luyá»‡n MÃ´ HÃ¬nh" gá»i `trainer.train()`

---

## ğŸ“Š Module 3: Model Evaluation

### File: `backend/models/evaluator.py`

```python
from sklearn.metrics import (
    confusion_matrix, 
    classification_report,
    roc_curve,
    roc_auc_score
)
import numpy as np

class ModelEvaluator:
    """Class Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh"""
    
    def __init__(self, model, X_test, y_test):
        self.model = model
        self.X_test = X_test
        self.y_test = y_test
        self.y_pred = None
        self.y_pred_proba = None
    
    def get_confusion_matrix(self):
        """Táº¡o confusion matrix"""
        # TODO: Implement
        pass
    
    def get_roc_curve(self):
        """Táº¡o ROC curve data"""
        # TODO: Implement
        # Return: fpr, tpr, auc_score
        pass
    
    def get_classification_report(self):
        """Táº¡o classification report"""
        # TODO: Implement
        pass
```

**Káº¿t ná»‘i vá»›i UI**: 
- `pages/model_training.py` Tab 2 (Káº¿t Quáº£)
- Replace mock data báº±ng káº¿t quáº£ thá»±c

---

## ğŸ” Module 4: SHAP Explainability

### File: `backend/explainability/shap_explainer.py`

```python
import shap
import numpy as np

class SHAPExplainer:
    """Class giáº£i thÃ­ch mÃ´ hÃ¬nh báº±ng SHAP"""
    
    def __init__(self, model, X_train):
        self.model = model
        self.X_train = X_train
        self.explainer = None
        self.shap_values = None
    
    def initialize_explainer(self):
        """Khá»Ÿi táº¡o SHAP explainer"""
        # TreeExplainer for tree models
        # LinearExplainer for linear models
        # TODO: Implement
        pass
    
    def compute_shap_values(self, X):
        """TÃ­nh SHAP values"""
        # TODO: Implement
        pass
    
    def get_global_importance(self):
        """Feature importance toÃ n cá»¥c"""
        # TODO: Implement
        pass
    
    def get_local_explanation(self, sample_idx):
        """Giáº£i thÃ­ch cho má»™t máº«u"""
        # TODO: Implement
        pass
```

**Káº¿t ná»‘i vá»›i UI**: 
- `pages/shap_explanation.py` - Táº¥t cáº£ tabs
- Button "Khá»Ÿi Táº¡o SHAP Explainer" gá»i `initialize_explainer()`

---

## ğŸ¤– Module 5: LLM Integration

### File: `backend/llm_integration/llm_client.py`

```python
from openai import OpenAI
import os

class LLMAnalyzer:
    """Class tÃ­ch há»£p LLM cho phÃ¢n tÃ­ch tá»± Ä‘á»™ng"""
    
    def __init__(self, provider='openai'):
        self.provider = provider
        if provider == 'openai':
            self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
    
    def analyze_data_quality(self, data_summary):
        """PhÃ¢n tÃ­ch cháº¥t lÆ°á»£ng dá»¯ liá»‡u"""
        prompt = f"""
        PhÃ¢n tÃ­ch dataset sau vÃ  Ä‘Æ°a ra nháº­n xÃ©t:
        {data_summary}
        
        HÃ£y Ä‘Ã¡nh giÃ¡:
        1. Cháº¥t lÆ°á»£ng dá»¯ liá»‡u
        2. PhÃ¢n phá»‘i cÃ¡c biáº¿n
        3. Váº¥n Ä‘á» cáº§n xá»­ lÃ½
        4. Khuyáº¿n nghá»‹
        """
        # TODO: Implement
        pass
    
    def interpret_shap(self, shap_data):
        """Diá»…n giáº£i SHAP values"""
        # TODO: Implement
        pass
    
    def generate_recommendations(self, customer_data, prediction):
        """Táº¡o gá»£i Ã½ cáº£i thiá»‡n"""
        # TODO: Implement
        pass
```

**Káº¿t ná»‘i vá»›i UI**: 
- `pages/upload_eda.py` Tab 4 (AI Analysis)
- `pages/shap_explanation.py` Tab 3 (AI Interpretation)
- `pages/prediction.py` Tab 3 (Gá»£i Ã)

---

## ğŸ”— Integration Workflow

### 1. Upload & EDA Page

```python
# In pages/upload_eda.py
from backend.data_processing.preprocessing import DataPreprocessor
from backend.llm_integration.llm_client import LLMAnalyzer

# Replace placeholder
if uploaded_file is not None:
    data = pd.read_csv(uploaded_file)
    st.session_state.data = data
    
    # Generate AI analysis
    llm = LLMAnalyzer()
    analysis = llm.analyze_data_quality(data.describe().to_dict())
    st.markdown(analysis)
```

### 2. Feature Engineering Page

```python
# In pages/feature_engineering.py
from backend.data_processing.preprocessing import DataPreprocessor

preprocessor = DataPreprocessor()

if st.button("Ãp Dá»¥ng Xá»­ LÃ½ Thiáº¿u"):
    processed_data = preprocessor.handle_missing_values(
        st.session_state.data, 
        strategy=missing_method
    )
    st.session_state.processed_data = processed_data
```

### 3. Model Training Page

```python
# In pages/model_training.py
from backend.models.trainer import ModelTrainer
from backend.models.evaluator import ModelEvaluator

if st.button("Huáº¥n Luyá»‡n MÃ´ HÃ¬nh"):
    trainer = ModelTrainer(model_type=model_type)
    trainer.prepare_data(X, y, test_size=test_size/100)
    trainer.train(params)
    
    st.session_state.model = trainer.model
    
    # Evaluate
    evaluator = ModelEvaluator(trainer.model, trainer.X_test, trainer.y_test)
    metrics = evaluator.get_classification_report()
    st.session_state.model_metrics = metrics
```

### 4. SHAP Page

```python
# In pages/shap_explanation.py
from backend.explainability.shap_explainer import SHAPExplainer

if st.button("Khá»Ÿi Táº¡o SHAP Explainer"):
    explainer = SHAPExplainer(
        st.session_state.model,
        st.session_state.X_train
    )
    explainer.initialize_explainer()
    explainer.compute_shap_values(st.session_state.X_test)
    
    st.session_state.explainer = explainer
    st.session_state.shap_values = explainer.shap_values
```

---

## ğŸ“ Testing Strategy

### Unit Tests
```python
# tests/test_preprocessing.py
import pytest
from backend.data_processing.preprocessing import DataPreprocessor

def test_handle_missing_values():
    preprocessor = DataPreprocessor()
    # Test logic
    pass
```

### Integration Tests
```python
# tests/test_integration.py
def test_full_pipeline():
    # Load data -> Process -> Train -> Evaluate -> Explain
    pass
```

---

## ğŸš€ Deployment Checklist

- [ ] Environment variables setup (.env)
- [ ] Dependencies installed (requirements.txt)
- [ ] All backend modules implemented
- [ ] Unit tests passing
- [ ] Integration tests passing
- [ ] UI connected to backend
- [ ] Error handling implemented
- [ ] Logging configured
- [ ] Documentation updated

---

## ğŸ“š Resources

- **Streamlit Docs**: https://docs.streamlit.io
- **SHAP Docs**: https://shap.readthedocs.io
- **Scikit-learn**: https://scikit-learn.org
- **XGBoost**: https://xgboost.readthedocs.io
- **LightGBM**: https://lightgbm.readthedocs.io
- **OpenAI API**: https://platform.openai.com/docs

---

## ğŸ’¡ Tips

1. **Start Small**: Implement má»™t module trÆ°á»›c, test ká»¹, rá»“i chuyá»ƒn sang module khÃ¡c
2. **Use Session State**: Streamlit session state Ä‘á»ƒ lÆ°u model vÃ  data giá»¯a cÃ¡c trang
3. **Error Handling**: Wrap logic trong try-except vÃ  hiá»ƒn thá»‹ lá»—i thÃ¢n thiá»‡n
4. **Progress Bars**: DÃ¹ng `st.progress()` cho cÃ¡c tÃ¡c vá»¥ lÃ¢u
5. **Caching**: DÃ¹ng `@st.cache_data` vÃ  `@st.cache_resource` cho hiá»‡u nÄƒng

---

**Happy Coding! ğŸš€**

